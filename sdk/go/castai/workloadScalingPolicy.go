// Code generated by pulumi-language-go DO NOT EDIT.
// *** WARNING: Do not edit by hand unless you're certain you know what you are doing! ***

package castai

import (
	"context"
	"reflect"

	"errors"
	"github.com/castai/pulumi-castai/sdk/go/castai/internal"
	"github.com/castai/pulumi-castai/sdk/go/castai/workload"
	"github.com/pulumi/pulumi/sdk/v3/go/pulumi"
)

type WorkloadScalingPolicy struct {
	pulumi.CustomResourceState

	AntiAffinity workload.WorkloadScalingPolicyAntiAffinityPtrOutput `pulumi:"antiAffinity"`
	// Recommendation apply type.
	// 	- IMMEDIATE - pods are restarted immediately when new recommendation is generated.
	// 	- DEFERRED - pods are not restarted and recommendation values are applied during natural restarts only (new deployment, etc.)
	ApplyType pulumi.StringOutput `pulumi:"applyType"`
	// Allows defining conditions for automatically assigning workloads to this scaling policy.
	AssignmentRules workload.WorkloadScalingPolicyAssignmentRuleArrayOutput `pulumi:"assignmentRules"`
	// CAST AI cluster id
	ClusterId pulumi.StringOutput `pulumi:"clusterId"`
	// Defines the confidence settings for applying recommendations.
	Confidence  workload.WorkloadScalingPolicyConfidencePtrOutput  `pulumi:"confidence"`
	Cpu         workload.WorkloadScalingPolicyCpuOutput            `pulumi:"cpu"`
	Downscaling workload.WorkloadScalingPolicyDownscalingPtrOutput `pulumi:"downscaling"`
	// Defines possible options for workload management.
	// 	- READ_ONLY - workload watched (metrics collected), but no actions performed by CAST AI.
	// 	- MANAGED - workload watched (metrics collected), CAST AI may perform actions on the workload.
	ManagementOption pulumi.StringOutput                                `pulumi:"managementOption"`
	Memory           workload.WorkloadScalingPolicyMemoryOutput         `pulumi:"memory"`
	MemoryEvent      workload.WorkloadScalingPolicyMemoryEventPtrOutput `pulumi:"memoryEvent"`
	// Scaling policy name
	Name              pulumi.StringOutput                                      `pulumi:"name"`
	PredictiveScaling workload.WorkloadScalingPolicyPredictiveScalingPtrOutput `pulumi:"predictiveScaling"`
	// Defines the rollout behavior used when applying recommendations. Prerequisites:
	// 	- Applicable to Deployment resources that support running as multi-replica.
	// 	- Deployment is running with single replica (replica count = 1).
	// 	- Deployment's rollout strategy allows for downtime.
	// 	- Recommendation apply type is "immediate".
	// 	- Cluster has workload-autoscaler component version v0.35.3 or higher.
	RolloutBehavior workload.WorkloadScalingPolicyRolloutBehaviorPtrOutput `pulumi:"rolloutBehavior"`
	Startup         workload.WorkloadScalingPolicyStartupPtrOutput         `pulumi:"startup"`
}

// NewWorkloadScalingPolicy registers a new resource with the given unique name, arguments, and options.
func NewWorkloadScalingPolicy(ctx *pulumi.Context,
	name string, args *WorkloadScalingPolicyArgs, opts ...pulumi.ResourceOption) (*WorkloadScalingPolicy, error) {
	if args == nil {
		return nil, errors.New("missing one or more required arguments")
	}

	if args.ApplyType == nil {
		return nil, errors.New("invalid value for required argument 'ApplyType'")
	}
	if args.ClusterId == nil {
		return nil, errors.New("invalid value for required argument 'ClusterId'")
	}
	if args.Cpu == nil {
		return nil, errors.New("invalid value for required argument 'Cpu'")
	}
	if args.ManagementOption == nil {
		return nil, errors.New("invalid value for required argument 'ManagementOption'")
	}
	if args.Memory == nil {
		return nil, errors.New("invalid value for required argument 'Memory'")
	}
	opts = internal.PkgResourceDefaultOpts(opts)
	var resource WorkloadScalingPolicy
	err := ctx.RegisterResource("castai:workload:WorkloadScalingPolicy", name, args, &resource, opts...)
	if err != nil {
		return nil, err
	}
	return &resource, nil
}

// GetWorkloadScalingPolicy gets an existing WorkloadScalingPolicy resource's state with the given name, ID, and optional
// state properties that are used to uniquely qualify the lookup (nil if not required).
func GetWorkloadScalingPolicy(ctx *pulumi.Context,
	name string, id pulumi.IDInput, state *WorkloadScalingPolicyState, opts ...pulumi.ResourceOption) (*WorkloadScalingPolicy, error) {
	var resource WorkloadScalingPolicy
	err := ctx.ReadResource("castai:workload:WorkloadScalingPolicy", name, id, state, &resource, opts...)
	if err != nil {
		return nil, err
	}
	return &resource, nil
}

// Input properties used for looking up and filtering WorkloadScalingPolicy resources.
type workloadScalingPolicyState struct {
	AntiAffinity *workload.WorkloadScalingPolicyAntiAffinity `pulumi:"antiAffinity"`
	// Recommendation apply type.
	// 	- IMMEDIATE - pods are restarted immediately when new recommendation is generated.
	// 	- DEFERRED - pods are not restarted and recommendation values are applied during natural restarts only (new deployment, etc.)
	ApplyType *string `pulumi:"applyType"`
	// Allows defining conditions for automatically assigning workloads to this scaling policy.
	AssignmentRules []workload.WorkloadScalingPolicyAssignmentRule `pulumi:"assignmentRules"`
	// CAST AI cluster id
	ClusterId *string `pulumi:"clusterId"`
	// Defines the confidence settings for applying recommendations.
	Confidence  *workload.WorkloadScalingPolicyConfidence  `pulumi:"confidence"`
	Cpu         *workload.WorkloadScalingPolicyCpu         `pulumi:"cpu"`
	Downscaling *workload.WorkloadScalingPolicyDownscaling `pulumi:"downscaling"`
	// Defines possible options for workload management.
	// 	- READ_ONLY - workload watched (metrics collected), but no actions performed by CAST AI.
	// 	- MANAGED - workload watched (metrics collected), CAST AI may perform actions on the workload.
	ManagementOption *string                                    `pulumi:"managementOption"`
	Memory           *workload.WorkloadScalingPolicyMemory      `pulumi:"memory"`
	MemoryEvent      *workload.WorkloadScalingPolicyMemoryEvent `pulumi:"memoryEvent"`
	// Scaling policy name
	Name              *string                                          `pulumi:"name"`
	PredictiveScaling *workload.WorkloadScalingPolicyPredictiveScaling `pulumi:"predictiveScaling"`
	// Defines the rollout behavior used when applying recommendations. Prerequisites:
	// 	- Applicable to Deployment resources that support running as multi-replica.
	// 	- Deployment is running with single replica (replica count = 1).
	// 	- Deployment's rollout strategy allows for downtime.
	// 	- Recommendation apply type is "immediate".
	// 	- Cluster has workload-autoscaler component version v0.35.3 or higher.
	RolloutBehavior *workload.WorkloadScalingPolicyRolloutBehavior `pulumi:"rolloutBehavior"`
	Startup         *workload.WorkloadScalingPolicyStartup         `pulumi:"startup"`
}

type WorkloadScalingPolicyState struct {
	AntiAffinity workload.WorkloadScalingPolicyAntiAffinityPtrInput
	// Recommendation apply type.
	// 	- IMMEDIATE - pods are restarted immediately when new recommendation is generated.
	// 	- DEFERRED - pods are not restarted and recommendation values are applied during natural restarts only (new deployment, etc.)
	ApplyType pulumi.StringPtrInput
	// Allows defining conditions for automatically assigning workloads to this scaling policy.
	AssignmentRules workload.WorkloadScalingPolicyAssignmentRuleArrayInput
	// CAST AI cluster id
	ClusterId pulumi.StringPtrInput
	// Defines the confidence settings for applying recommendations.
	Confidence  workload.WorkloadScalingPolicyConfidencePtrInput
	Cpu         workload.WorkloadScalingPolicyCpuPtrInput
	Downscaling workload.WorkloadScalingPolicyDownscalingPtrInput
	// Defines possible options for workload management.
	// 	- READ_ONLY - workload watched (metrics collected), but no actions performed by CAST AI.
	// 	- MANAGED - workload watched (metrics collected), CAST AI may perform actions on the workload.
	ManagementOption pulumi.StringPtrInput
	Memory           workload.WorkloadScalingPolicyMemoryPtrInput
	MemoryEvent      workload.WorkloadScalingPolicyMemoryEventPtrInput
	// Scaling policy name
	Name              pulumi.StringPtrInput
	PredictiveScaling workload.WorkloadScalingPolicyPredictiveScalingPtrInput
	// Defines the rollout behavior used when applying recommendations. Prerequisites:
	// 	- Applicable to Deployment resources that support running as multi-replica.
	// 	- Deployment is running with single replica (replica count = 1).
	// 	- Deployment's rollout strategy allows for downtime.
	// 	- Recommendation apply type is "immediate".
	// 	- Cluster has workload-autoscaler component version v0.35.3 or higher.
	RolloutBehavior workload.WorkloadScalingPolicyRolloutBehaviorPtrInput
	Startup         workload.WorkloadScalingPolicyStartupPtrInput
}

func (WorkloadScalingPolicyState) ElementType() reflect.Type {
	return reflect.TypeOf((*workloadScalingPolicyState)(nil)).Elem()
}

type workloadScalingPolicyArgs struct {
	AntiAffinity *workload.WorkloadScalingPolicyAntiAffinity `pulumi:"antiAffinity"`
	// Recommendation apply type.
	// 	- IMMEDIATE - pods are restarted immediately when new recommendation is generated.
	// 	- DEFERRED - pods are not restarted and recommendation values are applied during natural restarts only (new deployment, etc.)
	ApplyType string `pulumi:"applyType"`
	// Allows defining conditions for automatically assigning workloads to this scaling policy.
	AssignmentRules []workload.WorkloadScalingPolicyAssignmentRule `pulumi:"assignmentRules"`
	// CAST AI cluster id
	ClusterId string `pulumi:"clusterId"`
	// Defines the confidence settings for applying recommendations.
	Confidence  *workload.WorkloadScalingPolicyConfidence  `pulumi:"confidence"`
	Cpu         workload.WorkloadScalingPolicyCpu          `pulumi:"cpu"`
	Downscaling *workload.WorkloadScalingPolicyDownscaling `pulumi:"downscaling"`
	// Defines possible options for workload management.
	// 	- READ_ONLY - workload watched (metrics collected), but no actions performed by CAST AI.
	// 	- MANAGED - workload watched (metrics collected), CAST AI may perform actions on the workload.
	ManagementOption string                                     `pulumi:"managementOption"`
	Memory           workload.WorkloadScalingPolicyMemory       `pulumi:"memory"`
	MemoryEvent      *workload.WorkloadScalingPolicyMemoryEvent `pulumi:"memoryEvent"`
	// Scaling policy name
	Name              *string                                          `pulumi:"name"`
	PredictiveScaling *workload.WorkloadScalingPolicyPredictiveScaling `pulumi:"predictiveScaling"`
	// Defines the rollout behavior used when applying recommendations. Prerequisites:
	// 	- Applicable to Deployment resources that support running as multi-replica.
	// 	- Deployment is running with single replica (replica count = 1).
	// 	- Deployment's rollout strategy allows for downtime.
	// 	- Recommendation apply type is "immediate".
	// 	- Cluster has workload-autoscaler component version v0.35.3 or higher.
	RolloutBehavior *workload.WorkloadScalingPolicyRolloutBehavior `pulumi:"rolloutBehavior"`
	Startup         *workload.WorkloadScalingPolicyStartup         `pulumi:"startup"`
}

// The set of arguments for constructing a WorkloadScalingPolicy resource.
type WorkloadScalingPolicyArgs struct {
	AntiAffinity workload.WorkloadScalingPolicyAntiAffinityPtrInput
	// Recommendation apply type.
	// 	- IMMEDIATE - pods are restarted immediately when new recommendation is generated.
	// 	- DEFERRED - pods are not restarted and recommendation values are applied during natural restarts only (new deployment, etc.)
	ApplyType pulumi.StringInput
	// Allows defining conditions for automatically assigning workloads to this scaling policy.
	AssignmentRules workload.WorkloadScalingPolicyAssignmentRuleArrayInput
	// CAST AI cluster id
	ClusterId pulumi.StringInput
	// Defines the confidence settings for applying recommendations.
	Confidence  workload.WorkloadScalingPolicyConfidencePtrInput
	Cpu         workload.WorkloadScalingPolicyCpuInput
	Downscaling workload.WorkloadScalingPolicyDownscalingPtrInput
	// Defines possible options for workload management.
	// 	- READ_ONLY - workload watched (metrics collected), but no actions performed by CAST AI.
	// 	- MANAGED - workload watched (metrics collected), CAST AI may perform actions on the workload.
	ManagementOption pulumi.StringInput
	Memory           workload.WorkloadScalingPolicyMemoryInput
	MemoryEvent      workload.WorkloadScalingPolicyMemoryEventPtrInput
	// Scaling policy name
	Name              pulumi.StringPtrInput
	PredictiveScaling workload.WorkloadScalingPolicyPredictiveScalingPtrInput
	// Defines the rollout behavior used when applying recommendations. Prerequisites:
	// 	- Applicable to Deployment resources that support running as multi-replica.
	// 	- Deployment is running with single replica (replica count = 1).
	// 	- Deployment's rollout strategy allows for downtime.
	// 	- Recommendation apply type is "immediate".
	// 	- Cluster has workload-autoscaler component version v0.35.3 or higher.
	RolloutBehavior workload.WorkloadScalingPolicyRolloutBehaviorPtrInput
	Startup         workload.WorkloadScalingPolicyStartupPtrInput
}

func (WorkloadScalingPolicyArgs) ElementType() reflect.Type {
	return reflect.TypeOf((*workloadScalingPolicyArgs)(nil)).Elem()
}

type WorkloadScalingPolicyInput interface {
	pulumi.Input

	ToWorkloadScalingPolicyOutput() WorkloadScalingPolicyOutput
	ToWorkloadScalingPolicyOutputWithContext(ctx context.Context) WorkloadScalingPolicyOutput
}

func (*WorkloadScalingPolicy) ElementType() reflect.Type {
	return reflect.TypeOf((**WorkloadScalingPolicy)(nil)).Elem()
}

func (i *WorkloadScalingPolicy) ToWorkloadScalingPolicyOutput() WorkloadScalingPolicyOutput {
	return i.ToWorkloadScalingPolicyOutputWithContext(context.Background())
}

func (i *WorkloadScalingPolicy) ToWorkloadScalingPolicyOutputWithContext(ctx context.Context) WorkloadScalingPolicyOutput {
	return pulumi.ToOutputWithContext(ctx, i).(WorkloadScalingPolicyOutput)
}

// WorkloadScalingPolicyArrayInput is an input type that accepts WorkloadScalingPolicyArray and WorkloadScalingPolicyArrayOutput values.
// You can construct a concrete instance of `WorkloadScalingPolicyArrayInput` via:
//
//	WorkloadScalingPolicyArray{ WorkloadScalingPolicyArgs{...} }
type WorkloadScalingPolicyArrayInput interface {
	pulumi.Input

	ToWorkloadScalingPolicyArrayOutput() WorkloadScalingPolicyArrayOutput
	ToWorkloadScalingPolicyArrayOutputWithContext(context.Context) WorkloadScalingPolicyArrayOutput
}

type WorkloadScalingPolicyArray []WorkloadScalingPolicyInput

func (WorkloadScalingPolicyArray) ElementType() reflect.Type {
	return reflect.TypeOf((*[]*WorkloadScalingPolicy)(nil)).Elem()
}

func (i WorkloadScalingPolicyArray) ToWorkloadScalingPolicyArrayOutput() WorkloadScalingPolicyArrayOutput {
	return i.ToWorkloadScalingPolicyArrayOutputWithContext(context.Background())
}

func (i WorkloadScalingPolicyArray) ToWorkloadScalingPolicyArrayOutputWithContext(ctx context.Context) WorkloadScalingPolicyArrayOutput {
	return pulumi.ToOutputWithContext(ctx, i).(WorkloadScalingPolicyArrayOutput)
}

// WorkloadScalingPolicyMapInput is an input type that accepts WorkloadScalingPolicyMap and WorkloadScalingPolicyMapOutput values.
// You can construct a concrete instance of `WorkloadScalingPolicyMapInput` via:
//
//	WorkloadScalingPolicyMap{ "key": WorkloadScalingPolicyArgs{...} }
type WorkloadScalingPolicyMapInput interface {
	pulumi.Input

	ToWorkloadScalingPolicyMapOutput() WorkloadScalingPolicyMapOutput
	ToWorkloadScalingPolicyMapOutputWithContext(context.Context) WorkloadScalingPolicyMapOutput
}

type WorkloadScalingPolicyMap map[string]WorkloadScalingPolicyInput

func (WorkloadScalingPolicyMap) ElementType() reflect.Type {
	return reflect.TypeOf((*map[string]*WorkloadScalingPolicy)(nil)).Elem()
}

func (i WorkloadScalingPolicyMap) ToWorkloadScalingPolicyMapOutput() WorkloadScalingPolicyMapOutput {
	return i.ToWorkloadScalingPolicyMapOutputWithContext(context.Background())
}

func (i WorkloadScalingPolicyMap) ToWorkloadScalingPolicyMapOutputWithContext(ctx context.Context) WorkloadScalingPolicyMapOutput {
	return pulumi.ToOutputWithContext(ctx, i).(WorkloadScalingPolicyMapOutput)
}

type WorkloadScalingPolicyOutput struct{ *pulumi.OutputState }

func (WorkloadScalingPolicyOutput) ElementType() reflect.Type {
	return reflect.TypeOf((**WorkloadScalingPolicy)(nil)).Elem()
}

func (o WorkloadScalingPolicyOutput) ToWorkloadScalingPolicyOutput() WorkloadScalingPolicyOutput {
	return o
}

func (o WorkloadScalingPolicyOutput) ToWorkloadScalingPolicyOutputWithContext(ctx context.Context) WorkloadScalingPolicyOutput {
	return o
}

func (o WorkloadScalingPolicyOutput) AntiAffinity() workload.WorkloadScalingPolicyAntiAffinityPtrOutput {
	return o.ApplyT(func(v *WorkloadScalingPolicy) workload.WorkloadScalingPolicyAntiAffinityPtrOutput {
		return v.AntiAffinity
	}).(workload.WorkloadScalingPolicyAntiAffinityPtrOutput)
}

// Recommendation apply type.
//   - IMMEDIATE - pods are restarted immediately when new recommendation is generated.
//   - DEFERRED - pods are not restarted and recommendation values are applied during natural restarts only (new deployment, etc.)
func (o WorkloadScalingPolicyOutput) ApplyType() pulumi.StringOutput {
	return o.ApplyT(func(v *WorkloadScalingPolicy) pulumi.StringOutput { return v.ApplyType }).(pulumi.StringOutput)
}

// Allows defining conditions for automatically assigning workloads to this scaling policy.
func (o WorkloadScalingPolicyOutput) AssignmentRules() workload.WorkloadScalingPolicyAssignmentRuleArrayOutput {
	return o.ApplyT(func(v *WorkloadScalingPolicy) workload.WorkloadScalingPolicyAssignmentRuleArrayOutput {
		return v.AssignmentRules
	}).(workload.WorkloadScalingPolicyAssignmentRuleArrayOutput)
}

// CAST AI cluster id
func (o WorkloadScalingPolicyOutput) ClusterId() pulumi.StringOutput {
	return o.ApplyT(func(v *WorkloadScalingPolicy) pulumi.StringOutput { return v.ClusterId }).(pulumi.StringOutput)
}

// Defines the confidence settings for applying recommendations.
func (o WorkloadScalingPolicyOutput) Confidence() workload.WorkloadScalingPolicyConfidencePtrOutput {
	return o.ApplyT(func(v *WorkloadScalingPolicy) workload.WorkloadScalingPolicyConfidencePtrOutput { return v.Confidence }).(workload.WorkloadScalingPolicyConfidencePtrOutput)
}

func (o WorkloadScalingPolicyOutput) Cpu() workload.WorkloadScalingPolicyCpuOutput {
	return o.ApplyT(func(v *WorkloadScalingPolicy) workload.WorkloadScalingPolicyCpuOutput { return v.Cpu }).(workload.WorkloadScalingPolicyCpuOutput)
}

func (o WorkloadScalingPolicyOutput) Downscaling() workload.WorkloadScalingPolicyDownscalingPtrOutput {
	return o.ApplyT(func(v *WorkloadScalingPolicy) workload.WorkloadScalingPolicyDownscalingPtrOutput {
		return v.Downscaling
	}).(workload.WorkloadScalingPolicyDownscalingPtrOutput)
}

// Defines possible options for workload management.
//   - READ_ONLY - workload watched (metrics collected), but no actions performed by CAST AI.
//   - MANAGED - workload watched (metrics collected), CAST AI may perform actions on the workload.
func (o WorkloadScalingPolicyOutput) ManagementOption() pulumi.StringOutput {
	return o.ApplyT(func(v *WorkloadScalingPolicy) pulumi.StringOutput { return v.ManagementOption }).(pulumi.StringOutput)
}

func (o WorkloadScalingPolicyOutput) Memory() workload.WorkloadScalingPolicyMemoryOutput {
	return o.ApplyT(func(v *WorkloadScalingPolicy) workload.WorkloadScalingPolicyMemoryOutput { return v.Memory }).(workload.WorkloadScalingPolicyMemoryOutput)
}

func (o WorkloadScalingPolicyOutput) MemoryEvent() workload.WorkloadScalingPolicyMemoryEventPtrOutput {
	return o.ApplyT(func(v *WorkloadScalingPolicy) workload.WorkloadScalingPolicyMemoryEventPtrOutput {
		return v.MemoryEvent
	}).(workload.WorkloadScalingPolicyMemoryEventPtrOutput)
}

// Scaling policy name
func (o WorkloadScalingPolicyOutput) Name() pulumi.StringOutput {
	return o.ApplyT(func(v *WorkloadScalingPolicy) pulumi.StringOutput { return v.Name }).(pulumi.StringOutput)
}

func (o WorkloadScalingPolicyOutput) PredictiveScaling() workload.WorkloadScalingPolicyPredictiveScalingPtrOutput {
	return o.ApplyT(func(v *WorkloadScalingPolicy) workload.WorkloadScalingPolicyPredictiveScalingPtrOutput {
		return v.PredictiveScaling
	}).(workload.WorkloadScalingPolicyPredictiveScalingPtrOutput)
}

// Defines the rollout behavior used when applying recommendations. Prerequisites:
//   - Applicable to Deployment resources that support running as multi-replica.
//   - Deployment is running with single replica (replica count = 1).
//   - Deployment's rollout strategy allows for downtime.
//   - Recommendation apply type is "immediate".
//   - Cluster has workload-autoscaler component version v0.35.3 or higher.
func (o WorkloadScalingPolicyOutput) RolloutBehavior() workload.WorkloadScalingPolicyRolloutBehaviorPtrOutput {
	return o.ApplyT(func(v *WorkloadScalingPolicy) workload.WorkloadScalingPolicyRolloutBehaviorPtrOutput {
		return v.RolloutBehavior
	}).(workload.WorkloadScalingPolicyRolloutBehaviorPtrOutput)
}

func (o WorkloadScalingPolicyOutput) Startup() workload.WorkloadScalingPolicyStartupPtrOutput {
	return o.ApplyT(func(v *WorkloadScalingPolicy) workload.WorkloadScalingPolicyStartupPtrOutput { return v.Startup }).(workload.WorkloadScalingPolicyStartupPtrOutput)
}

type WorkloadScalingPolicyArrayOutput struct{ *pulumi.OutputState }

func (WorkloadScalingPolicyArrayOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*[]*WorkloadScalingPolicy)(nil)).Elem()
}

func (o WorkloadScalingPolicyArrayOutput) ToWorkloadScalingPolicyArrayOutput() WorkloadScalingPolicyArrayOutput {
	return o
}

func (o WorkloadScalingPolicyArrayOutput) ToWorkloadScalingPolicyArrayOutputWithContext(ctx context.Context) WorkloadScalingPolicyArrayOutput {
	return o
}

func (o WorkloadScalingPolicyArrayOutput) Index(i pulumi.IntInput) WorkloadScalingPolicyOutput {
	return pulumi.All(o, i).ApplyT(func(vs []interface{}) *WorkloadScalingPolicy {
		return vs[0].([]*WorkloadScalingPolicy)[vs[1].(int)]
	}).(WorkloadScalingPolicyOutput)
}

type WorkloadScalingPolicyMapOutput struct{ *pulumi.OutputState }

func (WorkloadScalingPolicyMapOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*map[string]*WorkloadScalingPolicy)(nil)).Elem()
}

func (o WorkloadScalingPolicyMapOutput) ToWorkloadScalingPolicyMapOutput() WorkloadScalingPolicyMapOutput {
	return o
}

func (o WorkloadScalingPolicyMapOutput) ToWorkloadScalingPolicyMapOutputWithContext(ctx context.Context) WorkloadScalingPolicyMapOutput {
	return o
}

func (o WorkloadScalingPolicyMapOutput) MapIndex(k pulumi.StringInput) WorkloadScalingPolicyOutput {
	return pulumi.All(o, k).ApplyT(func(vs []interface{}) *WorkloadScalingPolicy {
		return vs[0].(map[string]*WorkloadScalingPolicy)[vs[1].(string)]
	}).(WorkloadScalingPolicyOutput)
}

func init() {
	pulumi.RegisterInputType(reflect.TypeOf((*WorkloadScalingPolicyInput)(nil)).Elem(), &WorkloadScalingPolicy{})
	pulumi.RegisterInputType(reflect.TypeOf((*WorkloadScalingPolicyArrayInput)(nil)).Elem(), WorkloadScalingPolicyArray{})
	pulumi.RegisterInputType(reflect.TypeOf((*WorkloadScalingPolicyMapInput)(nil)).Elem(), WorkloadScalingPolicyMap{})
	pulumi.RegisterOutputType(WorkloadScalingPolicyOutput{})
	pulumi.RegisterOutputType(WorkloadScalingPolicyArrayOutput{})
	pulumi.RegisterOutputType(WorkloadScalingPolicyMapOutput{})
}
