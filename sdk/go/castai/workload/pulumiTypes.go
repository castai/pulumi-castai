// Code generated by pulumi-language-go DO NOT EDIT.
// *** WARNING: Do not edit by hand unless you're certain you know what you are doing! ***

package workload

import (
	"context"
	"reflect"

	"github.com/castai/pulumi-castai/sdk/go/castai/internal"
	"github.com/pulumi/pulumi/sdk/v3/go/pulumi"
)

var _ = internal.GetEnvOrDefault

type WorkloadScalingPolicyAntiAffinity struct {
	// Defines if anti-affinity should be considered when scaling the workload.
	// 	If enabled, requiring host ports, or having anti-affinity on hostname will force all recommendations to be deferred.
	ConsiderAntiAffinity *bool `pulumi:"considerAntiAffinity"`
}

// WorkloadScalingPolicyAntiAffinityInput is an input type that accepts WorkloadScalingPolicyAntiAffinityArgs and WorkloadScalingPolicyAntiAffinityOutput values.
// You can construct a concrete instance of `WorkloadScalingPolicyAntiAffinityInput` via:
//
//	WorkloadScalingPolicyAntiAffinityArgs{...}
type WorkloadScalingPolicyAntiAffinityInput interface {
	pulumi.Input

	ToWorkloadScalingPolicyAntiAffinityOutput() WorkloadScalingPolicyAntiAffinityOutput
	ToWorkloadScalingPolicyAntiAffinityOutputWithContext(context.Context) WorkloadScalingPolicyAntiAffinityOutput
}

type WorkloadScalingPolicyAntiAffinityArgs struct {
	// Defines if anti-affinity should be considered when scaling the workload.
	// 	If enabled, requiring host ports, or having anti-affinity on hostname will force all recommendations to be deferred.
	ConsiderAntiAffinity pulumi.BoolPtrInput `pulumi:"considerAntiAffinity"`
}

func (WorkloadScalingPolicyAntiAffinityArgs) ElementType() reflect.Type {
	return reflect.TypeOf((*WorkloadScalingPolicyAntiAffinity)(nil)).Elem()
}

func (i WorkloadScalingPolicyAntiAffinityArgs) ToWorkloadScalingPolicyAntiAffinityOutput() WorkloadScalingPolicyAntiAffinityOutput {
	return i.ToWorkloadScalingPolicyAntiAffinityOutputWithContext(context.Background())
}

func (i WorkloadScalingPolicyAntiAffinityArgs) ToWorkloadScalingPolicyAntiAffinityOutputWithContext(ctx context.Context) WorkloadScalingPolicyAntiAffinityOutput {
	return pulumi.ToOutputWithContext(ctx, i).(WorkloadScalingPolicyAntiAffinityOutput)
}

func (i WorkloadScalingPolicyAntiAffinityArgs) ToWorkloadScalingPolicyAntiAffinityPtrOutput() WorkloadScalingPolicyAntiAffinityPtrOutput {
	return i.ToWorkloadScalingPolicyAntiAffinityPtrOutputWithContext(context.Background())
}

func (i WorkloadScalingPolicyAntiAffinityArgs) ToWorkloadScalingPolicyAntiAffinityPtrOutputWithContext(ctx context.Context) WorkloadScalingPolicyAntiAffinityPtrOutput {
	return pulumi.ToOutputWithContext(ctx, i).(WorkloadScalingPolicyAntiAffinityOutput).ToWorkloadScalingPolicyAntiAffinityPtrOutputWithContext(ctx)
}

// WorkloadScalingPolicyAntiAffinityPtrInput is an input type that accepts WorkloadScalingPolicyAntiAffinityArgs, WorkloadScalingPolicyAntiAffinityPtr and WorkloadScalingPolicyAntiAffinityPtrOutput values.
// You can construct a concrete instance of `WorkloadScalingPolicyAntiAffinityPtrInput` via:
//
//	        WorkloadScalingPolicyAntiAffinityArgs{...}
//
//	or:
//
//	        nil
type WorkloadScalingPolicyAntiAffinityPtrInput interface {
	pulumi.Input

	ToWorkloadScalingPolicyAntiAffinityPtrOutput() WorkloadScalingPolicyAntiAffinityPtrOutput
	ToWorkloadScalingPolicyAntiAffinityPtrOutputWithContext(context.Context) WorkloadScalingPolicyAntiAffinityPtrOutput
}

type workloadScalingPolicyAntiAffinityPtrType WorkloadScalingPolicyAntiAffinityArgs

func WorkloadScalingPolicyAntiAffinityPtr(v *WorkloadScalingPolicyAntiAffinityArgs) WorkloadScalingPolicyAntiAffinityPtrInput {
	return (*workloadScalingPolicyAntiAffinityPtrType)(v)
}

func (*workloadScalingPolicyAntiAffinityPtrType) ElementType() reflect.Type {
	return reflect.TypeOf((**WorkloadScalingPolicyAntiAffinity)(nil)).Elem()
}

func (i *workloadScalingPolicyAntiAffinityPtrType) ToWorkloadScalingPolicyAntiAffinityPtrOutput() WorkloadScalingPolicyAntiAffinityPtrOutput {
	return i.ToWorkloadScalingPolicyAntiAffinityPtrOutputWithContext(context.Background())
}

func (i *workloadScalingPolicyAntiAffinityPtrType) ToWorkloadScalingPolicyAntiAffinityPtrOutputWithContext(ctx context.Context) WorkloadScalingPolicyAntiAffinityPtrOutput {
	return pulumi.ToOutputWithContext(ctx, i).(WorkloadScalingPolicyAntiAffinityPtrOutput)
}

type WorkloadScalingPolicyAntiAffinityOutput struct{ *pulumi.OutputState }

func (WorkloadScalingPolicyAntiAffinityOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*WorkloadScalingPolicyAntiAffinity)(nil)).Elem()
}

func (o WorkloadScalingPolicyAntiAffinityOutput) ToWorkloadScalingPolicyAntiAffinityOutput() WorkloadScalingPolicyAntiAffinityOutput {
	return o
}

func (o WorkloadScalingPolicyAntiAffinityOutput) ToWorkloadScalingPolicyAntiAffinityOutputWithContext(ctx context.Context) WorkloadScalingPolicyAntiAffinityOutput {
	return o
}

func (o WorkloadScalingPolicyAntiAffinityOutput) ToWorkloadScalingPolicyAntiAffinityPtrOutput() WorkloadScalingPolicyAntiAffinityPtrOutput {
	return o.ToWorkloadScalingPolicyAntiAffinityPtrOutputWithContext(context.Background())
}

func (o WorkloadScalingPolicyAntiAffinityOutput) ToWorkloadScalingPolicyAntiAffinityPtrOutputWithContext(ctx context.Context) WorkloadScalingPolicyAntiAffinityPtrOutput {
	return o.ApplyTWithContext(ctx, func(_ context.Context, v WorkloadScalingPolicyAntiAffinity) *WorkloadScalingPolicyAntiAffinity {
		return &v
	}).(WorkloadScalingPolicyAntiAffinityPtrOutput)
}

// Defines if anti-affinity should be considered when scaling the workload.
//
//	If enabled, requiring host ports, or having anti-affinity on hostname will force all recommendations to be deferred.
func (o WorkloadScalingPolicyAntiAffinityOutput) ConsiderAntiAffinity() pulumi.BoolPtrOutput {
	return o.ApplyT(func(v WorkloadScalingPolicyAntiAffinity) *bool { return v.ConsiderAntiAffinity }).(pulumi.BoolPtrOutput)
}

type WorkloadScalingPolicyAntiAffinityPtrOutput struct{ *pulumi.OutputState }

func (WorkloadScalingPolicyAntiAffinityPtrOutput) ElementType() reflect.Type {
	return reflect.TypeOf((**WorkloadScalingPolicyAntiAffinity)(nil)).Elem()
}

func (o WorkloadScalingPolicyAntiAffinityPtrOutput) ToWorkloadScalingPolicyAntiAffinityPtrOutput() WorkloadScalingPolicyAntiAffinityPtrOutput {
	return o
}

func (o WorkloadScalingPolicyAntiAffinityPtrOutput) ToWorkloadScalingPolicyAntiAffinityPtrOutputWithContext(ctx context.Context) WorkloadScalingPolicyAntiAffinityPtrOutput {
	return o
}

func (o WorkloadScalingPolicyAntiAffinityPtrOutput) Elem() WorkloadScalingPolicyAntiAffinityOutput {
	return o.ApplyT(func(v *WorkloadScalingPolicyAntiAffinity) WorkloadScalingPolicyAntiAffinity {
		if v != nil {
			return *v
		}
		var ret WorkloadScalingPolicyAntiAffinity
		return ret
	}).(WorkloadScalingPolicyAntiAffinityOutput)
}

// Defines if anti-affinity should be considered when scaling the workload.
//
//	If enabled, requiring host ports, or having anti-affinity on hostname will force all recommendations to be deferred.
func (o WorkloadScalingPolicyAntiAffinityPtrOutput) ConsiderAntiAffinity() pulumi.BoolPtrOutput {
	return o.ApplyT(func(v *WorkloadScalingPolicyAntiAffinity) *bool {
		if v == nil {
			return nil
		}
		return v.ConsiderAntiAffinity
	}).(pulumi.BoolPtrOutput)
}

type WorkloadScalingPolicyAssignmentRule struct {
	Rules []WorkloadScalingPolicyAssignmentRuleRule `pulumi:"rules"`
}

// WorkloadScalingPolicyAssignmentRuleInput is an input type that accepts WorkloadScalingPolicyAssignmentRuleArgs and WorkloadScalingPolicyAssignmentRuleOutput values.
// You can construct a concrete instance of `WorkloadScalingPolicyAssignmentRuleInput` via:
//
//	WorkloadScalingPolicyAssignmentRuleArgs{...}
type WorkloadScalingPolicyAssignmentRuleInput interface {
	pulumi.Input

	ToWorkloadScalingPolicyAssignmentRuleOutput() WorkloadScalingPolicyAssignmentRuleOutput
	ToWorkloadScalingPolicyAssignmentRuleOutputWithContext(context.Context) WorkloadScalingPolicyAssignmentRuleOutput
}

type WorkloadScalingPolicyAssignmentRuleArgs struct {
	Rules WorkloadScalingPolicyAssignmentRuleRuleArrayInput `pulumi:"rules"`
}

func (WorkloadScalingPolicyAssignmentRuleArgs) ElementType() reflect.Type {
	return reflect.TypeOf((*WorkloadScalingPolicyAssignmentRule)(nil)).Elem()
}

func (i WorkloadScalingPolicyAssignmentRuleArgs) ToWorkloadScalingPolicyAssignmentRuleOutput() WorkloadScalingPolicyAssignmentRuleOutput {
	return i.ToWorkloadScalingPolicyAssignmentRuleOutputWithContext(context.Background())
}

func (i WorkloadScalingPolicyAssignmentRuleArgs) ToWorkloadScalingPolicyAssignmentRuleOutputWithContext(ctx context.Context) WorkloadScalingPolicyAssignmentRuleOutput {
	return pulumi.ToOutputWithContext(ctx, i).(WorkloadScalingPolicyAssignmentRuleOutput)
}

// WorkloadScalingPolicyAssignmentRuleArrayInput is an input type that accepts WorkloadScalingPolicyAssignmentRuleArray and WorkloadScalingPolicyAssignmentRuleArrayOutput values.
// You can construct a concrete instance of `WorkloadScalingPolicyAssignmentRuleArrayInput` via:
//
//	WorkloadScalingPolicyAssignmentRuleArray{ WorkloadScalingPolicyAssignmentRuleArgs{...} }
type WorkloadScalingPolicyAssignmentRuleArrayInput interface {
	pulumi.Input

	ToWorkloadScalingPolicyAssignmentRuleArrayOutput() WorkloadScalingPolicyAssignmentRuleArrayOutput
	ToWorkloadScalingPolicyAssignmentRuleArrayOutputWithContext(context.Context) WorkloadScalingPolicyAssignmentRuleArrayOutput
}

type WorkloadScalingPolicyAssignmentRuleArray []WorkloadScalingPolicyAssignmentRuleInput

func (WorkloadScalingPolicyAssignmentRuleArray) ElementType() reflect.Type {
	return reflect.TypeOf((*[]WorkloadScalingPolicyAssignmentRule)(nil)).Elem()
}

func (i WorkloadScalingPolicyAssignmentRuleArray) ToWorkloadScalingPolicyAssignmentRuleArrayOutput() WorkloadScalingPolicyAssignmentRuleArrayOutput {
	return i.ToWorkloadScalingPolicyAssignmentRuleArrayOutputWithContext(context.Background())
}

func (i WorkloadScalingPolicyAssignmentRuleArray) ToWorkloadScalingPolicyAssignmentRuleArrayOutputWithContext(ctx context.Context) WorkloadScalingPolicyAssignmentRuleArrayOutput {
	return pulumi.ToOutputWithContext(ctx, i).(WorkloadScalingPolicyAssignmentRuleArrayOutput)
}

type WorkloadScalingPolicyAssignmentRuleOutput struct{ *pulumi.OutputState }

func (WorkloadScalingPolicyAssignmentRuleOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*WorkloadScalingPolicyAssignmentRule)(nil)).Elem()
}

func (o WorkloadScalingPolicyAssignmentRuleOutput) ToWorkloadScalingPolicyAssignmentRuleOutput() WorkloadScalingPolicyAssignmentRuleOutput {
	return o
}

func (o WorkloadScalingPolicyAssignmentRuleOutput) ToWorkloadScalingPolicyAssignmentRuleOutputWithContext(ctx context.Context) WorkloadScalingPolicyAssignmentRuleOutput {
	return o
}

func (o WorkloadScalingPolicyAssignmentRuleOutput) Rules() WorkloadScalingPolicyAssignmentRuleRuleArrayOutput {
	return o.ApplyT(func(v WorkloadScalingPolicyAssignmentRule) []WorkloadScalingPolicyAssignmentRuleRule { return v.Rules }).(WorkloadScalingPolicyAssignmentRuleRuleArrayOutput)
}

type WorkloadScalingPolicyAssignmentRuleArrayOutput struct{ *pulumi.OutputState }

func (WorkloadScalingPolicyAssignmentRuleArrayOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*[]WorkloadScalingPolicyAssignmentRule)(nil)).Elem()
}

func (o WorkloadScalingPolicyAssignmentRuleArrayOutput) ToWorkloadScalingPolicyAssignmentRuleArrayOutput() WorkloadScalingPolicyAssignmentRuleArrayOutput {
	return o
}

func (o WorkloadScalingPolicyAssignmentRuleArrayOutput) ToWorkloadScalingPolicyAssignmentRuleArrayOutputWithContext(ctx context.Context) WorkloadScalingPolicyAssignmentRuleArrayOutput {
	return o
}

func (o WorkloadScalingPolicyAssignmentRuleArrayOutput) Index(i pulumi.IntInput) WorkloadScalingPolicyAssignmentRuleOutput {
	return pulumi.All(o, i).ApplyT(func(vs []interface{}) WorkloadScalingPolicyAssignmentRule {
		return vs[0].([]WorkloadScalingPolicyAssignmentRule)[vs[1].(int)]
	}).(WorkloadScalingPolicyAssignmentRuleOutput)
}

type WorkloadScalingPolicyAssignmentRuleRule struct {
	// Allows assigning a scaling policy based on the workload's namespace.
	Namespace *WorkloadScalingPolicyAssignmentRuleRuleNamespace `pulumi:"namespace"`
	// Allows assigning a scaling policy based on the workload's metadata.
	Workload *WorkloadScalingPolicyAssignmentRuleRuleWorkload `pulumi:"workload"`
}

// WorkloadScalingPolicyAssignmentRuleRuleInput is an input type that accepts WorkloadScalingPolicyAssignmentRuleRuleArgs and WorkloadScalingPolicyAssignmentRuleRuleOutput values.
// You can construct a concrete instance of `WorkloadScalingPolicyAssignmentRuleRuleInput` via:
//
//	WorkloadScalingPolicyAssignmentRuleRuleArgs{...}
type WorkloadScalingPolicyAssignmentRuleRuleInput interface {
	pulumi.Input

	ToWorkloadScalingPolicyAssignmentRuleRuleOutput() WorkloadScalingPolicyAssignmentRuleRuleOutput
	ToWorkloadScalingPolicyAssignmentRuleRuleOutputWithContext(context.Context) WorkloadScalingPolicyAssignmentRuleRuleOutput
}

type WorkloadScalingPolicyAssignmentRuleRuleArgs struct {
	// Allows assigning a scaling policy based on the workload's namespace.
	Namespace WorkloadScalingPolicyAssignmentRuleRuleNamespacePtrInput `pulumi:"namespace"`
	// Allows assigning a scaling policy based on the workload's metadata.
	Workload WorkloadScalingPolicyAssignmentRuleRuleWorkloadPtrInput `pulumi:"workload"`
}

func (WorkloadScalingPolicyAssignmentRuleRuleArgs) ElementType() reflect.Type {
	return reflect.TypeOf((*WorkloadScalingPolicyAssignmentRuleRule)(nil)).Elem()
}

func (i WorkloadScalingPolicyAssignmentRuleRuleArgs) ToWorkloadScalingPolicyAssignmentRuleRuleOutput() WorkloadScalingPolicyAssignmentRuleRuleOutput {
	return i.ToWorkloadScalingPolicyAssignmentRuleRuleOutputWithContext(context.Background())
}

func (i WorkloadScalingPolicyAssignmentRuleRuleArgs) ToWorkloadScalingPolicyAssignmentRuleRuleOutputWithContext(ctx context.Context) WorkloadScalingPolicyAssignmentRuleRuleOutput {
	return pulumi.ToOutputWithContext(ctx, i).(WorkloadScalingPolicyAssignmentRuleRuleOutput)
}

// WorkloadScalingPolicyAssignmentRuleRuleArrayInput is an input type that accepts WorkloadScalingPolicyAssignmentRuleRuleArray and WorkloadScalingPolicyAssignmentRuleRuleArrayOutput values.
// You can construct a concrete instance of `WorkloadScalingPolicyAssignmentRuleRuleArrayInput` via:
//
//	WorkloadScalingPolicyAssignmentRuleRuleArray{ WorkloadScalingPolicyAssignmentRuleRuleArgs{...} }
type WorkloadScalingPolicyAssignmentRuleRuleArrayInput interface {
	pulumi.Input

	ToWorkloadScalingPolicyAssignmentRuleRuleArrayOutput() WorkloadScalingPolicyAssignmentRuleRuleArrayOutput
	ToWorkloadScalingPolicyAssignmentRuleRuleArrayOutputWithContext(context.Context) WorkloadScalingPolicyAssignmentRuleRuleArrayOutput
}

type WorkloadScalingPolicyAssignmentRuleRuleArray []WorkloadScalingPolicyAssignmentRuleRuleInput

func (WorkloadScalingPolicyAssignmentRuleRuleArray) ElementType() reflect.Type {
	return reflect.TypeOf((*[]WorkloadScalingPolicyAssignmentRuleRule)(nil)).Elem()
}

func (i WorkloadScalingPolicyAssignmentRuleRuleArray) ToWorkloadScalingPolicyAssignmentRuleRuleArrayOutput() WorkloadScalingPolicyAssignmentRuleRuleArrayOutput {
	return i.ToWorkloadScalingPolicyAssignmentRuleRuleArrayOutputWithContext(context.Background())
}

func (i WorkloadScalingPolicyAssignmentRuleRuleArray) ToWorkloadScalingPolicyAssignmentRuleRuleArrayOutputWithContext(ctx context.Context) WorkloadScalingPolicyAssignmentRuleRuleArrayOutput {
	return pulumi.ToOutputWithContext(ctx, i).(WorkloadScalingPolicyAssignmentRuleRuleArrayOutput)
}

type WorkloadScalingPolicyAssignmentRuleRuleOutput struct{ *pulumi.OutputState }

func (WorkloadScalingPolicyAssignmentRuleRuleOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*WorkloadScalingPolicyAssignmentRuleRule)(nil)).Elem()
}

func (o WorkloadScalingPolicyAssignmentRuleRuleOutput) ToWorkloadScalingPolicyAssignmentRuleRuleOutput() WorkloadScalingPolicyAssignmentRuleRuleOutput {
	return o
}

func (o WorkloadScalingPolicyAssignmentRuleRuleOutput) ToWorkloadScalingPolicyAssignmentRuleRuleOutputWithContext(ctx context.Context) WorkloadScalingPolicyAssignmentRuleRuleOutput {
	return o
}

// Allows assigning a scaling policy based on the workload's namespace.
func (o WorkloadScalingPolicyAssignmentRuleRuleOutput) Namespace() WorkloadScalingPolicyAssignmentRuleRuleNamespacePtrOutput {
	return o.ApplyT(func(v WorkloadScalingPolicyAssignmentRuleRule) *WorkloadScalingPolicyAssignmentRuleRuleNamespace {
		return v.Namespace
	}).(WorkloadScalingPolicyAssignmentRuleRuleNamespacePtrOutput)
}

// Allows assigning a scaling policy based on the workload's metadata.
func (o WorkloadScalingPolicyAssignmentRuleRuleOutput) Workload() WorkloadScalingPolicyAssignmentRuleRuleWorkloadPtrOutput {
	return o.ApplyT(func(v WorkloadScalingPolicyAssignmentRuleRule) *WorkloadScalingPolicyAssignmentRuleRuleWorkload {
		return v.Workload
	}).(WorkloadScalingPolicyAssignmentRuleRuleWorkloadPtrOutput)
}

type WorkloadScalingPolicyAssignmentRuleRuleArrayOutput struct{ *pulumi.OutputState }

func (WorkloadScalingPolicyAssignmentRuleRuleArrayOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*[]WorkloadScalingPolicyAssignmentRuleRule)(nil)).Elem()
}

func (o WorkloadScalingPolicyAssignmentRuleRuleArrayOutput) ToWorkloadScalingPolicyAssignmentRuleRuleArrayOutput() WorkloadScalingPolicyAssignmentRuleRuleArrayOutput {
	return o
}

func (o WorkloadScalingPolicyAssignmentRuleRuleArrayOutput) ToWorkloadScalingPolicyAssignmentRuleRuleArrayOutputWithContext(ctx context.Context) WorkloadScalingPolicyAssignmentRuleRuleArrayOutput {
	return o
}

func (o WorkloadScalingPolicyAssignmentRuleRuleArrayOutput) Index(i pulumi.IntInput) WorkloadScalingPolicyAssignmentRuleRuleOutput {
	return pulumi.All(o, i).ApplyT(func(vs []interface{}) WorkloadScalingPolicyAssignmentRuleRule {
		return vs[0].([]WorkloadScalingPolicyAssignmentRuleRule)[vs[1].(int)]
	}).(WorkloadScalingPolicyAssignmentRuleRuleOutput)
}

type WorkloadScalingPolicyAssignmentRuleRuleNamespace struct {
	// Defines matching by namespace names.
	Names []string `pulumi:"names"`
}

// WorkloadScalingPolicyAssignmentRuleRuleNamespaceInput is an input type that accepts WorkloadScalingPolicyAssignmentRuleRuleNamespaceArgs and WorkloadScalingPolicyAssignmentRuleRuleNamespaceOutput values.
// You can construct a concrete instance of `WorkloadScalingPolicyAssignmentRuleRuleNamespaceInput` via:
//
//	WorkloadScalingPolicyAssignmentRuleRuleNamespaceArgs{...}
type WorkloadScalingPolicyAssignmentRuleRuleNamespaceInput interface {
	pulumi.Input

	ToWorkloadScalingPolicyAssignmentRuleRuleNamespaceOutput() WorkloadScalingPolicyAssignmentRuleRuleNamespaceOutput
	ToWorkloadScalingPolicyAssignmentRuleRuleNamespaceOutputWithContext(context.Context) WorkloadScalingPolicyAssignmentRuleRuleNamespaceOutput
}

type WorkloadScalingPolicyAssignmentRuleRuleNamespaceArgs struct {
	// Defines matching by namespace names.
	Names pulumi.StringArrayInput `pulumi:"names"`
}

func (WorkloadScalingPolicyAssignmentRuleRuleNamespaceArgs) ElementType() reflect.Type {
	return reflect.TypeOf((*WorkloadScalingPolicyAssignmentRuleRuleNamespace)(nil)).Elem()
}

func (i WorkloadScalingPolicyAssignmentRuleRuleNamespaceArgs) ToWorkloadScalingPolicyAssignmentRuleRuleNamespaceOutput() WorkloadScalingPolicyAssignmentRuleRuleNamespaceOutput {
	return i.ToWorkloadScalingPolicyAssignmentRuleRuleNamespaceOutputWithContext(context.Background())
}

func (i WorkloadScalingPolicyAssignmentRuleRuleNamespaceArgs) ToWorkloadScalingPolicyAssignmentRuleRuleNamespaceOutputWithContext(ctx context.Context) WorkloadScalingPolicyAssignmentRuleRuleNamespaceOutput {
	return pulumi.ToOutputWithContext(ctx, i).(WorkloadScalingPolicyAssignmentRuleRuleNamespaceOutput)
}

func (i WorkloadScalingPolicyAssignmentRuleRuleNamespaceArgs) ToWorkloadScalingPolicyAssignmentRuleRuleNamespacePtrOutput() WorkloadScalingPolicyAssignmentRuleRuleNamespacePtrOutput {
	return i.ToWorkloadScalingPolicyAssignmentRuleRuleNamespacePtrOutputWithContext(context.Background())
}

func (i WorkloadScalingPolicyAssignmentRuleRuleNamespaceArgs) ToWorkloadScalingPolicyAssignmentRuleRuleNamespacePtrOutputWithContext(ctx context.Context) WorkloadScalingPolicyAssignmentRuleRuleNamespacePtrOutput {
	return pulumi.ToOutputWithContext(ctx, i).(WorkloadScalingPolicyAssignmentRuleRuleNamespaceOutput).ToWorkloadScalingPolicyAssignmentRuleRuleNamespacePtrOutputWithContext(ctx)
}

// WorkloadScalingPolicyAssignmentRuleRuleNamespacePtrInput is an input type that accepts WorkloadScalingPolicyAssignmentRuleRuleNamespaceArgs, WorkloadScalingPolicyAssignmentRuleRuleNamespacePtr and WorkloadScalingPolicyAssignmentRuleRuleNamespacePtrOutput values.
// You can construct a concrete instance of `WorkloadScalingPolicyAssignmentRuleRuleNamespacePtrInput` via:
//
//	        WorkloadScalingPolicyAssignmentRuleRuleNamespaceArgs{...}
//
//	or:
//
//	        nil
type WorkloadScalingPolicyAssignmentRuleRuleNamespacePtrInput interface {
	pulumi.Input

	ToWorkloadScalingPolicyAssignmentRuleRuleNamespacePtrOutput() WorkloadScalingPolicyAssignmentRuleRuleNamespacePtrOutput
	ToWorkloadScalingPolicyAssignmentRuleRuleNamespacePtrOutputWithContext(context.Context) WorkloadScalingPolicyAssignmentRuleRuleNamespacePtrOutput
}

type workloadScalingPolicyAssignmentRuleRuleNamespacePtrType WorkloadScalingPolicyAssignmentRuleRuleNamespaceArgs

func WorkloadScalingPolicyAssignmentRuleRuleNamespacePtr(v *WorkloadScalingPolicyAssignmentRuleRuleNamespaceArgs) WorkloadScalingPolicyAssignmentRuleRuleNamespacePtrInput {
	return (*workloadScalingPolicyAssignmentRuleRuleNamespacePtrType)(v)
}

func (*workloadScalingPolicyAssignmentRuleRuleNamespacePtrType) ElementType() reflect.Type {
	return reflect.TypeOf((**WorkloadScalingPolicyAssignmentRuleRuleNamespace)(nil)).Elem()
}

func (i *workloadScalingPolicyAssignmentRuleRuleNamespacePtrType) ToWorkloadScalingPolicyAssignmentRuleRuleNamespacePtrOutput() WorkloadScalingPolicyAssignmentRuleRuleNamespacePtrOutput {
	return i.ToWorkloadScalingPolicyAssignmentRuleRuleNamespacePtrOutputWithContext(context.Background())
}

func (i *workloadScalingPolicyAssignmentRuleRuleNamespacePtrType) ToWorkloadScalingPolicyAssignmentRuleRuleNamespacePtrOutputWithContext(ctx context.Context) WorkloadScalingPolicyAssignmentRuleRuleNamespacePtrOutput {
	return pulumi.ToOutputWithContext(ctx, i).(WorkloadScalingPolicyAssignmentRuleRuleNamespacePtrOutput)
}

type WorkloadScalingPolicyAssignmentRuleRuleNamespaceOutput struct{ *pulumi.OutputState }

func (WorkloadScalingPolicyAssignmentRuleRuleNamespaceOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*WorkloadScalingPolicyAssignmentRuleRuleNamespace)(nil)).Elem()
}

func (o WorkloadScalingPolicyAssignmentRuleRuleNamespaceOutput) ToWorkloadScalingPolicyAssignmentRuleRuleNamespaceOutput() WorkloadScalingPolicyAssignmentRuleRuleNamespaceOutput {
	return o
}

func (o WorkloadScalingPolicyAssignmentRuleRuleNamespaceOutput) ToWorkloadScalingPolicyAssignmentRuleRuleNamespaceOutputWithContext(ctx context.Context) WorkloadScalingPolicyAssignmentRuleRuleNamespaceOutput {
	return o
}

func (o WorkloadScalingPolicyAssignmentRuleRuleNamespaceOutput) ToWorkloadScalingPolicyAssignmentRuleRuleNamespacePtrOutput() WorkloadScalingPolicyAssignmentRuleRuleNamespacePtrOutput {
	return o.ToWorkloadScalingPolicyAssignmentRuleRuleNamespacePtrOutputWithContext(context.Background())
}

func (o WorkloadScalingPolicyAssignmentRuleRuleNamespaceOutput) ToWorkloadScalingPolicyAssignmentRuleRuleNamespacePtrOutputWithContext(ctx context.Context) WorkloadScalingPolicyAssignmentRuleRuleNamespacePtrOutput {
	return o.ApplyTWithContext(ctx, func(_ context.Context, v WorkloadScalingPolicyAssignmentRuleRuleNamespace) *WorkloadScalingPolicyAssignmentRuleRuleNamespace {
		return &v
	}).(WorkloadScalingPolicyAssignmentRuleRuleNamespacePtrOutput)
}

// Defines matching by namespace names.
func (o WorkloadScalingPolicyAssignmentRuleRuleNamespaceOutput) Names() pulumi.StringArrayOutput {
	return o.ApplyT(func(v WorkloadScalingPolicyAssignmentRuleRuleNamespace) []string { return v.Names }).(pulumi.StringArrayOutput)
}

type WorkloadScalingPolicyAssignmentRuleRuleNamespacePtrOutput struct{ *pulumi.OutputState }

func (WorkloadScalingPolicyAssignmentRuleRuleNamespacePtrOutput) ElementType() reflect.Type {
	return reflect.TypeOf((**WorkloadScalingPolicyAssignmentRuleRuleNamespace)(nil)).Elem()
}

func (o WorkloadScalingPolicyAssignmentRuleRuleNamespacePtrOutput) ToWorkloadScalingPolicyAssignmentRuleRuleNamespacePtrOutput() WorkloadScalingPolicyAssignmentRuleRuleNamespacePtrOutput {
	return o
}

func (o WorkloadScalingPolicyAssignmentRuleRuleNamespacePtrOutput) ToWorkloadScalingPolicyAssignmentRuleRuleNamespacePtrOutputWithContext(ctx context.Context) WorkloadScalingPolicyAssignmentRuleRuleNamespacePtrOutput {
	return o
}

func (o WorkloadScalingPolicyAssignmentRuleRuleNamespacePtrOutput) Elem() WorkloadScalingPolicyAssignmentRuleRuleNamespaceOutput {
	return o.ApplyT(func(v *WorkloadScalingPolicyAssignmentRuleRuleNamespace) WorkloadScalingPolicyAssignmentRuleRuleNamespace {
		if v != nil {
			return *v
		}
		var ret WorkloadScalingPolicyAssignmentRuleRuleNamespace
		return ret
	}).(WorkloadScalingPolicyAssignmentRuleRuleNamespaceOutput)
}

// Defines matching by namespace names.
func (o WorkloadScalingPolicyAssignmentRuleRuleNamespacePtrOutput) Names() pulumi.StringArrayOutput {
	return o.ApplyT(func(v *WorkloadScalingPolicyAssignmentRuleRuleNamespace) []string {
		if v == nil {
			return nil
		}
		return v.Names
	}).(pulumi.StringArrayOutput)
}

type WorkloadScalingPolicyAssignmentRuleRuleWorkload struct {
	// Group, version, and kind for Kubernetes resources. Format: kind[.version][.group].
	// It can be either:
	//  - only kind, e.g. "Deployment"
	//  - group and kind: e.g."Deployment.apps"
	//  - group, version and kind: e.g."Deployment.v1.apps"
	Gvks []string `pulumi:"gvks"`
	// Defines matching by label selector requirements.
	LabelsExpressions []WorkloadScalingPolicyAssignmentRuleRuleWorkloadLabelsExpression `pulumi:"labelsExpressions"`
}

// WorkloadScalingPolicyAssignmentRuleRuleWorkloadInput is an input type that accepts WorkloadScalingPolicyAssignmentRuleRuleWorkloadArgs and WorkloadScalingPolicyAssignmentRuleRuleWorkloadOutput values.
// You can construct a concrete instance of `WorkloadScalingPolicyAssignmentRuleRuleWorkloadInput` via:
//
//	WorkloadScalingPolicyAssignmentRuleRuleWorkloadArgs{...}
type WorkloadScalingPolicyAssignmentRuleRuleWorkloadInput interface {
	pulumi.Input

	ToWorkloadScalingPolicyAssignmentRuleRuleWorkloadOutput() WorkloadScalingPolicyAssignmentRuleRuleWorkloadOutput
	ToWorkloadScalingPolicyAssignmentRuleRuleWorkloadOutputWithContext(context.Context) WorkloadScalingPolicyAssignmentRuleRuleWorkloadOutput
}

type WorkloadScalingPolicyAssignmentRuleRuleWorkloadArgs struct {
	// Group, version, and kind for Kubernetes resources. Format: kind[.version][.group].
	// It can be either:
	//  - only kind, e.g. "Deployment"
	//  - group and kind: e.g."Deployment.apps"
	//  - group, version and kind: e.g."Deployment.v1.apps"
	Gvks pulumi.StringArrayInput `pulumi:"gvks"`
	// Defines matching by label selector requirements.
	LabelsExpressions WorkloadScalingPolicyAssignmentRuleRuleWorkloadLabelsExpressionArrayInput `pulumi:"labelsExpressions"`
}

func (WorkloadScalingPolicyAssignmentRuleRuleWorkloadArgs) ElementType() reflect.Type {
	return reflect.TypeOf((*WorkloadScalingPolicyAssignmentRuleRuleWorkload)(nil)).Elem()
}

func (i WorkloadScalingPolicyAssignmentRuleRuleWorkloadArgs) ToWorkloadScalingPolicyAssignmentRuleRuleWorkloadOutput() WorkloadScalingPolicyAssignmentRuleRuleWorkloadOutput {
	return i.ToWorkloadScalingPolicyAssignmentRuleRuleWorkloadOutputWithContext(context.Background())
}

func (i WorkloadScalingPolicyAssignmentRuleRuleWorkloadArgs) ToWorkloadScalingPolicyAssignmentRuleRuleWorkloadOutputWithContext(ctx context.Context) WorkloadScalingPolicyAssignmentRuleRuleWorkloadOutput {
	return pulumi.ToOutputWithContext(ctx, i).(WorkloadScalingPolicyAssignmentRuleRuleWorkloadOutput)
}

func (i WorkloadScalingPolicyAssignmentRuleRuleWorkloadArgs) ToWorkloadScalingPolicyAssignmentRuleRuleWorkloadPtrOutput() WorkloadScalingPolicyAssignmentRuleRuleWorkloadPtrOutput {
	return i.ToWorkloadScalingPolicyAssignmentRuleRuleWorkloadPtrOutputWithContext(context.Background())
}

func (i WorkloadScalingPolicyAssignmentRuleRuleWorkloadArgs) ToWorkloadScalingPolicyAssignmentRuleRuleWorkloadPtrOutputWithContext(ctx context.Context) WorkloadScalingPolicyAssignmentRuleRuleWorkloadPtrOutput {
	return pulumi.ToOutputWithContext(ctx, i).(WorkloadScalingPolicyAssignmentRuleRuleWorkloadOutput).ToWorkloadScalingPolicyAssignmentRuleRuleWorkloadPtrOutputWithContext(ctx)
}

// WorkloadScalingPolicyAssignmentRuleRuleWorkloadPtrInput is an input type that accepts WorkloadScalingPolicyAssignmentRuleRuleWorkloadArgs, WorkloadScalingPolicyAssignmentRuleRuleWorkloadPtr and WorkloadScalingPolicyAssignmentRuleRuleWorkloadPtrOutput values.
// You can construct a concrete instance of `WorkloadScalingPolicyAssignmentRuleRuleWorkloadPtrInput` via:
//
//	        WorkloadScalingPolicyAssignmentRuleRuleWorkloadArgs{...}
//
//	or:
//
//	        nil
type WorkloadScalingPolicyAssignmentRuleRuleWorkloadPtrInput interface {
	pulumi.Input

	ToWorkloadScalingPolicyAssignmentRuleRuleWorkloadPtrOutput() WorkloadScalingPolicyAssignmentRuleRuleWorkloadPtrOutput
	ToWorkloadScalingPolicyAssignmentRuleRuleWorkloadPtrOutputWithContext(context.Context) WorkloadScalingPolicyAssignmentRuleRuleWorkloadPtrOutput
}

type workloadScalingPolicyAssignmentRuleRuleWorkloadPtrType WorkloadScalingPolicyAssignmentRuleRuleWorkloadArgs

func WorkloadScalingPolicyAssignmentRuleRuleWorkloadPtr(v *WorkloadScalingPolicyAssignmentRuleRuleWorkloadArgs) WorkloadScalingPolicyAssignmentRuleRuleWorkloadPtrInput {
	return (*workloadScalingPolicyAssignmentRuleRuleWorkloadPtrType)(v)
}

func (*workloadScalingPolicyAssignmentRuleRuleWorkloadPtrType) ElementType() reflect.Type {
	return reflect.TypeOf((**WorkloadScalingPolicyAssignmentRuleRuleWorkload)(nil)).Elem()
}

func (i *workloadScalingPolicyAssignmentRuleRuleWorkloadPtrType) ToWorkloadScalingPolicyAssignmentRuleRuleWorkloadPtrOutput() WorkloadScalingPolicyAssignmentRuleRuleWorkloadPtrOutput {
	return i.ToWorkloadScalingPolicyAssignmentRuleRuleWorkloadPtrOutputWithContext(context.Background())
}

func (i *workloadScalingPolicyAssignmentRuleRuleWorkloadPtrType) ToWorkloadScalingPolicyAssignmentRuleRuleWorkloadPtrOutputWithContext(ctx context.Context) WorkloadScalingPolicyAssignmentRuleRuleWorkloadPtrOutput {
	return pulumi.ToOutputWithContext(ctx, i).(WorkloadScalingPolicyAssignmentRuleRuleWorkloadPtrOutput)
}

type WorkloadScalingPolicyAssignmentRuleRuleWorkloadOutput struct{ *pulumi.OutputState }

func (WorkloadScalingPolicyAssignmentRuleRuleWorkloadOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*WorkloadScalingPolicyAssignmentRuleRuleWorkload)(nil)).Elem()
}

func (o WorkloadScalingPolicyAssignmentRuleRuleWorkloadOutput) ToWorkloadScalingPolicyAssignmentRuleRuleWorkloadOutput() WorkloadScalingPolicyAssignmentRuleRuleWorkloadOutput {
	return o
}

func (o WorkloadScalingPolicyAssignmentRuleRuleWorkloadOutput) ToWorkloadScalingPolicyAssignmentRuleRuleWorkloadOutputWithContext(ctx context.Context) WorkloadScalingPolicyAssignmentRuleRuleWorkloadOutput {
	return o
}

func (o WorkloadScalingPolicyAssignmentRuleRuleWorkloadOutput) ToWorkloadScalingPolicyAssignmentRuleRuleWorkloadPtrOutput() WorkloadScalingPolicyAssignmentRuleRuleWorkloadPtrOutput {
	return o.ToWorkloadScalingPolicyAssignmentRuleRuleWorkloadPtrOutputWithContext(context.Background())
}

func (o WorkloadScalingPolicyAssignmentRuleRuleWorkloadOutput) ToWorkloadScalingPolicyAssignmentRuleRuleWorkloadPtrOutputWithContext(ctx context.Context) WorkloadScalingPolicyAssignmentRuleRuleWorkloadPtrOutput {
	return o.ApplyTWithContext(ctx, func(_ context.Context, v WorkloadScalingPolicyAssignmentRuleRuleWorkload) *WorkloadScalingPolicyAssignmentRuleRuleWorkload {
		return &v
	}).(WorkloadScalingPolicyAssignmentRuleRuleWorkloadPtrOutput)
}

// Group, version, and kind for Kubernetes resources. Format: kind[.version][.group].
// It can be either:
//   - only kind, e.g. "Deployment"
//   - group and kind: e.g."Deployment.apps"
//   - group, version and kind: e.g."Deployment.v1.apps"
func (o WorkloadScalingPolicyAssignmentRuleRuleWorkloadOutput) Gvks() pulumi.StringArrayOutput {
	return o.ApplyT(func(v WorkloadScalingPolicyAssignmentRuleRuleWorkload) []string { return v.Gvks }).(pulumi.StringArrayOutput)
}

// Defines matching by label selector requirements.
func (o WorkloadScalingPolicyAssignmentRuleRuleWorkloadOutput) LabelsExpressions() WorkloadScalingPolicyAssignmentRuleRuleWorkloadLabelsExpressionArrayOutput {
	return o.ApplyT(func(v WorkloadScalingPolicyAssignmentRuleRuleWorkload) []WorkloadScalingPolicyAssignmentRuleRuleWorkloadLabelsExpression {
		return v.LabelsExpressions
	}).(WorkloadScalingPolicyAssignmentRuleRuleWorkloadLabelsExpressionArrayOutput)
}

type WorkloadScalingPolicyAssignmentRuleRuleWorkloadPtrOutput struct{ *pulumi.OutputState }

func (WorkloadScalingPolicyAssignmentRuleRuleWorkloadPtrOutput) ElementType() reflect.Type {
	return reflect.TypeOf((**WorkloadScalingPolicyAssignmentRuleRuleWorkload)(nil)).Elem()
}

func (o WorkloadScalingPolicyAssignmentRuleRuleWorkloadPtrOutput) ToWorkloadScalingPolicyAssignmentRuleRuleWorkloadPtrOutput() WorkloadScalingPolicyAssignmentRuleRuleWorkloadPtrOutput {
	return o
}

func (o WorkloadScalingPolicyAssignmentRuleRuleWorkloadPtrOutput) ToWorkloadScalingPolicyAssignmentRuleRuleWorkloadPtrOutputWithContext(ctx context.Context) WorkloadScalingPolicyAssignmentRuleRuleWorkloadPtrOutput {
	return o
}

func (o WorkloadScalingPolicyAssignmentRuleRuleWorkloadPtrOutput) Elem() WorkloadScalingPolicyAssignmentRuleRuleWorkloadOutput {
	return o.ApplyT(func(v *WorkloadScalingPolicyAssignmentRuleRuleWorkload) WorkloadScalingPolicyAssignmentRuleRuleWorkload {
		if v != nil {
			return *v
		}
		var ret WorkloadScalingPolicyAssignmentRuleRuleWorkload
		return ret
	}).(WorkloadScalingPolicyAssignmentRuleRuleWorkloadOutput)
}

// Group, version, and kind for Kubernetes resources. Format: kind[.version][.group].
// It can be either:
//   - only kind, e.g. "Deployment"
//   - group and kind: e.g."Deployment.apps"
//   - group, version and kind: e.g."Deployment.v1.apps"
func (o WorkloadScalingPolicyAssignmentRuleRuleWorkloadPtrOutput) Gvks() pulumi.StringArrayOutput {
	return o.ApplyT(func(v *WorkloadScalingPolicyAssignmentRuleRuleWorkload) []string {
		if v == nil {
			return nil
		}
		return v.Gvks
	}).(pulumi.StringArrayOutput)
}

// Defines matching by label selector requirements.
func (o WorkloadScalingPolicyAssignmentRuleRuleWorkloadPtrOutput) LabelsExpressions() WorkloadScalingPolicyAssignmentRuleRuleWorkloadLabelsExpressionArrayOutput {
	return o.ApplyT(func(v *WorkloadScalingPolicyAssignmentRuleRuleWorkload) []WorkloadScalingPolicyAssignmentRuleRuleWorkloadLabelsExpression {
		if v == nil {
			return nil
		}
		return v.LabelsExpressions
	}).(WorkloadScalingPolicyAssignmentRuleRuleWorkloadLabelsExpressionArrayOutput)
}

type WorkloadScalingPolicyAssignmentRuleRuleWorkloadLabelsExpression struct {
	// The label key to match. Required for all operators except `Regex` and `Contains`. If not specified, it will search through all labels.
	Key *string `pulumi:"key"`
	// The operator to use for matching the label.
	Operator string `pulumi:"operator"`
	// A list of values to match against the label key. It is required for `In`, `NotIn`, `Regex`, and `Contains` operators.
	Values []string `pulumi:"values"`
}

// WorkloadScalingPolicyAssignmentRuleRuleWorkloadLabelsExpressionInput is an input type that accepts WorkloadScalingPolicyAssignmentRuleRuleWorkloadLabelsExpressionArgs and WorkloadScalingPolicyAssignmentRuleRuleWorkloadLabelsExpressionOutput values.
// You can construct a concrete instance of `WorkloadScalingPolicyAssignmentRuleRuleWorkloadLabelsExpressionInput` via:
//
//	WorkloadScalingPolicyAssignmentRuleRuleWorkloadLabelsExpressionArgs{...}
type WorkloadScalingPolicyAssignmentRuleRuleWorkloadLabelsExpressionInput interface {
	pulumi.Input

	ToWorkloadScalingPolicyAssignmentRuleRuleWorkloadLabelsExpressionOutput() WorkloadScalingPolicyAssignmentRuleRuleWorkloadLabelsExpressionOutput
	ToWorkloadScalingPolicyAssignmentRuleRuleWorkloadLabelsExpressionOutputWithContext(context.Context) WorkloadScalingPolicyAssignmentRuleRuleWorkloadLabelsExpressionOutput
}

type WorkloadScalingPolicyAssignmentRuleRuleWorkloadLabelsExpressionArgs struct {
	// The label key to match. Required for all operators except `Regex` and `Contains`. If not specified, it will search through all labels.
	Key pulumi.StringPtrInput `pulumi:"key"`
	// The operator to use for matching the label.
	Operator pulumi.StringInput `pulumi:"operator"`
	// A list of values to match against the label key. It is required for `In`, `NotIn`, `Regex`, and `Contains` operators.
	Values pulumi.StringArrayInput `pulumi:"values"`
}

func (WorkloadScalingPolicyAssignmentRuleRuleWorkloadLabelsExpressionArgs) ElementType() reflect.Type {
	return reflect.TypeOf((*WorkloadScalingPolicyAssignmentRuleRuleWorkloadLabelsExpression)(nil)).Elem()
}

func (i WorkloadScalingPolicyAssignmentRuleRuleWorkloadLabelsExpressionArgs) ToWorkloadScalingPolicyAssignmentRuleRuleWorkloadLabelsExpressionOutput() WorkloadScalingPolicyAssignmentRuleRuleWorkloadLabelsExpressionOutput {
	return i.ToWorkloadScalingPolicyAssignmentRuleRuleWorkloadLabelsExpressionOutputWithContext(context.Background())
}

func (i WorkloadScalingPolicyAssignmentRuleRuleWorkloadLabelsExpressionArgs) ToWorkloadScalingPolicyAssignmentRuleRuleWorkloadLabelsExpressionOutputWithContext(ctx context.Context) WorkloadScalingPolicyAssignmentRuleRuleWorkloadLabelsExpressionOutput {
	return pulumi.ToOutputWithContext(ctx, i).(WorkloadScalingPolicyAssignmentRuleRuleWorkloadLabelsExpressionOutput)
}

// WorkloadScalingPolicyAssignmentRuleRuleWorkloadLabelsExpressionArrayInput is an input type that accepts WorkloadScalingPolicyAssignmentRuleRuleWorkloadLabelsExpressionArray and WorkloadScalingPolicyAssignmentRuleRuleWorkloadLabelsExpressionArrayOutput values.
// You can construct a concrete instance of `WorkloadScalingPolicyAssignmentRuleRuleWorkloadLabelsExpressionArrayInput` via:
//
//	WorkloadScalingPolicyAssignmentRuleRuleWorkloadLabelsExpressionArray{ WorkloadScalingPolicyAssignmentRuleRuleWorkloadLabelsExpressionArgs{...} }
type WorkloadScalingPolicyAssignmentRuleRuleWorkloadLabelsExpressionArrayInput interface {
	pulumi.Input

	ToWorkloadScalingPolicyAssignmentRuleRuleWorkloadLabelsExpressionArrayOutput() WorkloadScalingPolicyAssignmentRuleRuleWorkloadLabelsExpressionArrayOutput
	ToWorkloadScalingPolicyAssignmentRuleRuleWorkloadLabelsExpressionArrayOutputWithContext(context.Context) WorkloadScalingPolicyAssignmentRuleRuleWorkloadLabelsExpressionArrayOutput
}

type WorkloadScalingPolicyAssignmentRuleRuleWorkloadLabelsExpressionArray []WorkloadScalingPolicyAssignmentRuleRuleWorkloadLabelsExpressionInput

func (WorkloadScalingPolicyAssignmentRuleRuleWorkloadLabelsExpressionArray) ElementType() reflect.Type {
	return reflect.TypeOf((*[]WorkloadScalingPolicyAssignmentRuleRuleWorkloadLabelsExpression)(nil)).Elem()
}

func (i WorkloadScalingPolicyAssignmentRuleRuleWorkloadLabelsExpressionArray) ToWorkloadScalingPolicyAssignmentRuleRuleWorkloadLabelsExpressionArrayOutput() WorkloadScalingPolicyAssignmentRuleRuleWorkloadLabelsExpressionArrayOutput {
	return i.ToWorkloadScalingPolicyAssignmentRuleRuleWorkloadLabelsExpressionArrayOutputWithContext(context.Background())
}

func (i WorkloadScalingPolicyAssignmentRuleRuleWorkloadLabelsExpressionArray) ToWorkloadScalingPolicyAssignmentRuleRuleWorkloadLabelsExpressionArrayOutputWithContext(ctx context.Context) WorkloadScalingPolicyAssignmentRuleRuleWorkloadLabelsExpressionArrayOutput {
	return pulumi.ToOutputWithContext(ctx, i).(WorkloadScalingPolicyAssignmentRuleRuleWorkloadLabelsExpressionArrayOutput)
}

type WorkloadScalingPolicyAssignmentRuleRuleWorkloadLabelsExpressionOutput struct{ *pulumi.OutputState }

func (WorkloadScalingPolicyAssignmentRuleRuleWorkloadLabelsExpressionOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*WorkloadScalingPolicyAssignmentRuleRuleWorkloadLabelsExpression)(nil)).Elem()
}

func (o WorkloadScalingPolicyAssignmentRuleRuleWorkloadLabelsExpressionOutput) ToWorkloadScalingPolicyAssignmentRuleRuleWorkloadLabelsExpressionOutput() WorkloadScalingPolicyAssignmentRuleRuleWorkloadLabelsExpressionOutput {
	return o
}

func (o WorkloadScalingPolicyAssignmentRuleRuleWorkloadLabelsExpressionOutput) ToWorkloadScalingPolicyAssignmentRuleRuleWorkloadLabelsExpressionOutputWithContext(ctx context.Context) WorkloadScalingPolicyAssignmentRuleRuleWorkloadLabelsExpressionOutput {
	return o
}

// The label key to match. Required for all operators except `Regex` and `Contains`. If not specified, it will search through all labels.
func (o WorkloadScalingPolicyAssignmentRuleRuleWorkloadLabelsExpressionOutput) Key() pulumi.StringPtrOutput {
	return o.ApplyT(func(v WorkloadScalingPolicyAssignmentRuleRuleWorkloadLabelsExpression) *string { return v.Key }).(pulumi.StringPtrOutput)
}

// The operator to use for matching the label.
func (o WorkloadScalingPolicyAssignmentRuleRuleWorkloadLabelsExpressionOutput) Operator() pulumi.StringOutput {
	return o.ApplyT(func(v WorkloadScalingPolicyAssignmentRuleRuleWorkloadLabelsExpression) string { return v.Operator }).(pulumi.StringOutput)
}

// A list of values to match against the label key. It is required for `In`, `NotIn`, `Regex`, and `Contains` operators.
func (o WorkloadScalingPolicyAssignmentRuleRuleWorkloadLabelsExpressionOutput) Values() pulumi.StringArrayOutput {
	return o.ApplyT(func(v WorkloadScalingPolicyAssignmentRuleRuleWorkloadLabelsExpression) []string { return v.Values }).(pulumi.StringArrayOutput)
}

type WorkloadScalingPolicyAssignmentRuleRuleWorkloadLabelsExpressionArrayOutput struct{ *pulumi.OutputState }

func (WorkloadScalingPolicyAssignmentRuleRuleWorkloadLabelsExpressionArrayOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*[]WorkloadScalingPolicyAssignmentRuleRuleWorkloadLabelsExpression)(nil)).Elem()
}

func (o WorkloadScalingPolicyAssignmentRuleRuleWorkloadLabelsExpressionArrayOutput) ToWorkloadScalingPolicyAssignmentRuleRuleWorkloadLabelsExpressionArrayOutput() WorkloadScalingPolicyAssignmentRuleRuleWorkloadLabelsExpressionArrayOutput {
	return o
}

func (o WorkloadScalingPolicyAssignmentRuleRuleWorkloadLabelsExpressionArrayOutput) ToWorkloadScalingPolicyAssignmentRuleRuleWorkloadLabelsExpressionArrayOutputWithContext(ctx context.Context) WorkloadScalingPolicyAssignmentRuleRuleWorkloadLabelsExpressionArrayOutput {
	return o
}

func (o WorkloadScalingPolicyAssignmentRuleRuleWorkloadLabelsExpressionArrayOutput) Index(i pulumi.IntInput) WorkloadScalingPolicyAssignmentRuleRuleWorkloadLabelsExpressionOutput {
	return pulumi.All(o, i).ApplyT(func(vs []interface{}) WorkloadScalingPolicyAssignmentRuleRuleWorkloadLabelsExpression {
		return vs[0].([]WorkloadScalingPolicyAssignmentRuleRuleWorkloadLabelsExpression)[vs[1].(int)]
	}).(WorkloadScalingPolicyAssignmentRuleRuleWorkloadLabelsExpressionOutput)
}

type WorkloadScalingPolicyConfidence struct {
	// Defines the confidence threshold for applying recommendations. The smaller number indicates that we require fewer metrics data points to apply recommendations - changing this value can cause applying less precise recommendations. Do not change the default unless you want to optimize with fewer data points (e.g., short-lived workloads).
	Threshold *float64 `pulumi:"threshold"`
}

// WorkloadScalingPolicyConfidenceInput is an input type that accepts WorkloadScalingPolicyConfidenceArgs and WorkloadScalingPolicyConfidenceOutput values.
// You can construct a concrete instance of `WorkloadScalingPolicyConfidenceInput` via:
//
//	WorkloadScalingPolicyConfidenceArgs{...}
type WorkloadScalingPolicyConfidenceInput interface {
	pulumi.Input

	ToWorkloadScalingPolicyConfidenceOutput() WorkloadScalingPolicyConfidenceOutput
	ToWorkloadScalingPolicyConfidenceOutputWithContext(context.Context) WorkloadScalingPolicyConfidenceOutput
}

type WorkloadScalingPolicyConfidenceArgs struct {
	// Defines the confidence threshold for applying recommendations. The smaller number indicates that we require fewer metrics data points to apply recommendations - changing this value can cause applying less precise recommendations. Do not change the default unless you want to optimize with fewer data points (e.g., short-lived workloads).
	Threshold pulumi.Float64PtrInput `pulumi:"threshold"`
}

func (WorkloadScalingPolicyConfidenceArgs) ElementType() reflect.Type {
	return reflect.TypeOf((*WorkloadScalingPolicyConfidence)(nil)).Elem()
}

func (i WorkloadScalingPolicyConfidenceArgs) ToWorkloadScalingPolicyConfidenceOutput() WorkloadScalingPolicyConfidenceOutput {
	return i.ToWorkloadScalingPolicyConfidenceOutputWithContext(context.Background())
}

func (i WorkloadScalingPolicyConfidenceArgs) ToWorkloadScalingPolicyConfidenceOutputWithContext(ctx context.Context) WorkloadScalingPolicyConfidenceOutput {
	return pulumi.ToOutputWithContext(ctx, i).(WorkloadScalingPolicyConfidenceOutput)
}

func (i WorkloadScalingPolicyConfidenceArgs) ToWorkloadScalingPolicyConfidencePtrOutput() WorkloadScalingPolicyConfidencePtrOutput {
	return i.ToWorkloadScalingPolicyConfidencePtrOutputWithContext(context.Background())
}

func (i WorkloadScalingPolicyConfidenceArgs) ToWorkloadScalingPolicyConfidencePtrOutputWithContext(ctx context.Context) WorkloadScalingPolicyConfidencePtrOutput {
	return pulumi.ToOutputWithContext(ctx, i).(WorkloadScalingPolicyConfidenceOutput).ToWorkloadScalingPolicyConfidencePtrOutputWithContext(ctx)
}

// WorkloadScalingPolicyConfidencePtrInput is an input type that accepts WorkloadScalingPolicyConfidenceArgs, WorkloadScalingPolicyConfidencePtr and WorkloadScalingPolicyConfidencePtrOutput values.
// You can construct a concrete instance of `WorkloadScalingPolicyConfidencePtrInput` via:
//
//	        WorkloadScalingPolicyConfidenceArgs{...}
//
//	or:
//
//	        nil
type WorkloadScalingPolicyConfidencePtrInput interface {
	pulumi.Input

	ToWorkloadScalingPolicyConfidencePtrOutput() WorkloadScalingPolicyConfidencePtrOutput
	ToWorkloadScalingPolicyConfidencePtrOutputWithContext(context.Context) WorkloadScalingPolicyConfidencePtrOutput
}

type workloadScalingPolicyConfidencePtrType WorkloadScalingPolicyConfidenceArgs

func WorkloadScalingPolicyConfidencePtr(v *WorkloadScalingPolicyConfidenceArgs) WorkloadScalingPolicyConfidencePtrInput {
	return (*workloadScalingPolicyConfidencePtrType)(v)
}

func (*workloadScalingPolicyConfidencePtrType) ElementType() reflect.Type {
	return reflect.TypeOf((**WorkloadScalingPolicyConfidence)(nil)).Elem()
}

func (i *workloadScalingPolicyConfidencePtrType) ToWorkloadScalingPolicyConfidencePtrOutput() WorkloadScalingPolicyConfidencePtrOutput {
	return i.ToWorkloadScalingPolicyConfidencePtrOutputWithContext(context.Background())
}

func (i *workloadScalingPolicyConfidencePtrType) ToWorkloadScalingPolicyConfidencePtrOutputWithContext(ctx context.Context) WorkloadScalingPolicyConfidencePtrOutput {
	return pulumi.ToOutputWithContext(ctx, i).(WorkloadScalingPolicyConfidencePtrOutput)
}

type WorkloadScalingPolicyConfidenceOutput struct{ *pulumi.OutputState }

func (WorkloadScalingPolicyConfidenceOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*WorkloadScalingPolicyConfidence)(nil)).Elem()
}

func (o WorkloadScalingPolicyConfidenceOutput) ToWorkloadScalingPolicyConfidenceOutput() WorkloadScalingPolicyConfidenceOutput {
	return o
}

func (o WorkloadScalingPolicyConfidenceOutput) ToWorkloadScalingPolicyConfidenceOutputWithContext(ctx context.Context) WorkloadScalingPolicyConfidenceOutput {
	return o
}

func (o WorkloadScalingPolicyConfidenceOutput) ToWorkloadScalingPolicyConfidencePtrOutput() WorkloadScalingPolicyConfidencePtrOutput {
	return o.ToWorkloadScalingPolicyConfidencePtrOutputWithContext(context.Background())
}

func (o WorkloadScalingPolicyConfidenceOutput) ToWorkloadScalingPolicyConfidencePtrOutputWithContext(ctx context.Context) WorkloadScalingPolicyConfidencePtrOutput {
	return o.ApplyTWithContext(ctx, func(_ context.Context, v WorkloadScalingPolicyConfidence) *WorkloadScalingPolicyConfidence {
		return &v
	}).(WorkloadScalingPolicyConfidencePtrOutput)
}

// Defines the confidence threshold for applying recommendations. The smaller number indicates that we require fewer metrics data points to apply recommendations - changing this value can cause applying less precise recommendations. Do not change the default unless you want to optimize with fewer data points (e.g., short-lived workloads).
func (o WorkloadScalingPolicyConfidenceOutput) Threshold() pulumi.Float64PtrOutput {
	return o.ApplyT(func(v WorkloadScalingPolicyConfidence) *float64 { return v.Threshold }).(pulumi.Float64PtrOutput)
}

type WorkloadScalingPolicyConfidencePtrOutput struct{ *pulumi.OutputState }

func (WorkloadScalingPolicyConfidencePtrOutput) ElementType() reflect.Type {
	return reflect.TypeOf((**WorkloadScalingPolicyConfidence)(nil)).Elem()
}

func (o WorkloadScalingPolicyConfidencePtrOutput) ToWorkloadScalingPolicyConfidencePtrOutput() WorkloadScalingPolicyConfidencePtrOutput {
	return o
}

func (o WorkloadScalingPolicyConfidencePtrOutput) ToWorkloadScalingPolicyConfidencePtrOutputWithContext(ctx context.Context) WorkloadScalingPolicyConfidencePtrOutput {
	return o
}

func (o WorkloadScalingPolicyConfidencePtrOutput) Elem() WorkloadScalingPolicyConfidenceOutput {
	return o.ApplyT(func(v *WorkloadScalingPolicyConfidence) WorkloadScalingPolicyConfidence {
		if v != nil {
			return *v
		}
		var ret WorkloadScalingPolicyConfidence
		return ret
	}).(WorkloadScalingPolicyConfidenceOutput)
}

// Defines the confidence threshold for applying recommendations. The smaller number indicates that we require fewer metrics data points to apply recommendations - changing this value can cause applying less precise recommendations. Do not change the default unless you want to optimize with fewer data points (e.g., short-lived workloads).
func (o WorkloadScalingPolicyConfidencePtrOutput) Threshold() pulumi.Float64PtrOutput {
	return o.ApplyT(func(v *WorkloadScalingPolicyConfidence) *float64 {
		if v == nil {
			return nil
		}
		return v.Threshold
	}).(pulumi.Float64PtrOutput)
}

type WorkloadScalingPolicyCpu struct {
	// The threshold of when to apply the recommendation. Recommendation will be applied when diff of current requests and new recommendation is greater than set value
	//
	// Deprecated: Use applyThresholdStrategy instead
	ApplyThreshold *float64 `pulumi:"applyThreshold"`
	// Resource apply threshold strategy settings. The default strategy is `PERCENTAGE` with percentage value set to 0.1.
	ApplyThresholdStrategy *WorkloadScalingPolicyCpuApplyThresholdStrategy `pulumi:"applyThresholdStrategy"`
	// The arguments for the function - i.e. for `QUANTILE` this should be a [0, 1] float. `MAX` doesn't accept any args
	Args *string `pulumi:"args"`
	// The function used to calculate the resource recommendation. Supported values: `QUANTILE`, `MAX`
	Function *string `pulumi:"function"`
	// Resource limit settings
	Limit *WorkloadScalingPolicyCpuLimit `pulumi:"limit"`
	// The look back period in seconds for the recommendation.
	LookBackPeriodSeconds *int `pulumi:"lookBackPeriodSeconds"`
	// Disables management for a single resource when set to `READ_ONLY`. The resource will use its original workload template requests and limits. Supported value: `READ_ONLY`. Minimum required workload-autoscaler version: `v0.23.1`.
	ManagementOption *string `pulumi:"managementOption"`
	// Max values for the recommendation, applies to every container. For memory - this is in MiB, for CPU - this is in cores.
	Max *float64 `pulumi:"max"`
	// Min values for the recommendation, applies to every container. For memory - this is in MiB, for CPU - this is in cores.
	Min *float64 `pulumi:"min"`
	// Overhead for the recommendation, e.g. `0.1` will result in 10% higher recommendation
	Overhead *float64 `pulumi:"overhead"`
}

// WorkloadScalingPolicyCpuInput is an input type that accepts WorkloadScalingPolicyCpuArgs and WorkloadScalingPolicyCpuOutput values.
// You can construct a concrete instance of `WorkloadScalingPolicyCpuInput` via:
//
//	WorkloadScalingPolicyCpuArgs{...}
type WorkloadScalingPolicyCpuInput interface {
	pulumi.Input

	ToWorkloadScalingPolicyCpuOutput() WorkloadScalingPolicyCpuOutput
	ToWorkloadScalingPolicyCpuOutputWithContext(context.Context) WorkloadScalingPolicyCpuOutput
}

type WorkloadScalingPolicyCpuArgs struct {
	// The threshold of when to apply the recommendation. Recommendation will be applied when diff of current requests and new recommendation is greater than set value
	//
	// Deprecated: Use applyThresholdStrategy instead
	ApplyThreshold pulumi.Float64PtrInput `pulumi:"applyThreshold"`
	// Resource apply threshold strategy settings. The default strategy is `PERCENTAGE` with percentage value set to 0.1.
	ApplyThresholdStrategy WorkloadScalingPolicyCpuApplyThresholdStrategyPtrInput `pulumi:"applyThresholdStrategy"`
	// The arguments for the function - i.e. for `QUANTILE` this should be a [0, 1] float. `MAX` doesn't accept any args
	Args pulumi.StringPtrInput `pulumi:"args"`
	// The function used to calculate the resource recommendation. Supported values: `QUANTILE`, `MAX`
	Function pulumi.StringPtrInput `pulumi:"function"`
	// Resource limit settings
	Limit WorkloadScalingPolicyCpuLimitPtrInput `pulumi:"limit"`
	// The look back period in seconds for the recommendation.
	LookBackPeriodSeconds pulumi.IntPtrInput `pulumi:"lookBackPeriodSeconds"`
	// Disables management for a single resource when set to `READ_ONLY`. The resource will use its original workload template requests and limits. Supported value: `READ_ONLY`. Minimum required workload-autoscaler version: `v0.23.1`.
	ManagementOption pulumi.StringPtrInput `pulumi:"managementOption"`
	// Max values for the recommendation, applies to every container. For memory - this is in MiB, for CPU - this is in cores.
	Max pulumi.Float64PtrInput `pulumi:"max"`
	// Min values for the recommendation, applies to every container. For memory - this is in MiB, for CPU - this is in cores.
	Min pulumi.Float64PtrInput `pulumi:"min"`
	// Overhead for the recommendation, e.g. `0.1` will result in 10% higher recommendation
	Overhead pulumi.Float64PtrInput `pulumi:"overhead"`
}

func (WorkloadScalingPolicyCpuArgs) ElementType() reflect.Type {
	return reflect.TypeOf((*WorkloadScalingPolicyCpu)(nil)).Elem()
}

func (i WorkloadScalingPolicyCpuArgs) ToWorkloadScalingPolicyCpuOutput() WorkloadScalingPolicyCpuOutput {
	return i.ToWorkloadScalingPolicyCpuOutputWithContext(context.Background())
}

func (i WorkloadScalingPolicyCpuArgs) ToWorkloadScalingPolicyCpuOutputWithContext(ctx context.Context) WorkloadScalingPolicyCpuOutput {
	return pulumi.ToOutputWithContext(ctx, i).(WorkloadScalingPolicyCpuOutput)
}

func (i WorkloadScalingPolicyCpuArgs) ToWorkloadScalingPolicyCpuPtrOutput() WorkloadScalingPolicyCpuPtrOutput {
	return i.ToWorkloadScalingPolicyCpuPtrOutputWithContext(context.Background())
}

func (i WorkloadScalingPolicyCpuArgs) ToWorkloadScalingPolicyCpuPtrOutputWithContext(ctx context.Context) WorkloadScalingPolicyCpuPtrOutput {
	return pulumi.ToOutputWithContext(ctx, i).(WorkloadScalingPolicyCpuOutput).ToWorkloadScalingPolicyCpuPtrOutputWithContext(ctx)
}

// WorkloadScalingPolicyCpuPtrInput is an input type that accepts WorkloadScalingPolicyCpuArgs, WorkloadScalingPolicyCpuPtr and WorkloadScalingPolicyCpuPtrOutput values.
// You can construct a concrete instance of `WorkloadScalingPolicyCpuPtrInput` via:
//
//	        WorkloadScalingPolicyCpuArgs{...}
//
//	or:
//
//	        nil
type WorkloadScalingPolicyCpuPtrInput interface {
	pulumi.Input

	ToWorkloadScalingPolicyCpuPtrOutput() WorkloadScalingPolicyCpuPtrOutput
	ToWorkloadScalingPolicyCpuPtrOutputWithContext(context.Context) WorkloadScalingPolicyCpuPtrOutput
}

type workloadScalingPolicyCpuPtrType WorkloadScalingPolicyCpuArgs

func WorkloadScalingPolicyCpuPtr(v *WorkloadScalingPolicyCpuArgs) WorkloadScalingPolicyCpuPtrInput {
	return (*workloadScalingPolicyCpuPtrType)(v)
}

func (*workloadScalingPolicyCpuPtrType) ElementType() reflect.Type {
	return reflect.TypeOf((**WorkloadScalingPolicyCpu)(nil)).Elem()
}

func (i *workloadScalingPolicyCpuPtrType) ToWorkloadScalingPolicyCpuPtrOutput() WorkloadScalingPolicyCpuPtrOutput {
	return i.ToWorkloadScalingPolicyCpuPtrOutputWithContext(context.Background())
}

func (i *workloadScalingPolicyCpuPtrType) ToWorkloadScalingPolicyCpuPtrOutputWithContext(ctx context.Context) WorkloadScalingPolicyCpuPtrOutput {
	return pulumi.ToOutputWithContext(ctx, i).(WorkloadScalingPolicyCpuPtrOutput)
}

type WorkloadScalingPolicyCpuOutput struct{ *pulumi.OutputState }

func (WorkloadScalingPolicyCpuOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*WorkloadScalingPolicyCpu)(nil)).Elem()
}

func (o WorkloadScalingPolicyCpuOutput) ToWorkloadScalingPolicyCpuOutput() WorkloadScalingPolicyCpuOutput {
	return o
}

func (o WorkloadScalingPolicyCpuOutput) ToWorkloadScalingPolicyCpuOutputWithContext(ctx context.Context) WorkloadScalingPolicyCpuOutput {
	return o
}

func (o WorkloadScalingPolicyCpuOutput) ToWorkloadScalingPolicyCpuPtrOutput() WorkloadScalingPolicyCpuPtrOutput {
	return o.ToWorkloadScalingPolicyCpuPtrOutputWithContext(context.Background())
}

func (o WorkloadScalingPolicyCpuOutput) ToWorkloadScalingPolicyCpuPtrOutputWithContext(ctx context.Context) WorkloadScalingPolicyCpuPtrOutput {
	return o.ApplyTWithContext(ctx, func(_ context.Context, v WorkloadScalingPolicyCpu) *WorkloadScalingPolicyCpu {
		return &v
	}).(WorkloadScalingPolicyCpuPtrOutput)
}

// The threshold of when to apply the recommendation. Recommendation will be applied when diff of current requests and new recommendation is greater than set value
//
// Deprecated: Use applyThresholdStrategy instead
func (o WorkloadScalingPolicyCpuOutput) ApplyThreshold() pulumi.Float64PtrOutput {
	return o.ApplyT(func(v WorkloadScalingPolicyCpu) *float64 { return v.ApplyThreshold }).(pulumi.Float64PtrOutput)
}

// Resource apply threshold strategy settings. The default strategy is `PERCENTAGE` with percentage value set to 0.1.
func (o WorkloadScalingPolicyCpuOutput) ApplyThresholdStrategy() WorkloadScalingPolicyCpuApplyThresholdStrategyPtrOutput {
	return o.ApplyT(func(v WorkloadScalingPolicyCpu) *WorkloadScalingPolicyCpuApplyThresholdStrategy {
		return v.ApplyThresholdStrategy
	}).(WorkloadScalingPolicyCpuApplyThresholdStrategyPtrOutput)
}

// The arguments for the function - i.e. for `QUANTILE` this should be a [0, 1] float. `MAX` doesn't accept any args
func (o WorkloadScalingPolicyCpuOutput) Args() pulumi.StringPtrOutput {
	return o.ApplyT(func(v WorkloadScalingPolicyCpu) *string { return v.Args }).(pulumi.StringPtrOutput)
}

// The function used to calculate the resource recommendation. Supported values: `QUANTILE`, `MAX`
func (o WorkloadScalingPolicyCpuOutput) Function() pulumi.StringPtrOutput {
	return o.ApplyT(func(v WorkloadScalingPolicyCpu) *string { return v.Function }).(pulumi.StringPtrOutput)
}

// Resource limit settings
func (o WorkloadScalingPolicyCpuOutput) Limit() WorkloadScalingPolicyCpuLimitPtrOutput {
	return o.ApplyT(func(v WorkloadScalingPolicyCpu) *WorkloadScalingPolicyCpuLimit { return v.Limit }).(WorkloadScalingPolicyCpuLimitPtrOutput)
}

// The look back period in seconds for the recommendation.
func (o WorkloadScalingPolicyCpuOutput) LookBackPeriodSeconds() pulumi.IntPtrOutput {
	return o.ApplyT(func(v WorkloadScalingPolicyCpu) *int { return v.LookBackPeriodSeconds }).(pulumi.IntPtrOutput)
}

// Disables management for a single resource when set to `READ_ONLY`. The resource will use its original workload template requests and limits. Supported value: `READ_ONLY`. Minimum required workload-autoscaler version: `v0.23.1`.
func (o WorkloadScalingPolicyCpuOutput) ManagementOption() pulumi.StringPtrOutput {
	return o.ApplyT(func(v WorkloadScalingPolicyCpu) *string { return v.ManagementOption }).(pulumi.StringPtrOutput)
}

// Max values for the recommendation, applies to every container. For memory - this is in MiB, for CPU - this is in cores.
func (o WorkloadScalingPolicyCpuOutput) Max() pulumi.Float64PtrOutput {
	return o.ApplyT(func(v WorkloadScalingPolicyCpu) *float64 { return v.Max }).(pulumi.Float64PtrOutput)
}

// Min values for the recommendation, applies to every container. For memory - this is in MiB, for CPU - this is in cores.
func (o WorkloadScalingPolicyCpuOutput) Min() pulumi.Float64PtrOutput {
	return o.ApplyT(func(v WorkloadScalingPolicyCpu) *float64 { return v.Min }).(pulumi.Float64PtrOutput)
}

// Overhead for the recommendation, e.g. `0.1` will result in 10% higher recommendation
func (o WorkloadScalingPolicyCpuOutput) Overhead() pulumi.Float64PtrOutput {
	return o.ApplyT(func(v WorkloadScalingPolicyCpu) *float64 { return v.Overhead }).(pulumi.Float64PtrOutput)
}

type WorkloadScalingPolicyCpuPtrOutput struct{ *pulumi.OutputState }

func (WorkloadScalingPolicyCpuPtrOutput) ElementType() reflect.Type {
	return reflect.TypeOf((**WorkloadScalingPolicyCpu)(nil)).Elem()
}

func (o WorkloadScalingPolicyCpuPtrOutput) ToWorkloadScalingPolicyCpuPtrOutput() WorkloadScalingPolicyCpuPtrOutput {
	return o
}

func (o WorkloadScalingPolicyCpuPtrOutput) ToWorkloadScalingPolicyCpuPtrOutputWithContext(ctx context.Context) WorkloadScalingPolicyCpuPtrOutput {
	return o
}

func (o WorkloadScalingPolicyCpuPtrOutput) Elem() WorkloadScalingPolicyCpuOutput {
	return o.ApplyT(func(v *WorkloadScalingPolicyCpu) WorkloadScalingPolicyCpu {
		if v != nil {
			return *v
		}
		var ret WorkloadScalingPolicyCpu
		return ret
	}).(WorkloadScalingPolicyCpuOutput)
}

// The threshold of when to apply the recommendation. Recommendation will be applied when diff of current requests and new recommendation is greater than set value
//
// Deprecated: Use applyThresholdStrategy instead
func (o WorkloadScalingPolicyCpuPtrOutput) ApplyThreshold() pulumi.Float64PtrOutput {
	return o.ApplyT(func(v *WorkloadScalingPolicyCpu) *float64 {
		if v == nil {
			return nil
		}
		return v.ApplyThreshold
	}).(pulumi.Float64PtrOutput)
}

// Resource apply threshold strategy settings. The default strategy is `PERCENTAGE` with percentage value set to 0.1.
func (o WorkloadScalingPolicyCpuPtrOutput) ApplyThresholdStrategy() WorkloadScalingPolicyCpuApplyThresholdStrategyPtrOutput {
	return o.ApplyT(func(v *WorkloadScalingPolicyCpu) *WorkloadScalingPolicyCpuApplyThresholdStrategy {
		if v == nil {
			return nil
		}
		return v.ApplyThresholdStrategy
	}).(WorkloadScalingPolicyCpuApplyThresholdStrategyPtrOutput)
}

// The arguments for the function - i.e. for `QUANTILE` this should be a [0, 1] float. `MAX` doesn't accept any args
func (o WorkloadScalingPolicyCpuPtrOutput) Args() pulumi.StringPtrOutput {
	return o.ApplyT(func(v *WorkloadScalingPolicyCpu) *string {
		if v == nil {
			return nil
		}
		return v.Args
	}).(pulumi.StringPtrOutput)
}

// The function used to calculate the resource recommendation. Supported values: `QUANTILE`, `MAX`
func (o WorkloadScalingPolicyCpuPtrOutput) Function() pulumi.StringPtrOutput {
	return o.ApplyT(func(v *WorkloadScalingPolicyCpu) *string {
		if v == nil {
			return nil
		}
		return v.Function
	}).(pulumi.StringPtrOutput)
}

// Resource limit settings
func (o WorkloadScalingPolicyCpuPtrOutput) Limit() WorkloadScalingPolicyCpuLimitPtrOutput {
	return o.ApplyT(func(v *WorkloadScalingPolicyCpu) *WorkloadScalingPolicyCpuLimit {
		if v == nil {
			return nil
		}
		return v.Limit
	}).(WorkloadScalingPolicyCpuLimitPtrOutput)
}

// The look back period in seconds for the recommendation.
func (o WorkloadScalingPolicyCpuPtrOutput) LookBackPeriodSeconds() pulumi.IntPtrOutput {
	return o.ApplyT(func(v *WorkloadScalingPolicyCpu) *int {
		if v == nil {
			return nil
		}
		return v.LookBackPeriodSeconds
	}).(pulumi.IntPtrOutput)
}

// Disables management for a single resource when set to `READ_ONLY`. The resource will use its original workload template requests and limits. Supported value: `READ_ONLY`. Minimum required workload-autoscaler version: `v0.23.1`.
func (o WorkloadScalingPolicyCpuPtrOutput) ManagementOption() pulumi.StringPtrOutput {
	return o.ApplyT(func(v *WorkloadScalingPolicyCpu) *string {
		if v == nil {
			return nil
		}
		return v.ManagementOption
	}).(pulumi.StringPtrOutput)
}

// Max values for the recommendation, applies to every container. For memory - this is in MiB, for CPU - this is in cores.
func (o WorkloadScalingPolicyCpuPtrOutput) Max() pulumi.Float64PtrOutput {
	return o.ApplyT(func(v *WorkloadScalingPolicyCpu) *float64 {
		if v == nil {
			return nil
		}
		return v.Max
	}).(pulumi.Float64PtrOutput)
}

// Min values for the recommendation, applies to every container. For memory - this is in MiB, for CPU - this is in cores.
func (o WorkloadScalingPolicyCpuPtrOutput) Min() pulumi.Float64PtrOutput {
	return o.ApplyT(func(v *WorkloadScalingPolicyCpu) *float64 {
		if v == nil {
			return nil
		}
		return v.Min
	}).(pulumi.Float64PtrOutput)
}

// Overhead for the recommendation, e.g. `0.1` will result in 10% higher recommendation
func (o WorkloadScalingPolicyCpuPtrOutput) Overhead() pulumi.Float64PtrOutput {
	return o.ApplyT(func(v *WorkloadScalingPolicyCpu) *float64 {
		if v == nil {
			return nil
		}
		return v.Overhead
	}).(pulumi.Float64PtrOutput)
}

type WorkloadScalingPolicyCpuApplyThresholdStrategy struct {
	// If denominator is close or equal to 0, the threshold will be much bigger for small values.For example when numerator, exponent is 1 and denominator is 0 the threshold for 0.5 req. CPU will be 200%.It must be defined for the CUSTOM_ADAPTIVE strategy.
	Denominator *string `pulumi:"denominator"`
	// The exponent changes how fast the curve is going down. The smaller value will cause that we won’t pick extremely small number for big resources, for example:
	// 	- if numerator is 0, denominator is 1, and exponent is 1, for 50 CPU we will pick 2% threshold
	// 	- if numerator is 0, denominator is 1, and exponent is 0.8, for 50 CPU we will pick 4.3% threshold
	// 	It must be defined for the CUSTOM_ADAPTIVE strategy.
	Exponent *float64 `pulumi:"exponent"`
	// The numerator affects vertical stretch of function used in adaptive threshold - smaller number will create smaller threshold.It must be defined for the CUSTOM_ADAPTIVE strategy.
	Numerator *float64 `pulumi:"numerator"`
	// Percentage of a how much difference should there be between the current pod requests and the new recommendation. It must be defined for the PERCENTAGE strategy.
	Percentage *float64 `pulumi:"percentage"`
	// Defines apply theshold strategy type.
	// 	- PERCENTAGE - recommendation will be applied when diff of current requests and new recommendation is greater than set value
	//     - DEFAULT_ADAPTIVE - will pick larger threshold percentage for small workloads and smaller percentage for large workloads.
	//     - CUSTOM_ADAPTIVE - works in same way as DEFAULT_ADAPTIVE, but it allows to tweak parameters of adaptive threshold formula: percentage = numerator/(currentRequest + denominator)^exponent. This strategy is for advance use cases, we recommend to use DEFAULT_ADAPTIVE strategy.
	Type string `pulumi:"type"`
}

// WorkloadScalingPolicyCpuApplyThresholdStrategyInput is an input type that accepts WorkloadScalingPolicyCpuApplyThresholdStrategyArgs and WorkloadScalingPolicyCpuApplyThresholdStrategyOutput values.
// You can construct a concrete instance of `WorkloadScalingPolicyCpuApplyThresholdStrategyInput` via:
//
//	WorkloadScalingPolicyCpuApplyThresholdStrategyArgs{...}
type WorkloadScalingPolicyCpuApplyThresholdStrategyInput interface {
	pulumi.Input

	ToWorkloadScalingPolicyCpuApplyThresholdStrategyOutput() WorkloadScalingPolicyCpuApplyThresholdStrategyOutput
	ToWorkloadScalingPolicyCpuApplyThresholdStrategyOutputWithContext(context.Context) WorkloadScalingPolicyCpuApplyThresholdStrategyOutput
}

type WorkloadScalingPolicyCpuApplyThresholdStrategyArgs struct {
	// If denominator is close or equal to 0, the threshold will be much bigger for small values.For example when numerator, exponent is 1 and denominator is 0 the threshold for 0.5 req. CPU will be 200%.It must be defined for the CUSTOM_ADAPTIVE strategy.
	Denominator pulumi.StringPtrInput `pulumi:"denominator"`
	// The exponent changes how fast the curve is going down. The smaller value will cause that we won’t pick extremely small number for big resources, for example:
	// 	- if numerator is 0, denominator is 1, and exponent is 1, for 50 CPU we will pick 2% threshold
	// 	- if numerator is 0, denominator is 1, and exponent is 0.8, for 50 CPU we will pick 4.3% threshold
	// 	It must be defined for the CUSTOM_ADAPTIVE strategy.
	Exponent pulumi.Float64PtrInput `pulumi:"exponent"`
	// The numerator affects vertical stretch of function used in adaptive threshold - smaller number will create smaller threshold.It must be defined for the CUSTOM_ADAPTIVE strategy.
	Numerator pulumi.Float64PtrInput `pulumi:"numerator"`
	// Percentage of a how much difference should there be between the current pod requests and the new recommendation. It must be defined for the PERCENTAGE strategy.
	Percentage pulumi.Float64PtrInput `pulumi:"percentage"`
	// Defines apply theshold strategy type.
	// 	- PERCENTAGE - recommendation will be applied when diff of current requests and new recommendation is greater than set value
	//     - DEFAULT_ADAPTIVE - will pick larger threshold percentage for small workloads and smaller percentage for large workloads.
	//     - CUSTOM_ADAPTIVE - works in same way as DEFAULT_ADAPTIVE, but it allows to tweak parameters of adaptive threshold formula: percentage = numerator/(currentRequest + denominator)^exponent. This strategy is for advance use cases, we recommend to use DEFAULT_ADAPTIVE strategy.
	Type pulumi.StringInput `pulumi:"type"`
}

func (WorkloadScalingPolicyCpuApplyThresholdStrategyArgs) ElementType() reflect.Type {
	return reflect.TypeOf((*WorkloadScalingPolicyCpuApplyThresholdStrategy)(nil)).Elem()
}

func (i WorkloadScalingPolicyCpuApplyThresholdStrategyArgs) ToWorkloadScalingPolicyCpuApplyThresholdStrategyOutput() WorkloadScalingPolicyCpuApplyThresholdStrategyOutput {
	return i.ToWorkloadScalingPolicyCpuApplyThresholdStrategyOutputWithContext(context.Background())
}

func (i WorkloadScalingPolicyCpuApplyThresholdStrategyArgs) ToWorkloadScalingPolicyCpuApplyThresholdStrategyOutputWithContext(ctx context.Context) WorkloadScalingPolicyCpuApplyThresholdStrategyOutput {
	return pulumi.ToOutputWithContext(ctx, i).(WorkloadScalingPolicyCpuApplyThresholdStrategyOutput)
}

func (i WorkloadScalingPolicyCpuApplyThresholdStrategyArgs) ToWorkloadScalingPolicyCpuApplyThresholdStrategyPtrOutput() WorkloadScalingPolicyCpuApplyThresholdStrategyPtrOutput {
	return i.ToWorkloadScalingPolicyCpuApplyThresholdStrategyPtrOutputWithContext(context.Background())
}

func (i WorkloadScalingPolicyCpuApplyThresholdStrategyArgs) ToWorkloadScalingPolicyCpuApplyThresholdStrategyPtrOutputWithContext(ctx context.Context) WorkloadScalingPolicyCpuApplyThresholdStrategyPtrOutput {
	return pulumi.ToOutputWithContext(ctx, i).(WorkloadScalingPolicyCpuApplyThresholdStrategyOutput).ToWorkloadScalingPolicyCpuApplyThresholdStrategyPtrOutputWithContext(ctx)
}

// WorkloadScalingPolicyCpuApplyThresholdStrategyPtrInput is an input type that accepts WorkloadScalingPolicyCpuApplyThresholdStrategyArgs, WorkloadScalingPolicyCpuApplyThresholdStrategyPtr and WorkloadScalingPolicyCpuApplyThresholdStrategyPtrOutput values.
// You can construct a concrete instance of `WorkloadScalingPolicyCpuApplyThresholdStrategyPtrInput` via:
//
//	        WorkloadScalingPolicyCpuApplyThresholdStrategyArgs{...}
//
//	or:
//
//	        nil
type WorkloadScalingPolicyCpuApplyThresholdStrategyPtrInput interface {
	pulumi.Input

	ToWorkloadScalingPolicyCpuApplyThresholdStrategyPtrOutput() WorkloadScalingPolicyCpuApplyThresholdStrategyPtrOutput
	ToWorkloadScalingPolicyCpuApplyThresholdStrategyPtrOutputWithContext(context.Context) WorkloadScalingPolicyCpuApplyThresholdStrategyPtrOutput
}

type workloadScalingPolicyCpuApplyThresholdStrategyPtrType WorkloadScalingPolicyCpuApplyThresholdStrategyArgs

func WorkloadScalingPolicyCpuApplyThresholdStrategyPtr(v *WorkloadScalingPolicyCpuApplyThresholdStrategyArgs) WorkloadScalingPolicyCpuApplyThresholdStrategyPtrInput {
	return (*workloadScalingPolicyCpuApplyThresholdStrategyPtrType)(v)
}

func (*workloadScalingPolicyCpuApplyThresholdStrategyPtrType) ElementType() reflect.Type {
	return reflect.TypeOf((**WorkloadScalingPolicyCpuApplyThresholdStrategy)(nil)).Elem()
}

func (i *workloadScalingPolicyCpuApplyThresholdStrategyPtrType) ToWorkloadScalingPolicyCpuApplyThresholdStrategyPtrOutput() WorkloadScalingPolicyCpuApplyThresholdStrategyPtrOutput {
	return i.ToWorkloadScalingPolicyCpuApplyThresholdStrategyPtrOutputWithContext(context.Background())
}

func (i *workloadScalingPolicyCpuApplyThresholdStrategyPtrType) ToWorkloadScalingPolicyCpuApplyThresholdStrategyPtrOutputWithContext(ctx context.Context) WorkloadScalingPolicyCpuApplyThresholdStrategyPtrOutput {
	return pulumi.ToOutputWithContext(ctx, i).(WorkloadScalingPolicyCpuApplyThresholdStrategyPtrOutput)
}

type WorkloadScalingPolicyCpuApplyThresholdStrategyOutput struct{ *pulumi.OutputState }

func (WorkloadScalingPolicyCpuApplyThresholdStrategyOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*WorkloadScalingPolicyCpuApplyThresholdStrategy)(nil)).Elem()
}

func (o WorkloadScalingPolicyCpuApplyThresholdStrategyOutput) ToWorkloadScalingPolicyCpuApplyThresholdStrategyOutput() WorkloadScalingPolicyCpuApplyThresholdStrategyOutput {
	return o
}

func (o WorkloadScalingPolicyCpuApplyThresholdStrategyOutput) ToWorkloadScalingPolicyCpuApplyThresholdStrategyOutputWithContext(ctx context.Context) WorkloadScalingPolicyCpuApplyThresholdStrategyOutput {
	return o
}

func (o WorkloadScalingPolicyCpuApplyThresholdStrategyOutput) ToWorkloadScalingPolicyCpuApplyThresholdStrategyPtrOutput() WorkloadScalingPolicyCpuApplyThresholdStrategyPtrOutput {
	return o.ToWorkloadScalingPolicyCpuApplyThresholdStrategyPtrOutputWithContext(context.Background())
}

func (o WorkloadScalingPolicyCpuApplyThresholdStrategyOutput) ToWorkloadScalingPolicyCpuApplyThresholdStrategyPtrOutputWithContext(ctx context.Context) WorkloadScalingPolicyCpuApplyThresholdStrategyPtrOutput {
	return o.ApplyTWithContext(ctx, func(_ context.Context, v WorkloadScalingPolicyCpuApplyThresholdStrategy) *WorkloadScalingPolicyCpuApplyThresholdStrategy {
		return &v
	}).(WorkloadScalingPolicyCpuApplyThresholdStrategyPtrOutput)
}

// If denominator is close or equal to 0, the threshold will be much bigger for small values.For example when numerator, exponent is 1 and denominator is 0 the threshold for 0.5 req. CPU will be 200%.It must be defined for the CUSTOM_ADAPTIVE strategy.
func (o WorkloadScalingPolicyCpuApplyThresholdStrategyOutput) Denominator() pulumi.StringPtrOutput {
	return o.ApplyT(func(v WorkloadScalingPolicyCpuApplyThresholdStrategy) *string { return v.Denominator }).(pulumi.StringPtrOutput)
}

// The exponent changes how fast the curve is going down. The smaller value will cause that we won’t pick extremely small number for big resources, for example:
//   - if numerator is 0, denominator is 1, and exponent is 1, for 50 CPU we will pick 2% threshold
//   - if numerator is 0, denominator is 1, and exponent is 0.8, for 50 CPU we will pick 4.3% threshold
//     It must be defined for the CUSTOM_ADAPTIVE strategy.
func (o WorkloadScalingPolicyCpuApplyThresholdStrategyOutput) Exponent() pulumi.Float64PtrOutput {
	return o.ApplyT(func(v WorkloadScalingPolicyCpuApplyThresholdStrategy) *float64 { return v.Exponent }).(pulumi.Float64PtrOutput)
}

// The numerator affects vertical stretch of function used in adaptive threshold - smaller number will create smaller threshold.It must be defined for the CUSTOM_ADAPTIVE strategy.
func (o WorkloadScalingPolicyCpuApplyThresholdStrategyOutput) Numerator() pulumi.Float64PtrOutput {
	return o.ApplyT(func(v WorkloadScalingPolicyCpuApplyThresholdStrategy) *float64 { return v.Numerator }).(pulumi.Float64PtrOutput)
}

// Percentage of a how much difference should there be between the current pod requests and the new recommendation. It must be defined for the PERCENTAGE strategy.
func (o WorkloadScalingPolicyCpuApplyThresholdStrategyOutput) Percentage() pulumi.Float64PtrOutput {
	return o.ApplyT(func(v WorkloadScalingPolicyCpuApplyThresholdStrategy) *float64 { return v.Percentage }).(pulumi.Float64PtrOutput)
}

// Defines apply theshold strategy type.
//   - PERCENTAGE - recommendation will be applied when diff of current requests and new recommendation is greater than set value
//   - DEFAULT_ADAPTIVE - will pick larger threshold percentage for small workloads and smaller percentage for large workloads.
//   - CUSTOM_ADAPTIVE - works in same way as DEFAULT_ADAPTIVE, but it allows to tweak parameters of adaptive threshold formula: percentage = numerator/(currentRequest + denominator)^exponent. This strategy is for advance use cases, we recommend to use DEFAULT_ADAPTIVE strategy.
func (o WorkloadScalingPolicyCpuApplyThresholdStrategyOutput) Type() pulumi.StringOutput {
	return o.ApplyT(func(v WorkloadScalingPolicyCpuApplyThresholdStrategy) string { return v.Type }).(pulumi.StringOutput)
}

type WorkloadScalingPolicyCpuApplyThresholdStrategyPtrOutput struct{ *pulumi.OutputState }

func (WorkloadScalingPolicyCpuApplyThresholdStrategyPtrOutput) ElementType() reflect.Type {
	return reflect.TypeOf((**WorkloadScalingPolicyCpuApplyThresholdStrategy)(nil)).Elem()
}

func (o WorkloadScalingPolicyCpuApplyThresholdStrategyPtrOutput) ToWorkloadScalingPolicyCpuApplyThresholdStrategyPtrOutput() WorkloadScalingPolicyCpuApplyThresholdStrategyPtrOutput {
	return o
}

func (o WorkloadScalingPolicyCpuApplyThresholdStrategyPtrOutput) ToWorkloadScalingPolicyCpuApplyThresholdStrategyPtrOutputWithContext(ctx context.Context) WorkloadScalingPolicyCpuApplyThresholdStrategyPtrOutput {
	return o
}

func (o WorkloadScalingPolicyCpuApplyThresholdStrategyPtrOutput) Elem() WorkloadScalingPolicyCpuApplyThresholdStrategyOutput {
	return o.ApplyT(func(v *WorkloadScalingPolicyCpuApplyThresholdStrategy) WorkloadScalingPolicyCpuApplyThresholdStrategy {
		if v != nil {
			return *v
		}
		var ret WorkloadScalingPolicyCpuApplyThresholdStrategy
		return ret
	}).(WorkloadScalingPolicyCpuApplyThresholdStrategyOutput)
}

// If denominator is close or equal to 0, the threshold will be much bigger for small values.For example when numerator, exponent is 1 and denominator is 0 the threshold for 0.5 req. CPU will be 200%.It must be defined for the CUSTOM_ADAPTIVE strategy.
func (o WorkloadScalingPolicyCpuApplyThresholdStrategyPtrOutput) Denominator() pulumi.StringPtrOutput {
	return o.ApplyT(func(v *WorkloadScalingPolicyCpuApplyThresholdStrategy) *string {
		if v == nil {
			return nil
		}
		return v.Denominator
	}).(pulumi.StringPtrOutput)
}

// The exponent changes how fast the curve is going down. The smaller value will cause that we won’t pick extremely small number for big resources, for example:
//   - if numerator is 0, denominator is 1, and exponent is 1, for 50 CPU we will pick 2% threshold
//   - if numerator is 0, denominator is 1, and exponent is 0.8, for 50 CPU we will pick 4.3% threshold
//     It must be defined for the CUSTOM_ADAPTIVE strategy.
func (o WorkloadScalingPolicyCpuApplyThresholdStrategyPtrOutput) Exponent() pulumi.Float64PtrOutput {
	return o.ApplyT(func(v *WorkloadScalingPolicyCpuApplyThresholdStrategy) *float64 {
		if v == nil {
			return nil
		}
		return v.Exponent
	}).(pulumi.Float64PtrOutput)
}

// The numerator affects vertical stretch of function used in adaptive threshold - smaller number will create smaller threshold.It must be defined for the CUSTOM_ADAPTIVE strategy.
func (o WorkloadScalingPolicyCpuApplyThresholdStrategyPtrOutput) Numerator() pulumi.Float64PtrOutput {
	return o.ApplyT(func(v *WorkloadScalingPolicyCpuApplyThresholdStrategy) *float64 {
		if v == nil {
			return nil
		}
		return v.Numerator
	}).(pulumi.Float64PtrOutput)
}

// Percentage of a how much difference should there be between the current pod requests and the new recommendation. It must be defined for the PERCENTAGE strategy.
func (o WorkloadScalingPolicyCpuApplyThresholdStrategyPtrOutput) Percentage() pulumi.Float64PtrOutput {
	return o.ApplyT(func(v *WorkloadScalingPolicyCpuApplyThresholdStrategy) *float64 {
		if v == nil {
			return nil
		}
		return v.Percentage
	}).(pulumi.Float64PtrOutput)
}

// Defines apply theshold strategy type.
//   - PERCENTAGE - recommendation will be applied when diff of current requests and new recommendation is greater than set value
//   - DEFAULT_ADAPTIVE - will pick larger threshold percentage for small workloads and smaller percentage for large workloads.
//   - CUSTOM_ADAPTIVE - works in same way as DEFAULT_ADAPTIVE, but it allows to tweak parameters of adaptive threshold formula: percentage = numerator/(currentRequest + denominator)^exponent. This strategy is for advance use cases, we recommend to use DEFAULT_ADAPTIVE strategy.
func (o WorkloadScalingPolicyCpuApplyThresholdStrategyPtrOutput) Type() pulumi.StringPtrOutput {
	return o.ApplyT(func(v *WorkloadScalingPolicyCpuApplyThresholdStrategy) *string {
		if v == nil {
			return nil
		}
		return &v.Type
	}).(pulumi.StringPtrOutput)
}

type WorkloadScalingPolicyCpuLimit struct {
	// Multiplier used to calculate the resource limit. It must be defined for the MULTIPLIER strategy.
	Multiplier *float64 `pulumi:"multiplier"`
	// Defines limit strategy type.
	// 	- NO_LIMIT - removes the resource limit even if it was specified in the workload spec.
	// 	- KEEP_LIMITS - keep existing resource limits. While limits provide stability predictability, they may restrict workloads that need to temporarily burst beyond their allocation.
	// 	- MULTIPLIER - used to calculate the resource limit. The final value is determined by multiplying the resource request by the specified factor.
	Type string `pulumi:"type"`
}

// WorkloadScalingPolicyCpuLimitInput is an input type that accepts WorkloadScalingPolicyCpuLimitArgs and WorkloadScalingPolicyCpuLimitOutput values.
// You can construct a concrete instance of `WorkloadScalingPolicyCpuLimitInput` via:
//
//	WorkloadScalingPolicyCpuLimitArgs{...}
type WorkloadScalingPolicyCpuLimitInput interface {
	pulumi.Input

	ToWorkloadScalingPolicyCpuLimitOutput() WorkloadScalingPolicyCpuLimitOutput
	ToWorkloadScalingPolicyCpuLimitOutputWithContext(context.Context) WorkloadScalingPolicyCpuLimitOutput
}

type WorkloadScalingPolicyCpuLimitArgs struct {
	// Multiplier used to calculate the resource limit. It must be defined for the MULTIPLIER strategy.
	Multiplier pulumi.Float64PtrInput `pulumi:"multiplier"`
	// Defines limit strategy type.
	// 	- NO_LIMIT - removes the resource limit even if it was specified in the workload spec.
	// 	- KEEP_LIMITS - keep existing resource limits. While limits provide stability predictability, they may restrict workloads that need to temporarily burst beyond their allocation.
	// 	- MULTIPLIER - used to calculate the resource limit. The final value is determined by multiplying the resource request by the specified factor.
	Type pulumi.StringInput `pulumi:"type"`
}

func (WorkloadScalingPolicyCpuLimitArgs) ElementType() reflect.Type {
	return reflect.TypeOf((*WorkloadScalingPolicyCpuLimit)(nil)).Elem()
}

func (i WorkloadScalingPolicyCpuLimitArgs) ToWorkloadScalingPolicyCpuLimitOutput() WorkloadScalingPolicyCpuLimitOutput {
	return i.ToWorkloadScalingPolicyCpuLimitOutputWithContext(context.Background())
}

func (i WorkloadScalingPolicyCpuLimitArgs) ToWorkloadScalingPolicyCpuLimitOutputWithContext(ctx context.Context) WorkloadScalingPolicyCpuLimitOutput {
	return pulumi.ToOutputWithContext(ctx, i).(WorkloadScalingPolicyCpuLimitOutput)
}

func (i WorkloadScalingPolicyCpuLimitArgs) ToWorkloadScalingPolicyCpuLimitPtrOutput() WorkloadScalingPolicyCpuLimitPtrOutput {
	return i.ToWorkloadScalingPolicyCpuLimitPtrOutputWithContext(context.Background())
}

func (i WorkloadScalingPolicyCpuLimitArgs) ToWorkloadScalingPolicyCpuLimitPtrOutputWithContext(ctx context.Context) WorkloadScalingPolicyCpuLimitPtrOutput {
	return pulumi.ToOutputWithContext(ctx, i).(WorkloadScalingPolicyCpuLimitOutput).ToWorkloadScalingPolicyCpuLimitPtrOutputWithContext(ctx)
}

// WorkloadScalingPolicyCpuLimitPtrInput is an input type that accepts WorkloadScalingPolicyCpuLimitArgs, WorkloadScalingPolicyCpuLimitPtr and WorkloadScalingPolicyCpuLimitPtrOutput values.
// You can construct a concrete instance of `WorkloadScalingPolicyCpuLimitPtrInput` via:
//
//	        WorkloadScalingPolicyCpuLimitArgs{...}
//
//	or:
//
//	        nil
type WorkloadScalingPolicyCpuLimitPtrInput interface {
	pulumi.Input

	ToWorkloadScalingPolicyCpuLimitPtrOutput() WorkloadScalingPolicyCpuLimitPtrOutput
	ToWorkloadScalingPolicyCpuLimitPtrOutputWithContext(context.Context) WorkloadScalingPolicyCpuLimitPtrOutput
}

type workloadScalingPolicyCpuLimitPtrType WorkloadScalingPolicyCpuLimitArgs

func WorkloadScalingPolicyCpuLimitPtr(v *WorkloadScalingPolicyCpuLimitArgs) WorkloadScalingPolicyCpuLimitPtrInput {
	return (*workloadScalingPolicyCpuLimitPtrType)(v)
}

func (*workloadScalingPolicyCpuLimitPtrType) ElementType() reflect.Type {
	return reflect.TypeOf((**WorkloadScalingPolicyCpuLimit)(nil)).Elem()
}

func (i *workloadScalingPolicyCpuLimitPtrType) ToWorkloadScalingPolicyCpuLimitPtrOutput() WorkloadScalingPolicyCpuLimitPtrOutput {
	return i.ToWorkloadScalingPolicyCpuLimitPtrOutputWithContext(context.Background())
}

func (i *workloadScalingPolicyCpuLimitPtrType) ToWorkloadScalingPolicyCpuLimitPtrOutputWithContext(ctx context.Context) WorkloadScalingPolicyCpuLimitPtrOutput {
	return pulumi.ToOutputWithContext(ctx, i).(WorkloadScalingPolicyCpuLimitPtrOutput)
}

type WorkloadScalingPolicyCpuLimitOutput struct{ *pulumi.OutputState }

func (WorkloadScalingPolicyCpuLimitOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*WorkloadScalingPolicyCpuLimit)(nil)).Elem()
}

func (o WorkloadScalingPolicyCpuLimitOutput) ToWorkloadScalingPolicyCpuLimitOutput() WorkloadScalingPolicyCpuLimitOutput {
	return o
}

func (o WorkloadScalingPolicyCpuLimitOutput) ToWorkloadScalingPolicyCpuLimitOutputWithContext(ctx context.Context) WorkloadScalingPolicyCpuLimitOutput {
	return o
}

func (o WorkloadScalingPolicyCpuLimitOutput) ToWorkloadScalingPolicyCpuLimitPtrOutput() WorkloadScalingPolicyCpuLimitPtrOutput {
	return o.ToWorkloadScalingPolicyCpuLimitPtrOutputWithContext(context.Background())
}

func (o WorkloadScalingPolicyCpuLimitOutput) ToWorkloadScalingPolicyCpuLimitPtrOutputWithContext(ctx context.Context) WorkloadScalingPolicyCpuLimitPtrOutput {
	return o.ApplyTWithContext(ctx, func(_ context.Context, v WorkloadScalingPolicyCpuLimit) *WorkloadScalingPolicyCpuLimit {
		return &v
	}).(WorkloadScalingPolicyCpuLimitPtrOutput)
}

// Multiplier used to calculate the resource limit. It must be defined for the MULTIPLIER strategy.
func (o WorkloadScalingPolicyCpuLimitOutput) Multiplier() pulumi.Float64PtrOutput {
	return o.ApplyT(func(v WorkloadScalingPolicyCpuLimit) *float64 { return v.Multiplier }).(pulumi.Float64PtrOutput)
}

// Defines limit strategy type.
//   - NO_LIMIT - removes the resource limit even if it was specified in the workload spec.
//   - KEEP_LIMITS - keep existing resource limits. While limits provide stability predictability, they may restrict workloads that need to temporarily burst beyond their allocation.
//   - MULTIPLIER - used to calculate the resource limit. The final value is determined by multiplying the resource request by the specified factor.
func (o WorkloadScalingPolicyCpuLimitOutput) Type() pulumi.StringOutput {
	return o.ApplyT(func(v WorkloadScalingPolicyCpuLimit) string { return v.Type }).(pulumi.StringOutput)
}

type WorkloadScalingPolicyCpuLimitPtrOutput struct{ *pulumi.OutputState }

func (WorkloadScalingPolicyCpuLimitPtrOutput) ElementType() reflect.Type {
	return reflect.TypeOf((**WorkloadScalingPolicyCpuLimit)(nil)).Elem()
}

func (o WorkloadScalingPolicyCpuLimitPtrOutput) ToWorkloadScalingPolicyCpuLimitPtrOutput() WorkloadScalingPolicyCpuLimitPtrOutput {
	return o
}

func (o WorkloadScalingPolicyCpuLimitPtrOutput) ToWorkloadScalingPolicyCpuLimitPtrOutputWithContext(ctx context.Context) WorkloadScalingPolicyCpuLimitPtrOutput {
	return o
}

func (o WorkloadScalingPolicyCpuLimitPtrOutput) Elem() WorkloadScalingPolicyCpuLimitOutput {
	return o.ApplyT(func(v *WorkloadScalingPolicyCpuLimit) WorkloadScalingPolicyCpuLimit {
		if v != nil {
			return *v
		}
		var ret WorkloadScalingPolicyCpuLimit
		return ret
	}).(WorkloadScalingPolicyCpuLimitOutput)
}

// Multiplier used to calculate the resource limit. It must be defined for the MULTIPLIER strategy.
func (o WorkloadScalingPolicyCpuLimitPtrOutput) Multiplier() pulumi.Float64PtrOutput {
	return o.ApplyT(func(v *WorkloadScalingPolicyCpuLimit) *float64 {
		if v == nil {
			return nil
		}
		return v.Multiplier
	}).(pulumi.Float64PtrOutput)
}

// Defines limit strategy type.
//   - NO_LIMIT - removes the resource limit even if it was specified in the workload spec.
//   - KEEP_LIMITS - keep existing resource limits. While limits provide stability predictability, they may restrict workloads that need to temporarily burst beyond their allocation.
//   - MULTIPLIER - used to calculate the resource limit. The final value is determined by multiplying the resource request by the specified factor.
func (o WorkloadScalingPolicyCpuLimitPtrOutput) Type() pulumi.StringPtrOutput {
	return o.ApplyT(func(v *WorkloadScalingPolicyCpuLimit) *string {
		if v == nil {
			return nil
		}
		return &v.Type
	}).(pulumi.StringPtrOutput)
}

type WorkloadScalingPolicyDownscaling struct {
	// Defines the apply type to be used when downscaling.
	// 	- IMMEDIATE - pods are restarted immediately when new recommendation is generated.
	// 	- DEFERRED - pods are not restarted and recommendation values are applied during natural restarts only (new deployment, etc.)
	ApplyType *string `pulumi:"applyType"`
}

// WorkloadScalingPolicyDownscalingInput is an input type that accepts WorkloadScalingPolicyDownscalingArgs and WorkloadScalingPolicyDownscalingOutput values.
// You can construct a concrete instance of `WorkloadScalingPolicyDownscalingInput` via:
//
//	WorkloadScalingPolicyDownscalingArgs{...}
type WorkloadScalingPolicyDownscalingInput interface {
	pulumi.Input

	ToWorkloadScalingPolicyDownscalingOutput() WorkloadScalingPolicyDownscalingOutput
	ToWorkloadScalingPolicyDownscalingOutputWithContext(context.Context) WorkloadScalingPolicyDownscalingOutput
}

type WorkloadScalingPolicyDownscalingArgs struct {
	// Defines the apply type to be used when downscaling.
	// 	- IMMEDIATE - pods are restarted immediately when new recommendation is generated.
	// 	- DEFERRED - pods are not restarted and recommendation values are applied during natural restarts only (new deployment, etc.)
	ApplyType pulumi.StringPtrInput `pulumi:"applyType"`
}

func (WorkloadScalingPolicyDownscalingArgs) ElementType() reflect.Type {
	return reflect.TypeOf((*WorkloadScalingPolicyDownscaling)(nil)).Elem()
}

func (i WorkloadScalingPolicyDownscalingArgs) ToWorkloadScalingPolicyDownscalingOutput() WorkloadScalingPolicyDownscalingOutput {
	return i.ToWorkloadScalingPolicyDownscalingOutputWithContext(context.Background())
}

func (i WorkloadScalingPolicyDownscalingArgs) ToWorkloadScalingPolicyDownscalingOutputWithContext(ctx context.Context) WorkloadScalingPolicyDownscalingOutput {
	return pulumi.ToOutputWithContext(ctx, i).(WorkloadScalingPolicyDownscalingOutput)
}

func (i WorkloadScalingPolicyDownscalingArgs) ToWorkloadScalingPolicyDownscalingPtrOutput() WorkloadScalingPolicyDownscalingPtrOutput {
	return i.ToWorkloadScalingPolicyDownscalingPtrOutputWithContext(context.Background())
}

func (i WorkloadScalingPolicyDownscalingArgs) ToWorkloadScalingPolicyDownscalingPtrOutputWithContext(ctx context.Context) WorkloadScalingPolicyDownscalingPtrOutput {
	return pulumi.ToOutputWithContext(ctx, i).(WorkloadScalingPolicyDownscalingOutput).ToWorkloadScalingPolicyDownscalingPtrOutputWithContext(ctx)
}

// WorkloadScalingPolicyDownscalingPtrInput is an input type that accepts WorkloadScalingPolicyDownscalingArgs, WorkloadScalingPolicyDownscalingPtr and WorkloadScalingPolicyDownscalingPtrOutput values.
// You can construct a concrete instance of `WorkloadScalingPolicyDownscalingPtrInput` via:
//
//	        WorkloadScalingPolicyDownscalingArgs{...}
//
//	or:
//
//	        nil
type WorkloadScalingPolicyDownscalingPtrInput interface {
	pulumi.Input

	ToWorkloadScalingPolicyDownscalingPtrOutput() WorkloadScalingPolicyDownscalingPtrOutput
	ToWorkloadScalingPolicyDownscalingPtrOutputWithContext(context.Context) WorkloadScalingPolicyDownscalingPtrOutput
}

type workloadScalingPolicyDownscalingPtrType WorkloadScalingPolicyDownscalingArgs

func WorkloadScalingPolicyDownscalingPtr(v *WorkloadScalingPolicyDownscalingArgs) WorkloadScalingPolicyDownscalingPtrInput {
	return (*workloadScalingPolicyDownscalingPtrType)(v)
}

func (*workloadScalingPolicyDownscalingPtrType) ElementType() reflect.Type {
	return reflect.TypeOf((**WorkloadScalingPolicyDownscaling)(nil)).Elem()
}

func (i *workloadScalingPolicyDownscalingPtrType) ToWorkloadScalingPolicyDownscalingPtrOutput() WorkloadScalingPolicyDownscalingPtrOutput {
	return i.ToWorkloadScalingPolicyDownscalingPtrOutputWithContext(context.Background())
}

func (i *workloadScalingPolicyDownscalingPtrType) ToWorkloadScalingPolicyDownscalingPtrOutputWithContext(ctx context.Context) WorkloadScalingPolicyDownscalingPtrOutput {
	return pulumi.ToOutputWithContext(ctx, i).(WorkloadScalingPolicyDownscalingPtrOutput)
}

type WorkloadScalingPolicyDownscalingOutput struct{ *pulumi.OutputState }

func (WorkloadScalingPolicyDownscalingOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*WorkloadScalingPolicyDownscaling)(nil)).Elem()
}

func (o WorkloadScalingPolicyDownscalingOutput) ToWorkloadScalingPolicyDownscalingOutput() WorkloadScalingPolicyDownscalingOutput {
	return o
}

func (o WorkloadScalingPolicyDownscalingOutput) ToWorkloadScalingPolicyDownscalingOutputWithContext(ctx context.Context) WorkloadScalingPolicyDownscalingOutput {
	return o
}

func (o WorkloadScalingPolicyDownscalingOutput) ToWorkloadScalingPolicyDownscalingPtrOutput() WorkloadScalingPolicyDownscalingPtrOutput {
	return o.ToWorkloadScalingPolicyDownscalingPtrOutputWithContext(context.Background())
}

func (o WorkloadScalingPolicyDownscalingOutput) ToWorkloadScalingPolicyDownscalingPtrOutputWithContext(ctx context.Context) WorkloadScalingPolicyDownscalingPtrOutput {
	return o.ApplyTWithContext(ctx, func(_ context.Context, v WorkloadScalingPolicyDownscaling) *WorkloadScalingPolicyDownscaling {
		return &v
	}).(WorkloadScalingPolicyDownscalingPtrOutput)
}

// Defines the apply type to be used when downscaling.
//   - IMMEDIATE - pods are restarted immediately when new recommendation is generated.
//   - DEFERRED - pods are not restarted and recommendation values are applied during natural restarts only (new deployment, etc.)
func (o WorkloadScalingPolicyDownscalingOutput) ApplyType() pulumi.StringPtrOutput {
	return o.ApplyT(func(v WorkloadScalingPolicyDownscaling) *string { return v.ApplyType }).(pulumi.StringPtrOutput)
}

type WorkloadScalingPolicyDownscalingPtrOutput struct{ *pulumi.OutputState }

func (WorkloadScalingPolicyDownscalingPtrOutput) ElementType() reflect.Type {
	return reflect.TypeOf((**WorkloadScalingPolicyDownscaling)(nil)).Elem()
}

func (o WorkloadScalingPolicyDownscalingPtrOutput) ToWorkloadScalingPolicyDownscalingPtrOutput() WorkloadScalingPolicyDownscalingPtrOutput {
	return o
}

func (o WorkloadScalingPolicyDownscalingPtrOutput) ToWorkloadScalingPolicyDownscalingPtrOutputWithContext(ctx context.Context) WorkloadScalingPolicyDownscalingPtrOutput {
	return o
}

func (o WorkloadScalingPolicyDownscalingPtrOutput) Elem() WorkloadScalingPolicyDownscalingOutput {
	return o.ApplyT(func(v *WorkloadScalingPolicyDownscaling) WorkloadScalingPolicyDownscaling {
		if v != nil {
			return *v
		}
		var ret WorkloadScalingPolicyDownscaling
		return ret
	}).(WorkloadScalingPolicyDownscalingOutput)
}

// Defines the apply type to be used when downscaling.
//   - IMMEDIATE - pods are restarted immediately when new recommendation is generated.
//   - DEFERRED - pods are not restarted and recommendation values are applied during natural restarts only (new deployment, etc.)
func (o WorkloadScalingPolicyDownscalingPtrOutput) ApplyType() pulumi.StringPtrOutput {
	return o.ApplyT(func(v *WorkloadScalingPolicyDownscaling) *string {
		if v == nil {
			return nil
		}
		return v.ApplyType
	}).(pulumi.StringPtrOutput)
}

type WorkloadScalingPolicyMemory struct {
	// The threshold of when to apply the recommendation. Recommendation will be applied when diff of current requests and new recommendation is greater than set value
	//
	// Deprecated: Use applyThresholdStrategy instead
	ApplyThreshold *float64 `pulumi:"applyThreshold"`
	// Resource apply threshold strategy settings. The default strategy is `PERCENTAGE` with percentage value set to 0.1.
	ApplyThresholdStrategy *WorkloadScalingPolicyMemoryApplyThresholdStrategy `pulumi:"applyThresholdStrategy"`
	// The arguments for the function - i.e. for `QUANTILE` this should be a [0, 1] float. `MAX` doesn't accept any args
	Args *string `pulumi:"args"`
	// The function used to calculate the resource recommendation. Supported values: `QUANTILE`, `MAX`
	Function *string `pulumi:"function"`
	// Resource limit settings
	Limit *WorkloadScalingPolicyMemoryLimit `pulumi:"limit"`
	// The look back period in seconds for the recommendation.
	LookBackPeriodSeconds *int `pulumi:"lookBackPeriodSeconds"`
	// Disables management for a single resource when set to `READ_ONLY`. The resource will use its original workload template requests and limits. Supported value: `READ_ONLY`. Minimum required workload-autoscaler version: `v0.23.1`.
	ManagementOption *string `pulumi:"managementOption"`
	// Max values for the recommendation, applies to every container. For memory - this is in MiB, for CPU - this is in cores.
	Max *float64 `pulumi:"max"`
	// Min values for the recommendation, applies to every container. For memory - this is in MiB, for CPU - this is in cores.
	Min *float64 `pulumi:"min"`
	// Overhead for the recommendation, e.g. `0.1` will result in 10% higher recommendation
	Overhead *float64 `pulumi:"overhead"`
}

// WorkloadScalingPolicyMemoryInput is an input type that accepts WorkloadScalingPolicyMemoryArgs and WorkloadScalingPolicyMemoryOutput values.
// You can construct a concrete instance of `WorkloadScalingPolicyMemoryInput` via:
//
//	WorkloadScalingPolicyMemoryArgs{...}
type WorkloadScalingPolicyMemoryInput interface {
	pulumi.Input

	ToWorkloadScalingPolicyMemoryOutput() WorkloadScalingPolicyMemoryOutput
	ToWorkloadScalingPolicyMemoryOutputWithContext(context.Context) WorkloadScalingPolicyMemoryOutput
}

type WorkloadScalingPolicyMemoryArgs struct {
	// The threshold of when to apply the recommendation. Recommendation will be applied when diff of current requests and new recommendation is greater than set value
	//
	// Deprecated: Use applyThresholdStrategy instead
	ApplyThreshold pulumi.Float64PtrInput `pulumi:"applyThreshold"`
	// Resource apply threshold strategy settings. The default strategy is `PERCENTAGE` with percentage value set to 0.1.
	ApplyThresholdStrategy WorkloadScalingPolicyMemoryApplyThresholdStrategyPtrInput `pulumi:"applyThresholdStrategy"`
	// The arguments for the function - i.e. for `QUANTILE` this should be a [0, 1] float. `MAX` doesn't accept any args
	Args pulumi.StringPtrInput `pulumi:"args"`
	// The function used to calculate the resource recommendation. Supported values: `QUANTILE`, `MAX`
	Function pulumi.StringPtrInput `pulumi:"function"`
	// Resource limit settings
	Limit WorkloadScalingPolicyMemoryLimitPtrInput `pulumi:"limit"`
	// The look back period in seconds for the recommendation.
	LookBackPeriodSeconds pulumi.IntPtrInput `pulumi:"lookBackPeriodSeconds"`
	// Disables management for a single resource when set to `READ_ONLY`. The resource will use its original workload template requests and limits. Supported value: `READ_ONLY`. Minimum required workload-autoscaler version: `v0.23.1`.
	ManagementOption pulumi.StringPtrInput `pulumi:"managementOption"`
	// Max values for the recommendation, applies to every container. For memory - this is in MiB, for CPU - this is in cores.
	Max pulumi.Float64PtrInput `pulumi:"max"`
	// Min values for the recommendation, applies to every container. For memory - this is in MiB, for CPU - this is in cores.
	Min pulumi.Float64PtrInput `pulumi:"min"`
	// Overhead for the recommendation, e.g. `0.1` will result in 10% higher recommendation
	Overhead pulumi.Float64PtrInput `pulumi:"overhead"`
}

func (WorkloadScalingPolicyMemoryArgs) ElementType() reflect.Type {
	return reflect.TypeOf((*WorkloadScalingPolicyMemory)(nil)).Elem()
}

func (i WorkloadScalingPolicyMemoryArgs) ToWorkloadScalingPolicyMemoryOutput() WorkloadScalingPolicyMemoryOutput {
	return i.ToWorkloadScalingPolicyMemoryOutputWithContext(context.Background())
}

func (i WorkloadScalingPolicyMemoryArgs) ToWorkloadScalingPolicyMemoryOutputWithContext(ctx context.Context) WorkloadScalingPolicyMemoryOutput {
	return pulumi.ToOutputWithContext(ctx, i).(WorkloadScalingPolicyMemoryOutput)
}

func (i WorkloadScalingPolicyMemoryArgs) ToWorkloadScalingPolicyMemoryPtrOutput() WorkloadScalingPolicyMemoryPtrOutput {
	return i.ToWorkloadScalingPolicyMemoryPtrOutputWithContext(context.Background())
}

func (i WorkloadScalingPolicyMemoryArgs) ToWorkloadScalingPolicyMemoryPtrOutputWithContext(ctx context.Context) WorkloadScalingPolicyMemoryPtrOutput {
	return pulumi.ToOutputWithContext(ctx, i).(WorkloadScalingPolicyMemoryOutput).ToWorkloadScalingPolicyMemoryPtrOutputWithContext(ctx)
}

// WorkloadScalingPolicyMemoryPtrInput is an input type that accepts WorkloadScalingPolicyMemoryArgs, WorkloadScalingPolicyMemoryPtr and WorkloadScalingPolicyMemoryPtrOutput values.
// You can construct a concrete instance of `WorkloadScalingPolicyMemoryPtrInput` via:
//
//	        WorkloadScalingPolicyMemoryArgs{...}
//
//	or:
//
//	        nil
type WorkloadScalingPolicyMemoryPtrInput interface {
	pulumi.Input

	ToWorkloadScalingPolicyMemoryPtrOutput() WorkloadScalingPolicyMemoryPtrOutput
	ToWorkloadScalingPolicyMemoryPtrOutputWithContext(context.Context) WorkloadScalingPolicyMemoryPtrOutput
}

type workloadScalingPolicyMemoryPtrType WorkloadScalingPolicyMemoryArgs

func WorkloadScalingPolicyMemoryPtr(v *WorkloadScalingPolicyMemoryArgs) WorkloadScalingPolicyMemoryPtrInput {
	return (*workloadScalingPolicyMemoryPtrType)(v)
}

func (*workloadScalingPolicyMemoryPtrType) ElementType() reflect.Type {
	return reflect.TypeOf((**WorkloadScalingPolicyMemory)(nil)).Elem()
}

func (i *workloadScalingPolicyMemoryPtrType) ToWorkloadScalingPolicyMemoryPtrOutput() WorkloadScalingPolicyMemoryPtrOutput {
	return i.ToWorkloadScalingPolicyMemoryPtrOutputWithContext(context.Background())
}

func (i *workloadScalingPolicyMemoryPtrType) ToWorkloadScalingPolicyMemoryPtrOutputWithContext(ctx context.Context) WorkloadScalingPolicyMemoryPtrOutput {
	return pulumi.ToOutputWithContext(ctx, i).(WorkloadScalingPolicyMemoryPtrOutput)
}

type WorkloadScalingPolicyMemoryOutput struct{ *pulumi.OutputState }

func (WorkloadScalingPolicyMemoryOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*WorkloadScalingPolicyMemory)(nil)).Elem()
}

func (o WorkloadScalingPolicyMemoryOutput) ToWorkloadScalingPolicyMemoryOutput() WorkloadScalingPolicyMemoryOutput {
	return o
}

func (o WorkloadScalingPolicyMemoryOutput) ToWorkloadScalingPolicyMemoryOutputWithContext(ctx context.Context) WorkloadScalingPolicyMemoryOutput {
	return o
}

func (o WorkloadScalingPolicyMemoryOutput) ToWorkloadScalingPolicyMemoryPtrOutput() WorkloadScalingPolicyMemoryPtrOutput {
	return o.ToWorkloadScalingPolicyMemoryPtrOutputWithContext(context.Background())
}

func (o WorkloadScalingPolicyMemoryOutput) ToWorkloadScalingPolicyMemoryPtrOutputWithContext(ctx context.Context) WorkloadScalingPolicyMemoryPtrOutput {
	return o.ApplyTWithContext(ctx, func(_ context.Context, v WorkloadScalingPolicyMemory) *WorkloadScalingPolicyMemory {
		return &v
	}).(WorkloadScalingPolicyMemoryPtrOutput)
}

// The threshold of when to apply the recommendation. Recommendation will be applied when diff of current requests and new recommendation is greater than set value
//
// Deprecated: Use applyThresholdStrategy instead
func (o WorkloadScalingPolicyMemoryOutput) ApplyThreshold() pulumi.Float64PtrOutput {
	return o.ApplyT(func(v WorkloadScalingPolicyMemory) *float64 { return v.ApplyThreshold }).(pulumi.Float64PtrOutput)
}

// Resource apply threshold strategy settings. The default strategy is `PERCENTAGE` with percentage value set to 0.1.
func (o WorkloadScalingPolicyMemoryOutput) ApplyThresholdStrategy() WorkloadScalingPolicyMemoryApplyThresholdStrategyPtrOutput {
	return o.ApplyT(func(v WorkloadScalingPolicyMemory) *WorkloadScalingPolicyMemoryApplyThresholdStrategy {
		return v.ApplyThresholdStrategy
	}).(WorkloadScalingPolicyMemoryApplyThresholdStrategyPtrOutput)
}

// The arguments for the function - i.e. for `QUANTILE` this should be a [0, 1] float. `MAX` doesn't accept any args
func (o WorkloadScalingPolicyMemoryOutput) Args() pulumi.StringPtrOutput {
	return o.ApplyT(func(v WorkloadScalingPolicyMemory) *string { return v.Args }).(pulumi.StringPtrOutput)
}

// The function used to calculate the resource recommendation. Supported values: `QUANTILE`, `MAX`
func (o WorkloadScalingPolicyMemoryOutput) Function() pulumi.StringPtrOutput {
	return o.ApplyT(func(v WorkloadScalingPolicyMemory) *string { return v.Function }).(pulumi.StringPtrOutput)
}

// Resource limit settings
func (o WorkloadScalingPolicyMemoryOutput) Limit() WorkloadScalingPolicyMemoryLimitPtrOutput {
	return o.ApplyT(func(v WorkloadScalingPolicyMemory) *WorkloadScalingPolicyMemoryLimit { return v.Limit }).(WorkloadScalingPolicyMemoryLimitPtrOutput)
}

// The look back period in seconds for the recommendation.
func (o WorkloadScalingPolicyMemoryOutput) LookBackPeriodSeconds() pulumi.IntPtrOutput {
	return o.ApplyT(func(v WorkloadScalingPolicyMemory) *int { return v.LookBackPeriodSeconds }).(pulumi.IntPtrOutput)
}

// Disables management for a single resource when set to `READ_ONLY`. The resource will use its original workload template requests and limits. Supported value: `READ_ONLY`. Minimum required workload-autoscaler version: `v0.23.1`.
func (o WorkloadScalingPolicyMemoryOutput) ManagementOption() pulumi.StringPtrOutput {
	return o.ApplyT(func(v WorkloadScalingPolicyMemory) *string { return v.ManagementOption }).(pulumi.StringPtrOutput)
}

// Max values for the recommendation, applies to every container. For memory - this is in MiB, for CPU - this is in cores.
func (o WorkloadScalingPolicyMemoryOutput) Max() pulumi.Float64PtrOutput {
	return o.ApplyT(func(v WorkloadScalingPolicyMemory) *float64 { return v.Max }).(pulumi.Float64PtrOutput)
}

// Min values for the recommendation, applies to every container. For memory - this is in MiB, for CPU - this is in cores.
func (o WorkloadScalingPolicyMemoryOutput) Min() pulumi.Float64PtrOutput {
	return o.ApplyT(func(v WorkloadScalingPolicyMemory) *float64 { return v.Min }).(pulumi.Float64PtrOutput)
}

// Overhead for the recommendation, e.g. `0.1` will result in 10% higher recommendation
func (o WorkloadScalingPolicyMemoryOutput) Overhead() pulumi.Float64PtrOutput {
	return o.ApplyT(func(v WorkloadScalingPolicyMemory) *float64 { return v.Overhead }).(pulumi.Float64PtrOutput)
}

type WorkloadScalingPolicyMemoryPtrOutput struct{ *pulumi.OutputState }

func (WorkloadScalingPolicyMemoryPtrOutput) ElementType() reflect.Type {
	return reflect.TypeOf((**WorkloadScalingPolicyMemory)(nil)).Elem()
}

func (o WorkloadScalingPolicyMemoryPtrOutput) ToWorkloadScalingPolicyMemoryPtrOutput() WorkloadScalingPolicyMemoryPtrOutput {
	return o
}

func (o WorkloadScalingPolicyMemoryPtrOutput) ToWorkloadScalingPolicyMemoryPtrOutputWithContext(ctx context.Context) WorkloadScalingPolicyMemoryPtrOutput {
	return o
}

func (o WorkloadScalingPolicyMemoryPtrOutput) Elem() WorkloadScalingPolicyMemoryOutput {
	return o.ApplyT(func(v *WorkloadScalingPolicyMemory) WorkloadScalingPolicyMemory {
		if v != nil {
			return *v
		}
		var ret WorkloadScalingPolicyMemory
		return ret
	}).(WorkloadScalingPolicyMemoryOutput)
}

// The threshold of when to apply the recommendation. Recommendation will be applied when diff of current requests and new recommendation is greater than set value
//
// Deprecated: Use applyThresholdStrategy instead
func (o WorkloadScalingPolicyMemoryPtrOutput) ApplyThreshold() pulumi.Float64PtrOutput {
	return o.ApplyT(func(v *WorkloadScalingPolicyMemory) *float64 {
		if v == nil {
			return nil
		}
		return v.ApplyThreshold
	}).(pulumi.Float64PtrOutput)
}

// Resource apply threshold strategy settings. The default strategy is `PERCENTAGE` with percentage value set to 0.1.
func (o WorkloadScalingPolicyMemoryPtrOutput) ApplyThresholdStrategy() WorkloadScalingPolicyMemoryApplyThresholdStrategyPtrOutput {
	return o.ApplyT(func(v *WorkloadScalingPolicyMemory) *WorkloadScalingPolicyMemoryApplyThresholdStrategy {
		if v == nil {
			return nil
		}
		return v.ApplyThresholdStrategy
	}).(WorkloadScalingPolicyMemoryApplyThresholdStrategyPtrOutput)
}

// The arguments for the function - i.e. for `QUANTILE` this should be a [0, 1] float. `MAX` doesn't accept any args
func (o WorkloadScalingPolicyMemoryPtrOutput) Args() pulumi.StringPtrOutput {
	return o.ApplyT(func(v *WorkloadScalingPolicyMemory) *string {
		if v == nil {
			return nil
		}
		return v.Args
	}).(pulumi.StringPtrOutput)
}

// The function used to calculate the resource recommendation. Supported values: `QUANTILE`, `MAX`
func (o WorkloadScalingPolicyMemoryPtrOutput) Function() pulumi.StringPtrOutput {
	return o.ApplyT(func(v *WorkloadScalingPolicyMemory) *string {
		if v == nil {
			return nil
		}
		return v.Function
	}).(pulumi.StringPtrOutput)
}

// Resource limit settings
func (o WorkloadScalingPolicyMemoryPtrOutput) Limit() WorkloadScalingPolicyMemoryLimitPtrOutput {
	return o.ApplyT(func(v *WorkloadScalingPolicyMemory) *WorkloadScalingPolicyMemoryLimit {
		if v == nil {
			return nil
		}
		return v.Limit
	}).(WorkloadScalingPolicyMemoryLimitPtrOutput)
}

// The look back period in seconds for the recommendation.
func (o WorkloadScalingPolicyMemoryPtrOutput) LookBackPeriodSeconds() pulumi.IntPtrOutput {
	return o.ApplyT(func(v *WorkloadScalingPolicyMemory) *int {
		if v == nil {
			return nil
		}
		return v.LookBackPeriodSeconds
	}).(pulumi.IntPtrOutput)
}

// Disables management for a single resource when set to `READ_ONLY`. The resource will use its original workload template requests and limits. Supported value: `READ_ONLY`. Minimum required workload-autoscaler version: `v0.23.1`.
func (o WorkloadScalingPolicyMemoryPtrOutput) ManagementOption() pulumi.StringPtrOutput {
	return o.ApplyT(func(v *WorkloadScalingPolicyMemory) *string {
		if v == nil {
			return nil
		}
		return v.ManagementOption
	}).(pulumi.StringPtrOutput)
}

// Max values for the recommendation, applies to every container. For memory - this is in MiB, for CPU - this is in cores.
func (o WorkloadScalingPolicyMemoryPtrOutput) Max() pulumi.Float64PtrOutput {
	return o.ApplyT(func(v *WorkloadScalingPolicyMemory) *float64 {
		if v == nil {
			return nil
		}
		return v.Max
	}).(pulumi.Float64PtrOutput)
}

// Min values for the recommendation, applies to every container. For memory - this is in MiB, for CPU - this is in cores.
func (o WorkloadScalingPolicyMemoryPtrOutput) Min() pulumi.Float64PtrOutput {
	return o.ApplyT(func(v *WorkloadScalingPolicyMemory) *float64 {
		if v == nil {
			return nil
		}
		return v.Min
	}).(pulumi.Float64PtrOutput)
}

// Overhead for the recommendation, e.g. `0.1` will result in 10% higher recommendation
func (o WorkloadScalingPolicyMemoryPtrOutput) Overhead() pulumi.Float64PtrOutput {
	return o.ApplyT(func(v *WorkloadScalingPolicyMemory) *float64 {
		if v == nil {
			return nil
		}
		return v.Overhead
	}).(pulumi.Float64PtrOutput)
}

type WorkloadScalingPolicyMemoryApplyThresholdStrategy struct {
	// If denominator is close or equal to 0, the threshold will be much bigger for small values.For example when numerator, exponent is 1 and denominator is 0 the threshold for 0.5 req. CPU will be 200%.It must be defined for the CUSTOM_ADAPTIVE strategy.
	Denominator *string `pulumi:"denominator"`
	// The exponent changes how fast the curve is going down. The smaller value will cause that we won’t pick extremely small number for big resources, for example:
	// 	- if numerator is 0, denominator is 1, and exponent is 1, for 50 CPU we will pick 2% threshold
	// 	- if numerator is 0, denominator is 1, and exponent is 0.8, for 50 CPU we will pick 4.3% threshold
	// 	It must be defined for the CUSTOM_ADAPTIVE strategy.
	Exponent *float64 `pulumi:"exponent"`
	// The numerator affects vertical stretch of function used in adaptive threshold - smaller number will create smaller threshold.It must be defined for the CUSTOM_ADAPTIVE strategy.
	Numerator *float64 `pulumi:"numerator"`
	// Percentage of a how much difference should there be between the current pod requests and the new recommendation. It must be defined for the PERCENTAGE strategy.
	Percentage *float64 `pulumi:"percentage"`
	// Defines apply theshold strategy type.
	// 	- PERCENTAGE - recommendation will be applied when diff of current requests and new recommendation is greater than set value
	//     - DEFAULT_ADAPTIVE - will pick larger threshold percentage for small workloads and smaller percentage for large workloads.
	//     - CUSTOM_ADAPTIVE - works in same way as DEFAULT_ADAPTIVE, but it allows to tweak parameters of adaptive threshold formula: percentage = numerator/(currentRequest + denominator)^exponent. This strategy is for advance use cases, we recommend to use DEFAULT_ADAPTIVE strategy.
	Type string `pulumi:"type"`
}

// WorkloadScalingPolicyMemoryApplyThresholdStrategyInput is an input type that accepts WorkloadScalingPolicyMemoryApplyThresholdStrategyArgs and WorkloadScalingPolicyMemoryApplyThresholdStrategyOutput values.
// You can construct a concrete instance of `WorkloadScalingPolicyMemoryApplyThresholdStrategyInput` via:
//
//	WorkloadScalingPolicyMemoryApplyThresholdStrategyArgs{...}
type WorkloadScalingPolicyMemoryApplyThresholdStrategyInput interface {
	pulumi.Input

	ToWorkloadScalingPolicyMemoryApplyThresholdStrategyOutput() WorkloadScalingPolicyMemoryApplyThresholdStrategyOutput
	ToWorkloadScalingPolicyMemoryApplyThresholdStrategyOutputWithContext(context.Context) WorkloadScalingPolicyMemoryApplyThresholdStrategyOutput
}

type WorkloadScalingPolicyMemoryApplyThresholdStrategyArgs struct {
	// If denominator is close or equal to 0, the threshold will be much bigger for small values.For example when numerator, exponent is 1 and denominator is 0 the threshold for 0.5 req. CPU will be 200%.It must be defined for the CUSTOM_ADAPTIVE strategy.
	Denominator pulumi.StringPtrInput `pulumi:"denominator"`
	// The exponent changes how fast the curve is going down. The smaller value will cause that we won’t pick extremely small number for big resources, for example:
	// 	- if numerator is 0, denominator is 1, and exponent is 1, for 50 CPU we will pick 2% threshold
	// 	- if numerator is 0, denominator is 1, and exponent is 0.8, for 50 CPU we will pick 4.3% threshold
	// 	It must be defined for the CUSTOM_ADAPTIVE strategy.
	Exponent pulumi.Float64PtrInput `pulumi:"exponent"`
	// The numerator affects vertical stretch of function used in adaptive threshold - smaller number will create smaller threshold.It must be defined for the CUSTOM_ADAPTIVE strategy.
	Numerator pulumi.Float64PtrInput `pulumi:"numerator"`
	// Percentage of a how much difference should there be between the current pod requests and the new recommendation. It must be defined for the PERCENTAGE strategy.
	Percentage pulumi.Float64PtrInput `pulumi:"percentage"`
	// Defines apply theshold strategy type.
	// 	- PERCENTAGE - recommendation will be applied when diff of current requests and new recommendation is greater than set value
	//     - DEFAULT_ADAPTIVE - will pick larger threshold percentage for small workloads and smaller percentage for large workloads.
	//     - CUSTOM_ADAPTIVE - works in same way as DEFAULT_ADAPTIVE, but it allows to tweak parameters of adaptive threshold formula: percentage = numerator/(currentRequest + denominator)^exponent. This strategy is for advance use cases, we recommend to use DEFAULT_ADAPTIVE strategy.
	Type pulumi.StringInput `pulumi:"type"`
}

func (WorkloadScalingPolicyMemoryApplyThresholdStrategyArgs) ElementType() reflect.Type {
	return reflect.TypeOf((*WorkloadScalingPolicyMemoryApplyThresholdStrategy)(nil)).Elem()
}

func (i WorkloadScalingPolicyMemoryApplyThresholdStrategyArgs) ToWorkloadScalingPolicyMemoryApplyThresholdStrategyOutput() WorkloadScalingPolicyMemoryApplyThresholdStrategyOutput {
	return i.ToWorkloadScalingPolicyMemoryApplyThresholdStrategyOutputWithContext(context.Background())
}

func (i WorkloadScalingPolicyMemoryApplyThresholdStrategyArgs) ToWorkloadScalingPolicyMemoryApplyThresholdStrategyOutputWithContext(ctx context.Context) WorkloadScalingPolicyMemoryApplyThresholdStrategyOutput {
	return pulumi.ToOutputWithContext(ctx, i).(WorkloadScalingPolicyMemoryApplyThresholdStrategyOutput)
}

func (i WorkloadScalingPolicyMemoryApplyThresholdStrategyArgs) ToWorkloadScalingPolicyMemoryApplyThresholdStrategyPtrOutput() WorkloadScalingPolicyMemoryApplyThresholdStrategyPtrOutput {
	return i.ToWorkloadScalingPolicyMemoryApplyThresholdStrategyPtrOutputWithContext(context.Background())
}

func (i WorkloadScalingPolicyMemoryApplyThresholdStrategyArgs) ToWorkloadScalingPolicyMemoryApplyThresholdStrategyPtrOutputWithContext(ctx context.Context) WorkloadScalingPolicyMemoryApplyThresholdStrategyPtrOutput {
	return pulumi.ToOutputWithContext(ctx, i).(WorkloadScalingPolicyMemoryApplyThresholdStrategyOutput).ToWorkloadScalingPolicyMemoryApplyThresholdStrategyPtrOutputWithContext(ctx)
}

// WorkloadScalingPolicyMemoryApplyThresholdStrategyPtrInput is an input type that accepts WorkloadScalingPolicyMemoryApplyThresholdStrategyArgs, WorkloadScalingPolicyMemoryApplyThresholdStrategyPtr and WorkloadScalingPolicyMemoryApplyThresholdStrategyPtrOutput values.
// You can construct a concrete instance of `WorkloadScalingPolicyMemoryApplyThresholdStrategyPtrInput` via:
//
//	        WorkloadScalingPolicyMemoryApplyThresholdStrategyArgs{...}
//
//	or:
//
//	        nil
type WorkloadScalingPolicyMemoryApplyThresholdStrategyPtrInput interface {
	pulumi.Input

	ToWorkloadScalingPolicyMemoryApplyThresholdStrategyPtrOutput() WorkloadScalingPolicyMemoryApplyThresholdStrategyPtrOutput
	ToWorkloadScalingPolicyMemoryApplyThresholdStrategyPtrOutputWithContext(context.Context) WorkloadScalingPolicyMemoryApplyThresholdStrategyPtrOutput
}

type workloadScalingPolicyMemoryApplyThresholdStrategyPtrType WorkloadScalingPolicyMemoryApplyThresholdStrategyArgs

func WorkloadScalingPolicyMemoryApplyThresholdStrategyPtr(v *WorkloadScalingPolicyMemoryApplyThresholdStrategyArgs) WorkloadScalingPolicyMemoryApplyThresholdStrategyPtrInput {
	return (*workloadScalingPolicyMemoryApplyThresholdStrategyPtrType)(v)
}

func (*workloadScalingPolicyMemoryApplyThresholdStrategyPtrType) ElementType() reflect.Type {
	return reflect.TypeOf((**WorkloadScalingPolicyMemoryApplyThresholdStrategy)(nil)).Elem()
}

func (i *workloadScalingPolicyMemoryApplyThresholdStrategyPtrType) ToWorkloadScalingPolicyMemoryApplyThresholdStrategyPtrOutput() WorkloadScalingPolicyMemoryApplyThresholdStrategyPtrOutput {
	return i.ToWorkloadScalingPolicyMemoryApplyThresholdStrategyPtrOutputWithContext(context.Background())
}

func (i *workloadScalingPolicyMemoryApplyThresholdStrategyPtrType) ToWorkloadScalingPolicyMemoryApplyThresholdStrategyPtrOutputWithContext(ctx context.Context) WorkloadScalingPolicyMemoryApplyThresholdStrategyPtrOutput {
	return pulumi.ToOutputWithContext(ctx, i).(WorkloadScalingPolicyMemoryApplyThresholdStrategyPtrOutput)
}

type WorkloadScalingPolicyMemoryApplyThresholdStrategyOutput struct{ *pulumi.OutputState }

func (WorkloadScalingPolicyMemoryApplyThresholdStrategyOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*WorkloadScalingPolicyMemoryApplyThresholdStrategy)(nil)).Elem()
}

func (o WorkloadScalingPolicyMemoryApplyThresholdStrategyOutput) ToWorkloadScalingPolicyMemoryApplyThresholdStrategyOutput() WorkloadScalingPolicyMemoryApplyThresholdStrategyOutput {
	return o
}

func (o WorkloadScalingPolicyMemoryApplyThresholdStrategyOutput) ToWorkloadScalingPolicyMemoryApplyThresholdStrategyOutputWithContext(ctx context.Context) WorkloadScalingPolicyMemoryApplyThresholdStrategyOutput {
	return o
}

func (o WorkloadScalingPolicyMemoryApplyThresholdStrategyOutput) ToWorkloadScalingPolicyMemoryApplyThresholdStrategyPtrOutput() WorkloadScalingPolicyMemoryApplyThresholdStrategyPtrOutput {
	return o.ToWorkloadScalingPolicyMemoryApplyThresholdStrategyPtrOutputWithContext(context.Background())
}

func (o WorkloadScalingPolicyMemoryApplyThresholdStrategyOutput) ToWorkloadScalingPolicyMemoryApplyThresholdStrategyPtrOutputWithContext(ctx context.Context) WorkloadScalingPolicyMemoryApplyThresholdStrategyPtrOutput {
	return o.ApplyTWithContext(ctx, func(_ context.Context, v WorkloadScalingPolicyMemoryApplyThresholdStrategy) *WorkloadScalingPolicyMemoryApplyThresholdStrategy {
		return &v
	}).(WorkloadScalingPolicyMemoryApplyThresholdStrategyPtrOutput)
}

// If denominator is close or equal to 0, the threshold will be much bigger for small values.For example when numerator, exponent is 1 and denominator is 0 the threshold for 0.5 req. CPU will be 200%.It must be defined for the CUSTOM_ADAPTIVE strategy.
func (o WorkloadScalingPolicyMemoryApplyThresholdStrategyOutput) Denominator() pulumi.StringPtrOutput {
	return o.ApplyT(func(v WorkloadScalingPolicyMemoryApplyThresholdStrategy) *string { return v.Denominator }).(pulumi.StringPtrOutput)
}

// The exponent changes how fast the curve is going down. The smaller value will cause that we won’t pick extremely small number for big resources, for example:
//   - if numerator is 0, denominator is 1, and exponent is 1, for 50 CPU we will pick 2% threshold
//   - if numerator is 0, denominator is 1, and exponent is 0.8, for 50 CPU we will pick 4.3% threshold
//     It must be defined for the CUSTOM_ADAPTIVE strategy.
func (o WorkloadScalingPolicyMemoryApplyThresholdStrategyOutput) Exponent() pulumi.Float64PtrOutput {
	return o.ApplyT(func(v WorkloadScalingPolicyMemoryApplyThresholdStrategy) *float64 { return v.Exponent }).(pulumi.Float64PtrOutput)
}

// The numerator affects vertical stretch of function used in adaptive threshold - smaller number will create smaller threshold.It must be defined for the CUSTOM_ADAPTIVE strategy.
func (o WorkloadScalingPolicyMemoryApplyThresholdStrategyOutput) Numerator() pulumi.Float64PtrOutput {
	return o.ApplyT(func(v WorkloadScalingPolicyMemoryApplyThresholdStrategy) *float64 { return v.Numerator }).(pulumi.Float64PtrOutput)
}

// Percentage of a how much difference should there be between the current pod requests and the new recommendation. It must be defined for the PERCENTAGE strategy.
func (o WorkloadScalingPolicyMemoryApplyThresholdStrategyOutput) Percentage() pulumi.Float64PtrOutput {
	return o.ApplyT(func(v WorkloadScalingPolicyMemoryApplyThresholdStrategy) *float64 { return v.Percentage }).(pulumi.Float64PtrOutput)
}

// Defines apply theshold strategy type.
//   - PERCENTAGE - recommendation will be applied when diff of current requests and new recommendation is greater than set value
//   - DEFAULT_ADAPTIVE - will pick larger threshold percentage for small workloads and smaller percentage for large workloads.
//   - CUSTOM_ADAPTIVE - works in same way as DEFAULT_ADAPTIVE, but it allows to tweak parameters of adaptive threshold formula: percentage = numerator/(currentRequest + denominator)^exponent. This strategy is for advance use cases, we recommend to use DEFAULT_ADAPTIVE strategy.
func (o WorkloadScalingPolicyMemoryApplyThresholdStrategyOutput) Type() pulumi.StringOutput {
	return o.ApplyT(func(v WorkloadScalingPolicyMemoryApplyThresholdStrategy) string { return v.Type }).(pulumi.StringOutput)
}

type WorkloadScalingPolicyMemoryApplyThresholdStrategyPtrOutput struct{ *pulumi.OutputState }

func (WorkloadScalingPolicyMemoryApplyThresholdStrategyPtrOutput) ElementType() reflect.Type {
	return reflect.TypeOf((**WorkloadScalingPolicyMemoryApplyThresholdStrategy)(nil)).Elem()
}

func (o WorkloadScalingPolicyMemoryApplyThresholdStrategyPtrOutput) ToWorkloadScalingPolicyMemoryApplyThresholdStrategyPtrOutput() WorkloadScalingPolicyMemoryApplyThresholdStrategyPtrOutput {
	return o
}

func (o WorkloadScalingPolicyMemoryApplyThresholdStrategyPtrOutput) ToWorkloadScalingPolicyMemoryApplyThresholdStrategyPtrOutputWithContext(ctx context.Context) WorkloadScalingPolicyMemoryApplyThresholdStrategyPtrOutput {
	return o
}

func (o WorkloadScalingPolicyMemoryApplyThresholdStrategyPtrOutput) Elem() WorkloadScalingPolicyMemoryApplyThresholdStrategyOutput {
	return o.ApplyT(func(v *WorkloadScalingPolicyMemoryApplyThresholdStrategy) WorkloadScalingPolicyMemoryApplyThresholdStrategy {
		if v != nil {
			return *v
		}
		var ret WorkloadScalingPolicyMemoryApplyThresholdStrategy
		return ret
	}).(WorkloadScalingPolicyMemoryApplyThresholdStrategyOutput)
}

// If denominator is close or equal to 0, the threshold will be much bigger for small values.For example when numerator, exponent is 1 and denominator is 0 the threshold for 0.5 req. CPU will be 200%.It must be defined for the CUSTOM_ADAPTIVE strategy.
func (o WorkloadScalingPolicyMemoryApplyThresholdStrategyPtrOutput) Denominator() pulumi.StringPtrOutput {
	return o.ApplyT(func(v *WorkloadScalingPolicyMemoryApplyThresholdStrategy) *string {
		if v == nil {
			return nil
		}
		return v.Denominator
	}).(pulumi.StringPtrOutput)
}

// The exponent changes how fast the curve is going down. The smaller value will cause that we won’t pick extremely small number for big resources, for example:
//   - if numerator is 0, denominator is 1, and exponent is 1, for 50 CPU we will pick 2% threshold
//   - if numerator is 0, denominator is 1, and exponent is 0.8, for 50 CPU we will pick 4.3% threshold
//     It must be defined for the CUSTOM_ADAPTIVE strategy.
func (o WorkloadScalingPolicyMemoryApplyThresholdStrategyPtrOutput) Exponent() pulumi.Float64PtrOutput {
	return o.ApplyT(func(v *WorkloadScalingPolicyMemoryApplyThresholdStrategy) *float64 {
		if v == nil {
			return nil
		}
		return v.Exponent
	}).(pulumi.Float64PtrOutput)
}

// The numerator affects vertical stretch of function used in adaptive threshold - smaller number will create smaller threshold.It must be defined for the CUSTOM_ADAPTIVE strategy.
func (o WorkloadScalingPolicyMemoryApplyThresholdStrategyPtrOutput) Numerator() pulumi.Float64PtrOutput {
	return o.ApplyT(func(v *WorkloadScalingPolicyMemoryApplyThresholdStrategy) *float64 {
		if v == nil {
			return nil
		}
		return v.Numerator
	}).(pulumi.Float64PtrOutput)
}

// Percentage of a how much difference should there be between the current pod requests and the new recommendation. It must be defined for the PERCENTAGE strategy.
func (o WorkloadScalingPolicyMemoryApplyThresholdStrategyPtrOutput) Percentage() pulumi.Float64PtrOutput {
	return o.ApplyT(func(v *WorkloadScalingPolicyMemoryApplyThresholdStrategy) *float64 {
		if v == nil {
			return nil
		}
		return v.Percentage
	}).(pulumi.Float64PtrOutput)
}

// Defines apply theshold strategy type.
//   - PERCENTAGE - recommendation will be applied when diff of current requests and new recommendation is greater than set value
//   - DEFAULT_ADAPTIVE - will pick larger threshold percentage for small workloads and smaller percentage for large workloads.
//   - CUSTOM_ADAPTIVE - works in same way as DEFAULT_ADAPTIVE, but it allows to tweak parameters of adaptive threshold formula: percentage = numerator/(currentRequest + denominator)^exponent. This strategy is for advance use cases, we recommend to use DEFAULT_ADAPTIVE strategy.
func (o WorkloadScalingPolicyMemoryApplyThresholdStrategyPtrOutput) Type() pulumi.StringPtrOutput {
	return o.ApplyT(func(v *WorkloadScalingPolicyMemoryApplyThresholdStrategy) *string {
		if v == nil {
			return nil
		}
		return &v.Type
	}).(pulumi.StringPtrOutput)
}

type WorkloadScalingPolicyMemoryEvent struct {
	// Defines the apply type to be used when applying recommendation for memory related event.
	// 	- IMMEDIATE - pods are restarted immediately when new recommendation is generated.
	// 	- DEFERRED - pods are not restarted and recommendation values are applied during natural restarts only (new deployment, etc.)
	ApplyType *string `pulumi:"applyType"`
}

// WorkloadScalingPolicyMemoryEventInput is an input type that accepts WorkloadScalingPolicyMemoryEventArgs and WorkloadScalingPolicyMemoryEventOutput values.
// You can construct a concrete instance of `WorkloadScalingPolicyMemoryEventInput` via:
//
//	WorkloadScalingPolicyMemoryEventArgs{...}
type WorkloadScalingPolicyMemoryEventInput interface {
	pulumi.Input

	ToWorkloadScalingPolicyMemoryEventOutput() WorkloadScalingPolicyMemoryEventOutput
	ToWorkloadScalingPolicyMemoryEventOutputWithContext(context.Context) WorkloadScalingPolicyMemoryEventOutput
}

type WorkloadScalingPolicyMemoryEventArgs struct {
	// Defines the apply type to be used when applying recommendation for memory related event.
	// 	- IMMEDIATE - pods are restarted immediately when new recommendation is generated.
	// 	- DEFERRED - pods are not restarted and recommendation values are applied during natural restarts only (new deployment, etc.)
	ApplyType pulumi.StringPtrInput `pulumi:"applyType"`
}

func (WorkloadScalingPolicyMemoryEventArgs) ElementType() reflect.Type {
	return reflect.TypeOf((*WorkloadScalingPolicyMemoryEvent)(nil)).Elem()
}

func (i WorkloadScalingPolicyMemoryEventArgs) ToWorkloadScalingPolicyMemoryEventOutput() WorkloadScalingPolicyMemoryEventOutput {
	return i.ToWorkloadScalingPolicyMemoryEventOutputWithContext(context.Background())
}

func (i WorkloadScalingPolicyMemoryEventArgs) ToWorkloadScalingPolicyMemoryEventOutputWithContext(ctx context.Context) WorkloadScalingPolicyMemoryEventOutput {
	return pulumi.ToOutputWithContext(ctx, i).(WorkloadScalingPolicyMemoryEventOutput)
}

func (i WorkloadScalingPolicyMemoryEventArgs) ToWorkloadScalingPolicyMemoryEventPtrOutput() WorkloadScalingPolicyMemoryEventPtrOutput {
	return i.ToWorkloadScalingPolicyMemoryEventPtrOutputWithContext(context.Background())
}

func (i WorkloadScalingPolicyMemoryEventArgs) ToWorkloadScalingPolicyMemoryEventPtrOutputWithContext(ctx context.Context) WorkloadScalingPolicyMemoryEventPtrOutput {
	return pulumi.ToOutputWithContext(ctx, i).(WorkloadScalingPolicyMemoryEventOutput).ToWorkloadScalingPolicyMemoryEventPtrOutputWithContext(ctx)
}

// WorkloadScalingPolicyMemoryEventPtrInput is an input type that accepts WorkloadScalingPolicyMemoryEventArgs, WorkloadScalingPolicyMemoryEventPtr and WorkloadScalingPolicyMemoryEventPtrOutput values.
// You can construct a concrete instance of `WorkloadScalingPolicyMemoryEventPtrInput` via:
//
//	        WorkloadScalingPolicyMemoryEventArgs{...}
//
//	or:
//
//	        nil
type WorkloadScalingPolicyMemoryEventPtrInput interface {
	pulumi.Input

	ToWorkloadScalingPolicyMemoryEventPtrOutput() WorkloadScalingPolicyMemoryEventPtrOutput
	ToWorkloadScalingPolicyMemoryEventPtrOutputWithContext(context.Context) WorkloadScalingPolicyMemoryEventPtrOutput
}

type workloadScalingPolicyMemoryEventPtrType WorkloadScalingPolicyMemoryEventArgs

func WorkloadScalingPolicyMemoryEventPtr(v *WorkloadScalingPolicyMemoryEventArgs) WorkloadScalingPolicyMemoryEventPtrInput {
	return (*workloadScalingPolicyMemoryEventPtrType)(v)
}

func (*workloadScalingPolicyMemoryEventPtrType) ElementType() reflect.Type {
	return reflect.TypeOf((**WorkloadScalingPolicyMemoryEvent)(nil)).Elem()
}

func (i *workloadScalingPolicyMemoryEventPtrType) ToWorkloadScalingPolicyMemoryEventPtrOutput() WorkloadScalingPolicyMemoryEventPtrOutput {
	return i.ToWorkloadScalingPolicyMemoryEventPtrOutputWithContext(context.Background())
}

func (i *workloadScalingPolicyMemoryEventPtrType) ToWorkloadScalingPolicyMemoryEventPtrOutputWithContext(ctx context.Context) WorkloadScalingPolicyMemoryEventPtrOutput {
	return pulumi.ToOutputWithContext(ctx, i).(WorkloadScalingPolicyMemoryEventPtrOutput)
}

type WorkloadScalingPolicyMemoryEventOutput struct{ *pulumi.OutputState }

func (WorkloadScalingPolicyMemoryEventOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*WorkloadScalingPolicyMemoryEvent)(nil)).Elem()
}

func (o WorkloadScalingPolicyMemoryEventOutput) ToWorkloadScalingPolicyMemoryEventOutput() WorkloadScalingPolicyMemoryEventOutput {
	return o
}

func (o WorkloadScalingPolicyMemoryEventOutput) ToWorkloadScalingPolicyMemoryEventOutputWithContext(ctx context.Context) WorkloadScalingPolicyMemoryEventOutput {
	return o
}

func (o WorkloadScalingPolicyMemoryEventOutput) ToWorkloadScalingPolicyMemoryEventPtrOutput() WorkloadScalingPolicyMemoryEventPtrOutput {
	return o.ToWorkloadScalingPolicyMemoryEventPtrOutputWithContext(context.Background())
}

func (o WorkloadScalingPolicyMemoryEventOutput) ToWorkloadScalingPolicyMemoryEventPtrOutputWithContext(ctx context.Context) WorkloadScalingPolicyMemoryEventPtrOutput {
	return o.ApplyTWithContext(ctx, func(_ context.Context, v WorkloadScalingPolicyMemoryEvent) *WorkloadScalingPolicyMemoryEvent {
		return &v
	}).(WorkloadScalingPolicyMemoryEventPtrOutput)
}

// Defines the apply type to be used when applying recommendation for memory related event.
//   - IMMEDIATE - pods are restarted immediately when new recommendation is generated.
//   - DEFERRED - pods are not restarted and recommendation values are applied during natural restarts only (new deployment, etc.)
func (o WorkloadScalingPolicyMemoryEventOutput) ApplyType() pulumi.StringPtrOutput {
	return o.ApplyT(func(v WorkloadScalingPolicyMemoryEvent) *string { return v.ApplyType }).(pulumi.StringPtrOutput)
}

type WorkloadScalingPolicyMemoryEventPtrOutput struct{ *pulumi.OutputState }

func (WorkloadScalingPolicyMemoryEventPtrOutput) ElementType() reflect.Type {
	return reflect.TypeOf((**WorkloadScalingPolicyMemoryEvent)(nil)).Elem()
}

func (o WorkloadScalingPolicyMemoryEventPtrOutput) ToWorkloadScalingPolicyMemoryEventPtrOutput() WorkloadScalingPolicyMemoryEventPtrOutput {
	return o
}

func (o WorkloadScalingPolicyMemoryEventPtrOutput) ToWorkloadScalingPolicyMemoryEventPtrOutputWithContext(ctx context.Context) WorkloadScalingPolicyMemoryEventPtrOutput {
	return o
}

func (o WorkloadScalingPolicyMemoryEventPtrOutput) Elem() WorkloadScalingPolicyMemoryEventOutput {
	return o.ApplyT(func(v *WorkloadScalingPolicyMemoryEvent) WorkloadScalingPolicyMemoryEvent {
		if v != nil {
			return *v
		}
		var ret WorkloadScalingPolicyMemoryEvent
		return ret
	}).(WorkloadScalingPolicyMemoryEventOutput)
}

// Defines the apply type to be used when applying recommendation for memory related event.
//   - IMMEDIATE - pods are restarted immediately when new recommendation is generated.
//   - DEFERRED - pods are not restarted and recommendation values are applied during natural restarts only (new deployment, etc.)
func (o WorkloadScalingPolicyMemoryEventPtrOutput) ApplyType() pulumi.StringPtrOutput {
	return o.ApplyT(func(v *WorkloadScalingPolicyMemoryEvent) *string {
		if v == nil {
			return nil
		}
		return v.ApplyType
	}).(pulumi.StringPtrOutput)
}

type WorkloadScalingPolicyMemoryLimit struct {
	// Multiplier used to calculate the resource limit. It must be defined for the MULTIPLIER strategy.
	Multiplier *float64 `pulumi:"multiplier"`
	// Defines limit strategy type.
	// 	- NO_LIMIT - removes the resource limit even if it was specified in the workload spec.
	// 	- KEEP_LIMITS - keep existing resource limits. While limits provide stability predictability, they may restrict workloads that need to temporarily burst beyond their allocation.
	// 	- MULTIPLIER - used to calculate the resource limit. The final value is determined by multiplying the resource request by the specified factor.
	Type string `pulumi:"type"`
}

// WorkloadScalingPolicyMemoryLimitInput is an input type that accepts WorkloadScalingPolicyMemoryLimitArgs and WorkloadScalingPolicyMemoryLimitOutput values.
// You can construct a concrete instance of `WorkloadScalingPolicyMemoryLimitInput` via:
//
//	WorkloadScalingPolicyMemoryLimitArgs{...}
type WorkloadScalingPolicyMemoryLimitInput interface {
	pulumi.Input

	ToWorkloadScalingPolicyMemoryLimitOutput() WorkloadScalingPolicyMemoryLimitOutput
	ToWorkloadScalingPolicyMemoryLimitOutputWithContext(context.Context) WorkloadScalingPolicyMemoryLimitOutput
}

type WorkloadScalingPolicyMemoryLimitArgs struct {
	// Multiplier used to calculate the resource limit. It must be defined for the MULTIPLIER strategy.
	Multiplier pulumi.Float64PtrInput `pulumi:"multiplier"`
	// Defines limit strategy type.
	// 	- NO_LIMIT - removes the resource limit even if it was specified in the workload spec.
	// 	- KEEP_LIMITS - keep existing resource limits. While limits provide stability predictability, they may restrict workloads that need to temporarily burst beyond their allocation.
	// 	- MULTIPLIER - used to calculate the resource limit. The final value is determined by multiplying the resource request by the specified factor.
	Type pulumi.StringInput `pulumi:"type"`
}

func (WorkloadScalingPolicyMemoryLimitArgs) ElementType() reflect.Type {
	return reflect.TypeOf((*WorkloadScalingPolicyMemoryLimit)(nil)).Elem()
}

func (i WorkloadScalingPolicyMemoryLimitArgs) ToWorkloadScalingPolicyMemoryLimitOutput() WorkloadScalingPolicyMemoryLimitOutput {
	return i.ToWorkloadScalingPolicyMemoryLimitOutputWithContext(context.Background())
}

func (i WorkloadScalingPolicyMemoryLimitArgs) ToWorkloadScalingPolicyMemoryLimitOutputWithContext(ctx context.Context) WorkloadScalingPolicyMemoryLimitOutput {
	return pulumi.ToOutputWithContext(ctx, i).(WorkloadScalingPolicyMemoryLimitOutput)
}

func (i WorkloadScalingPolicyMemoryLimitArgs) ToWorkloadScalingPolicyMemoryLimitPtrOutput() WorkloadScalingPolicyMemoryLimitPtrOutput {
	return i.ToWorkloadScalingPolicyMemoryLimitPtrOutputWithContext(context.Background())
}

func (i WorkloadScalingPolicyMemoryLimitArgs) ToWorkloadScalingPolicyMemoryLimitPtrOutputWithContext(ctx context.Context) WorkloadScalingPolicyMemoryLimitPtrOutput {
	return pulumi.ToOutputWithContext(ctx, i).(WorkloadScalingPolicyMemoryLimitOutput).ToWorkloadScalingPolicyMemoryLimitPtrOutputWithContext(ctx)
}

// WorkloadScalingPolicyMemoryLimitPtrInput is an input type that accepts WorkloadScalingPolicyMemoryLimitArgs, WorkloadScalingPolicyMemoryLimitPtr and WorkloadScalingPolicyMemoryLimitPtrOutput values.
// You can construct a concrete instance of `WorkloadScalingPolicyMemoryLimitPtrInput` via:
//
//	        WorkloadScalingPolicyMemoryLimitArgs{...}
//
//	or:
//
//	        nil
type WorkloadScalingPolicyMemoryLimitPtrInput interface {
	pulumi.Input

	ToWorkloadScalingPolicyMemoryLimitPtrOutput() WorkloadScalingPolicyMemoryLimitPtrOutput
	ToWorkloadScalingPolicyMemoryLimitPtrOutputWithContext(context.Context) WorkloadScalingPolicyMemoryLimitPtrOutput
}

type workloadScalingPolicyMemoryLimitPtrType WorkloadScalingPolicyMemoryLimitArgs

func WorkloadScalingPolicyMemoryLimitPtr(v *WorkloadScalingPolicyMemoryLimitArgs) WorkloadScalingPolicyMemoryLimitPtrInput {
	return (*workloadScalingPolicyMemoryLimitPtrType)(v)
}

func (*workloadScalingPolicyMemoryLimitPtrType) ElementType() reflect.Type {
	return reflect.TypeOf((**WorkloadScalingPolicyMemoryLimit)(nil)).Elem()
}

func (i *workloadScalingPolicyMemoryLimitPtrType) ToWorkloadScalingPolicyMemoryLimitPtrOutput() WorkloadScalingPolicyMemoryLimitPtrOutput {
	return i.ToWorkloadScalingPolicyMemoryLimitPtrOutputWithContext(context.Background())
}

func (i *workloadScalingPolicyMemoryLimitPtrType) ToWorkloadScalingPolicyMemoryLimitPtrOutputWithContext(ctx context.Context) WorkloadScalingPolicyMemoryLimitPtrOutput {
	return pulumi.ToOutputWithContext(ctx, i).(WorkloadScalingPolicyMemoryLimitPtrOutput)
}

type WorkloadScalingPolicyMemoryLimitOutput struct{ *pulumi.OutputState }

func (WorkloadScalingPolicyMemoryLimitOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*WorkloadScalingPolicyMemoryLimit)(nil)).Elem()
}

func (o WorkloadScalingPolicyMemoryLimitOutput) ToWorkloadScalingPolicyMemoryLimitOutput() WorkloadScalingPolicyMemoryLimitOutput {
	return o
}

func (o WorkloadScalingPolicyMemoryLimitOutput) ToWorkloadScalingPolicyMemoryLimitOutputWithContext(ctx context.Context) WorkloadScalingPolicyMemoryLimitOutput {
	return o
}

func (o WorkloadScalingPolicyMemoryLimitOutput) ToWorkloadScalingPolicyMemoryLimitPtrOutput() WorkloadScalingPolicyMemoryLimitPtrOutput {
	return o.ToWorkloadScalingPolicyMemoryLimitPtrOutputWithContext(context.Background())
}

func (o WorkloadScalingPolicyMemoryLimitOutput) ToWorkloadScalingPolicyMemoryLimitPtrOutputWithContext(ctx context.Context) WorkloadScalingPolicyMemoryLimitPtrOutput {
	return o.ApplyTWithContext(ctx, func(_ context.Context, v WorkloadScalingPolicyMemoryLimit) *WorkloadScalingPolicyMemoryLimit {
		return &v
	}).(WorkloadScalingPolicyMemoryLimitPtrOutput)
}

// Multiplier used to calculate the resource limit. It must be defined for the MULTIPLIER strategy.
func (o WorkloadScalingPolicyMemoryLimitOutput) Multiplier() pulumi.Float64PtrOutput {
	return o.ApplyT(func(v WorkloadScalingPolicyMemoryLimit) *float64 { return v.Multiplier }).(pulumi.Float64PtrOutput)
}

// Defines limit strategy type.
//   - NO_LIMIT - removes the resource limit even if it was specified in the workload spec.
//   - KEEP_LIMITS - keep existing resource limits. While limits provide stability predictability, they may restrict workloads that need to temporarily burst beyond their allocation.
//   - MULTIPLIER - used to calculate the resource limit. The final value is determined by multiplying the resource request by the specified factor.
func (o WorkloadScalingPolicyMemoryLimitOutput) Type() pulumi.StringOutput {
	return o.ApplyT(func(v WorkloadScalingPolicyMemoryLimit) string { return v.Type }).(pulumi.StringOutput)
}

type WorkloadScalingPolicyMemoryLimitPtrOutput struct{ *pulumi.OutputState }

func (WorkloadScalingPolicyMemoryLimitPtrOutput) ElementType() reflect.Type {
	return reflect.TypeOf((**WorkloadScalingPolicyMemoryLimit)(nil)).Elem()
}

func (o WorkloadScalingPolicyMemoryLimitPtrOutput) ToWorkloadScalingPolicyMemoryLimitPtrOutput() WorkloadScalingPolicyMemoryLimitPtrOutput {
	return o
}

func (o WorkloadScalingPolicyMemoryLimitPtrOutput) ToWorkloadScalingPolicyMemoryLimitPtrOutputWithContext(ctx context.Context) WorkloadScalingPolicyMemoryLimitPtrOutput {
	return o
}

func (o WorkloadScalingPolicyMemoryLimitPtrOutput) Elem() WorkloadScalingPolicyMemoryLimitOutput {
	return o.ApplyT(func(v *WorkloadScalingPolicyMemoryLimit) WorkloadScalingPolicyMemoryLimit {
		if v != nil {
			return *v
		}
		var ret WorkloadScalingPolicyMemoryLimit
		return ret
	}).(WorkloadScalingPolicyMemoryLimitOutput)
}

// Multiplier used to calculate the resource limit. It must be defined for the MULTIPLIER strategy.
func (o WorkloadScalingPolicyMemoryLimitPtrOutput) Multiplier() pulumi.Float64PtrOutput {
	return o.ApplyT(func(v *WorkloadScalingPolicyMemoryLimit) *float64 {
		if v == nil {
			return nil
		}
		return v.Multiplier
	}).(pulumi.Float64PtrOutput)
}

// Defines limit strategy type.
//   - NO_LIMIT - removes the resource limit even if it was specified in the workload spec.
//   - KEEP_LIMITS - keep existing resource limits. While limits provide stability predictability, they may restrict workloads that need to temporarily burst beyond their allocation.
//   - MULTIPLIER - used to calculate the resource limit. The final value is determined by multiplying the resource request by the specified factor.
func (o WorkloadScalingPolicyMemoryLimitPtrOutput) Type() pulumi.StringPtrOutput {
	return o.ApplyT(func(v *WorkloadScalingPolicyMemoryLimit) *string {
		if v == nil {
			return nil
		}
		return &v.Type
	}).(pulumi.StringPtrOutput)
}

type WorkloadScalingPolicyPredictiveScaling struct {
	// Defines predictive scaling resource configuration.
	Cpu *WorkloadScalingPolicyPredictiveScalingCpu `pulumi:"cpu"`
}

// WorkloadScalingPolicyPredictiveScalingInput is an input type that accepts WorkloadScalingPolicyPredictiveScalingArgs and WorkloadScalingPolicyPredictiveScalingOutput values.
// You can construct a concrete instance of `WorkloadScalingPolicyPredictiveScalingInput` via:
//
//	WorkloadScalingPolicyPredictiveScalingArgs{...}
type WorkloadScalingPolicyPredictiveScalingInput interface {
	pulumi.Input

	ToWorkloadScalingPolicyPredictiveScalingOutput() WorkloadScalingPolicyPredictiveScalingOutput
	ToWorkloadScalingPolicyPredictiveScalingOutputWithContext(context.Context) WorkloadScalingPolicyPredictiveScalingOutput
}

type WorkloadScalingPolicyPredictiveScalingArgs struct {
	// Defines predictive scaling resource configuration.
	Cpu WorkloadScalingPolicyPredictiveScalingCpuPtrInput `pulumi:"cpu"`
}

func (WorkloadScalingPolicyPredictiveScalingArgs) ElementType() reflect.Type {
	return reflect.TypeOf((*WorkloadScalingPolicyPredictiveScaling)(nil)).Elem()
}

func (i WorkloadScalingPolicyPredictiveScalingArgs) ToWorkloadScalingPolicyPredictiveScalingOutput() WorkloadScalingPolicyPredictiveScalingOutput {
	return i.ToWorkloadScalingPolicyPredictiveScalingOutputWithContext(context.Background())
}

func (i WorkloadScalingPolicyPredictiveScalingArgs) ToWorkloadScalingPolicyPredictiveScalingOutputWithContext(ctx context.Context) WorkloadScalingPolicyPredictiveScalingOutput {
	return pulumi.ToOutputWithContext(ctx, i).(WorkloadScalingPolicyPredictiveScalingOutput)
}

func (i WorkloadScalingPolicyPredictiveScalingArgs) ToWorkloadScalingPolicyPredictiveScalingPtrOutput() WorkloadScalingPolicyPredictiveScalingPtrOutput {
	return i.ToWorkloadScalingPolicyPredictiveScalingPtrOutputWithContext(context.Background())
}

func (i WorkloadScalingPolicyPredictiveScalingArgs) ToWorkloadScalingPolicyPredictiveScalingPtrOutputWithContext(ctx context.Context) WorkloadScalingPolicyPredictiveScalingPtrOutput {
	return pulumi.ToOutputWithContext(ctx, i).(WorkloadScalingPolicyPredictiveScalingOutput).ToWorkloadScalingPolicyPredictiveScalingPtrOutputWithContext(ctx)
}

// WorkloadScalingPolicyPredictiveScalingPtrInput is an input type that accepts WorkloadScalingPolicyPredictiveScalingArgs, WorkloadScalingPolicyPredictiveScalingPtr and WorkloadScalingPolicyPredictiveScalingPtrOutput values.
// You can construct a concrete instance of `WorkloadScalingPolicyPredictiveScalingPtrInput` via:
//
//	        WorkloadScalingPolicyPredictiveScalingArgs{...}
//
//	or:
//
//	        nil
type WorkloadScalingPolicyPredictiveScalingPtrInput interface {
	pulumi.Input

	ToWorkloadScalingPolicyPredictiveScalingPtrOutput() WorkloadScalingPolicyPredictiveScalingPtrOutput
	ToWorkloadScalingPolicyPredictiveScalingPtrOutputWithContext(context.Context) WorkloadScalingPolicyPredictiveScalingPtrOutput
}

type workloadScalingPolicyPredictiveScalingPtrType WorkloadScalingPolicyPredictiveScalingArgs

func WorkloadScalingPolicyPredictiveScalingPtr(v *WorkloadScalingPolicyPredictiveScalingArgs) WorkloadScalingPolicyPredictiveScalingPtrInput {
	return (*workloadScalingPolicyPredictiveScalingPtrType)(v)
}

func (*workloadScalingPolicyPredictiveScalingPtrType) ElementType() reflect.Type {
	return reflect.TypeOf((**WorkloadScalingPolicyPredictiveScaling)(nil)).Elem()
}

func (i *workloadScalingPolicyPredictiveScalingPtrType) ToWorkloadScalingPolicyPredictiveScalingPtrOutput() WorkloadScalingPolicyPredictiveScalingPtrOutput {
	return i.ToWorkloadScalingPolicyPredictiveScalingPtrOutputWithContext(context.Background())
}

func (i *workloadScalingPolicyPredictiveScalingPtrType) ToWorkloadScalingPolicyPredictiveScalingPtrOutputWithContext(ctx context.Context) WorkloadScalingPolicyPredictiveScalingPtrOutput {
	return pulumi.ToOutputWithContext(ctx, i).(WorkloadScalingPolicyPredictiveScalingPtrOutput)
}

type WorkloadScalingPolicyPredictiveScalingOutput struct{ *pulumi.OutputState }

func (WorkloadScalingPolicyPredictiveScalingOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*WorkloadScalingPolicyPredictiveScaling)(nil)).Elem()
}

func (o WorkloadScalingPolicyPredictiveScalingOutput) ToWorkloadScalingPolicyPredictiveScalingOutput() WorkloadScalingPolicyPredictiveScalingOutput {
	return o
}

func (o WorkloadScalingPolicyPredictiveScalingOutput) ToWorkloadScalingPolicyPredictiveScalingOutputWithContext(ctx context.Context) WorkloadScalingPolicyPredictiveScalingOutput {
	return o
}

func (o WorkloadScalingPolicyPredictiveScalingOutput) ToWorkloadScalingPolicyPredictiveScalingPtrOutput() WorkloadScalingPolicyPredictiveScalingPtrOutput {
	return o.ToWorkloadScalingPolicyPredictiveScalingPtrOutputWithContext(context.Background())
}

func (o WorkloadScalingPolicyPredictiveScalingOutput) ToWorkloadScalingPolicyPredictiveScalingPtrOutputWithContext(ctx context.Context) WorkloadScalingPolicyPredictiveScalingPtrOutput {
	return o.ApplyTWithContext(ctx, func(_ context.Context, v WorkloadScalingPolicyPredictiveScaling) *WorkloadScalingPolicyPredictiveScaling {
		return &v
	}).(WorkloadScalingPolicyPredictiveScalingPtrOutput)
}

// Defines predictive scaling resource configuration.
func (o WorkloadScalingPolicyPredictiveScalingOutput) Cpu() WorkloadScalingPolicyPredictiveScalingCpuPtrOutput {
	return o.ApplyT(func(v WorkloadScalingPolicyPredictiveScaling) *WorkloadScalingPolicyPredictiveScalingCpu {
		return v.Cpu
	}).(WorkloadScalingPolicyPredictiveScalingCpuPtrOutput)
}

type WorkloadScalingPolicyPredictiveScalingPtrOutput struct{ *pulumi.OutputState }

func (WorkloadScalingPolicyPredictiveScalingPtrOutput) ElementType() reflect.Type {
	return reflect.TypeOf((**WorkloadScalingPolicyPredictiveScaling)(nil)).Elem()
}

func (o WorkloadScalingPolicyPredictiveScalingPtrOutput) ToWorkloadScalingPolicyPredictiveScalingPtrOutput() WorkloadScalingPolicyPredictiveScalingPtrOutput {
	return o
}

func (o WorkloadScalingPolicyPredictiveScalingPtrOutput) ToWorkloadScalingPolicyPredictiveScalingPtrOutputWithContext(ctx context.Context) WorkloadScalingPolicyPredictiveScalingPtrOutput {
	return o
}

func (o WorkloadScalingPolicyPredictiveScalingPtrOutput) Elem() WorkloadScalingPolicyPredictiveScalingOutput {
	return o.ApplyT(func(v *WorkloadScalingPolicyPredictiveScaling) WorkloadScalingPolicyPredictiveScaling {
		if v != nil {
			return *v
		}
		var ret WorkloadScalingPolicyPredictiveScaling
		return ret
	}).(WorkloadScalingPolicyPredictiveScalingOutput)
}

// Defines predictive scaling resource configuration.
func (o WorkloadScalingPolicyPredictiveScalingPtrOutput) Cpu() WorkloadScalingPolicyPredictiveScalingCpuPtrOutput {
	return o.ApplyT(func(v *WorkloadScalingPolicyPredictiveScaling) *WorkloadScalingPolicyPredictiveScalingCpu {
		if v == nil {
			return nil
		}
		return v.Cpu
	}).(WorkloadScalingPolicyPredictiveScalingCpuPtrOutput)
}

type WorkloadScalingPolicyPredictiveScalingCpu struct {
	// Defines if predictive scaling is enabled for resource.
	Enabled bool `pulumi:"enabled"`
}

// WorkloadScalingPolicyPredictiveScalingCpuInput is an input type that accepts WorkloadScalingPolicyPredictiveScalingCpuArgs and WorkloadScalingPolicyPredictiveScalingCpuOutput values.
// You can construct a concrete instance of `WorkloadScalingPolicyPredictiveScalingCpuInput` via:
//
//	WorkloadScalingPolicyPredictiveScalingCpuArgs{...}
type WorkloadScalingPolicyPredictiveScalingCpuInput interface {
	pulumi.Input

	ToWorkloadScalingPolicyPredictiveScalingCpuOutput() WorkloadScalingPolicyPredictiveScalingCpuOutput
	ToWorkloadScalingPolicyPredictiveScalingCpuOutputWithContext(context.Context) WorkloadScalingPolicyPredictiveScalingCpuOutput
}

type WorkloadScalingPolicyPredictiveScalingCpuArgs struct {
	// Defines if predictive scaling is enabled for resource.
	Enabled pulumi.BoolInput `pulumi:"enabled"`
}

func (WorkloadScalingPolicyPredictiveScalingCpuArgs) ElementType() reflect.Type {
	return reflect.TypeOf((*WorkloadScalingPolicyPredictiveScalingCpu)(nil)).Elem()
}

func (i WorkloadScalingPolicyPredictiveScalingCpuArgs) ToWorkloadScalingPolicyPredictiveScalingCpuOutput() WorkloadScalingPolicyPredictiveScalingCpuOutput {
	return i.ToWorkloadScalingPolicyPredictiveScalingCpuOutputWithContext(context.Background())
}

func (i WorkloadScalingPolicyPredictiveScalingCpuArgs) ToWorkloadScalingPolicyPredictiveScalingCpuOutputWithContext(ctx context.Context) WorkloadScalingPolicyPredictiveScalingCpuOutput {
	return pulumi.ToOutputWithContext(ctx, i).(WorkloadScalingPolicyPredictiveScalingCpuOutput)
}

func (i WorkloadScalingPolicyPredictiveScalingCpuArgs) ToWorkloadScalingPolicyPredictiveScalingCpuPtrOutput() WorkloadScalingPolicyPredictiveScalingCpuPtrOutput {
	return i.ToWorkloadScalingPolicyPredictiveScalingCpuPtrOutputWithContext(context.Background())
}

func (i WorkloadScalingPolicyPredictiveScalingCpuArgs) ToWorkloadScalingPolicyPredictiveScalingCpuPtrOutputWithContext(ctx context.Context) WorkloadScalingPolicyPredictiveScalingCpuPtrOutput {
	return pulumi.ToOutputWithContext(ctx, i).(WorkloadScalingPolicyPredictiveScalingCpuOutput).ToWorkloadScalingPolicyPredictiveScalingCpuPtrOutputWithContext(ctx)
}

// WorkloadScalingPolicyPredictiveScalingCpuPtrInput is an input type that accepts WorkloadScalingPolicyPredictiveScalingCpuArgs, WorkloadScalingPolicyPredictiveScalingCpuPtr and WorkloadScalingPolicyPredictiveScalingCpuPtrOutput values.
// You can construct a concrete instance of `WorkloadScalingPolicyPredictiveScalingCpuPtrInput` via:
//
//	        WorkloadScalingPolicyPredictiveScalingCpuArgs{...}
//
//	or:
//
//	        nil
type WorkloadScalingPolicyPredictiveScalingCpuPtrInput interface {
	pulumi.Input

	ToWorkloadScalingPolicyPredictiveScalingCpuPtrOutput() WorkloadScalingPolicyPredictiveScalingCpuPtrOutput
	ToWorkloadScalingPolicyPredictiveScalingCpuPtrOutputWithContext(context.Context) WorkloadScalingPolicyPredictiveScalingCpuPtrOutput
}

type workloadScalingPolicyPredictiveScalingCpuPtrType WorkloadScalingPolicyPredictiveScalingCpuArgs

func WorkloadScalingPolicyPredictiveScalingCpuPtr(v *WorkloadScalingPolicyPredictiveScalingCpuArgs) WorkloadScalingPolicyPredictiveScalingCpuPtrInput {
	return (*workloadScalingPolicyPredictiveScalingCpuPtrType)(v)
}

func (*workloadScalingPolicyPredictiveScalingCpuPtrType) ElementType() reflect.Type {
	return reflect.TypeOf((**WorkloadScalingPolicyPredictiveScalingCpu)(nil)).Elem()
}

func (i *workloadScalingPolicyPredictiveScalingCpuPtrType) ToWorkloadScalingPolicyPredictiveScalingCpuPtrOutput() WorkloadScalingPolicyPredictiveScalingCpuPtrOutput {
	return i.ToWorkloadScalingPolicyPredictiveScalingCpuPtrOutputWithContext(context.Background())
}

func (i *workloadScalingPolicyPredictiveScalingCpuPtrType) ToWorkloadScalingPolicyPredictiveScalingCpuPtrOutputWithContext(ctx context.Context) WorkloadScalingPolicyPredictiveScalingCpuPtrOutput {
	return pulumi.ToOutputWithContext(ctx, i).(WorkloadScalingPolicyPredictiveScalingCpuPtrOutput)
}

type WorkloadScalingPolicyPredictiveScalingCpuOutput struct{ *pulumi.OutputState }

func (WorkloadScalingPolicyPredictiveScalingCpuOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*WorkloadScalingPolicyPredictiveScalingCpu)(nil)).Elem()
}

func (o WorkloadScalingPolicyPredictiveScalingCpuOutput) ToWorkloadScalingPolicyPredictiveScalingCpuOutput() WorkloadScalingPolicyPredictiveScalingCpuOutput {
	return o
}

func (o WorkloadScalingPolicyPredictiveScalingCpuOutput) ToWorkloadScalingPolicyPredictiveScalingCpuOutputWithContext(ctx context.Context) WorkloadScalingPolicyPredictiveScalingCpuOutput {
	return o
}

func (o WorkloadScalingPolicyPredictiveScalingCpuOutput) ToWorkloadScalingPolicyPredictiveScalingCpuPtrOutput() WorkloadScalingPolicyPredictiveScalingCpuPtrOutput {
	return o.ToWorkloadScalingPolicyPredictiveScalingCpuPtrOutputWithContext(context.Background())
}

func (o WorkloadScalingPolicyPredictiveScalingCpuOutput) ToWorkloadScalingPolicyPredictiveScalingCpuPtrOutputWithContext(ctx context.Context) WorkloadScalingPolicyPredictiveScalingCpuPtrOutput {
	return o.ApplyTWithContext(ctx, func(_ context.Context, v WorkloadScalingPolicyPredictiveScalingCpu) *WorkloadScalingPolicyPredictiveScalingCpu {
		return &v
	}).(WorkloadScalingPolicyPredictiveScalingCpuPtrOutput)
}

// Defines if predictive scaling is enabled for resource.
func (o WorkloadScalingPolicyPredictiveScalingCpuOutput) Enabled() pulumi.BoolOutput {
	return o.ApplyT(func(v WorkloadScalingPolicyPredictiveScalingCpu) bool { return v.Enabled }).(pulumi.BoolOutput)
}

type WorkloadScalingPolicyPredictiveScalingCpuPtrOutput struct{ *pulumi.OutputState }

func (WorkloadScalingPolicyPredictiveScalingCpuPtrOutput) ElementType() reflect.Type {
	return reflect.TypeOf((**WorkloadScalingPolicyPredictiveScalingCpu)(nil)).Elem()
}

func (o WorkloadScalingPolicyPredictiveScalingCpuPtrOutput) ToWorkloadScalingPolicyPredictiveScalingCpuPtrOutput() WorkloadScalingPolicyPredictiveScalingCpuPtrOutput {
	return o
}

func (o WorkloadScalingPolicyPredictiveScalingCpuPtrOutput) ToWorkloadScalingPolicyPredictiveScalingCpuPtrOutputWithContext(ctx context.Context) WorkloadScalingPolicyPredictiveScalingCpuPtrOutput {
	return o
}

func (o WorkloadScalingPolicyPredictiveScalingCpuPtrOutput) Elem() WorkloadScalingPolicyPredictiveScalingCpuOutput {
	return o.ApplyT(func(v *WorkloadScalingPolicyPredictiveScalingCpu) WorkloadScalingPolicyPredictiveScalingCpu {
		if v != nil {
			return *v
		}
		var ret WorkloadScalingPolicyPredictiveScalingCpu
		return ret
	}).(WorkloadScalingPolicyPredictiveScalingCpuOutput)
}

// Defines if predictive scaling is enabled for resource.
func (o WorkloadScalingPolicyPredictiveScalingCpuPtrOutput) Enabled() pulumi.BoolPtrOutput {
	return o.ApplyT(func(v *WorkloadScalingPolicyPredictiveScalingCpu) *bool {
		if v == nil {
			return nil
		}
		return &v.Enabled
	}).(pulumi.BoolPtrOutput)
}

type WorkloadScalingPolicyRolloutBehavior struct {
	// Defines if pods should be restarted one by one to avoid service disruption.
	PreferOneByOne *bool `pulumi:"preferOneByOne"`
	// Defines the rollout type to be used when applying recommendations.
	// 	- NO_DISRUPTION - pods are restarted without causing service disruption.
	Type *string `pulumi:"type"`
}

// WorkloadScalingPolicyRolloutBehaviorInput is an input type that accepts WorkloadScalingPolicyRolloutBehaviorArgs and WorkloadScalingPolicyRolloutBehaviorOutput values.
// You can construct a concrete instance of `WorkloadScalingPolicyRolloutBehaviorInput` via:
//
//	WorkloadScalingPolicyRolloutBehaviorArgs{...}
type WorkloadScalingPolicyRolloutBehaviorInput interface {
	pulumi.Input

	ToWorkloadScalingPolicyRolloutBehaviorOutput() WorkloadScalingPolicyRolloutBehaviorOutput
	ToWorkloadScalingPolicyRolloutBehaviorOutputWithContext(context.Context) WorkloadScalingPolicyRolloutBehaviorOutput
}

type WorkloadScalingPolicyRolloutBehaviorArgs struct {
	// Defines if pods should be restarted one by one to avoid service disruption.
	PreferOneByOne pulumi.BoolPtrInput `pulumi:"preferOneByOne"`
	// Defines the rollout type to be used when applying recommendations.
	// 	- NO_DISRUPTION - pods are restarted without causing service disruption.
	Type pulumi.StringPtrInput `pulumi:"type"`
}

func (WorkloadScalingPolicyRolloutBehaviorArgs) ElementType() reflect.Type {
	return reflect.TypeOf((*WorkloadScalingPolicyRolloutBehavior)(nil)).Elem()
}

func (i WorkloadScalingPolicyRolloutBehaviorArgs) ToWorkloadScalingPolicyRolloutBehaviorOutput() WorkloadScalingPolicyRolloutBehaviorOutput {
	return i.ToWorkloadScalingPolicyRolloutBehaviorOutputWithContext(context.Background())
}

func (i WorkloadScalingPolicyRolloutBehaviorArgs) ToWorkloadScalingPolicyRolloutBehaviorOutputWithContext(ctx context.Context) WorkloadScalingPolicyRolloutBehaviorOutput {
	return pulumi.ToOutputWithContext(ctx, i).(WorkloadScalingPolicyRolloutBehaviorOutput)
}

func (i WorkloadScalingPolicyRolloutBehaviorArgs) ToWorkloadScalingPolicyRolloutBehaviorPtrOutput() WorkloadScalingPolicyRolloutBehaviorPtrOutput {
	return i.ToWorkloadScalingPolicyRolloutBehaviorPtrOutputWithContext(context.Background())
}

func (i WorkloadScalingPolicyRolloutBehaviorArgs) ToWorkloadScalingPolicyRolloutBehaviorPtrOutputWithContext(ctx context.Context) WorkloadScalingPolicyRolloutBehaviorPtrOutput {
	return pulumi.ToOutputWithContext(ctx, i).(WorkloadScalingPolicyRolloutBehaviorOutput).ToWorkloadScalingPolicyRolloutBehaviorPtrOutputWithContext(ctx)
}

// WorkloadScalingPolicyRolloutBehaviorPtrInput is an input type that accepts WorkloadScalingPolicyRolloutBehaviorArgs, WorkloadScalingPolicyRolloutBehaviorPtr and WorkloadScalingPolicyRolloutBehaviorPtrOutput values.
// You can construct a concrete instance of `WorkloadScalingPolicyRolloutBehaviorPtrInput` via:
//
//	        WorkloadScalingPolicyRolloutBehaviorArgs{...}
//
//	or:
//
//	        nil
type WorkloadScalingPolicyRolloutBehaviorPtrInput interface {
	pulumi.Input

	ToWorkloadScalingPolicyRolloutBehaviorPtrOutput() WorkloadScalingPolicyRolloutBehaviorPtrOutput
	ToWorkloadScalingPolicyRolloutBehaviorPtrOutputWithContext(context.Context) WorkloadScalingPolicyRolloutBehaviorPtrOutput
}

type workloadScalingPolicyRolloutBehaviorPtrType WorkloadScalingPolicyRolloutBehaviorArgs

func WorkloadScalingPolicyRolloutBehaviorPtr(v *WorkloadScalingPolicyRolloutBehaviorArgs) WorkloadScalingPolicyRolloutBehaviorPtrInput {
	return (*workloadScalingPolicyRolloutBehaviorPtrType)(v)
}

func (*workloadScalingPolicyRolloutBehaviorPtrType) ElementType() reflect.Type {
	return reflect.TypeOf((**WorkloadScalingPolicyRolloutBehavior)(nil)).Elem()
}

func (i *workloadScalingPolicyRolloutBehaviorPtrType) ToWorkloadScalingPolicyRolloutBehaviorPtrOutput() WorkloadScalingPolicyRolloutBehaviorPtrOutput {
	return i.ToWorkloadScalingPolicyRolloutBehaviorPtrOutputWithContext(context.Background())
}

func (i *workloadScalingPolicyRolloutBehaviorPtrType) ToWorkloadScalingPolicyRolloutBehaviorPtrOutputWithContext(ctx context.Context) WorkloadScalingPolicyRolloutBehaviorPtrOutput {
	return pulumi.ToOutputWithContext(ctx, i).(WorkloadScalingPolicyRolloutBehaviorPtrOutput)
}

type WorkloadScalingPolicyRolloutBehaviorOutput struct{ *pulumi.OutputState }

func (WorkloadScalingPolicyRolloutBehaviorOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*WorkloadScalingPolicyRolloutBehavior)(nil)).Elem()
}

func (o WorkloadScalingPolicyRolloutBehaviorOutput) ToWorkloadScalingPolicyRolloutBehaviorOutput() WorkloadScalingPolicyRolloutBehaviorOutput {
	return o
}

func (o WorkloadScalingPolicyRolloutBehaviorOutput) ToWorkloadScalingPolicyRolloutBehaviorOutputWithContext(ctx context.Context) WorkloadScalingPolicyRolloutBehaviorOutput {
	return o
}

func (o WorkloadScalingPolicyRolloutBehaviorOutput) ToWorkloadScalingPolicyRolloutBehaviorPtrOutput() WorkloadScalingPolicyRolloutBehaviorPtrOutput {
	return o.ToWorkloadScalingPolicyRolloutBehaviorPtrOutputWithContext(context.Background())
}

func (o WorkloadScalingPolicyRolloutBehaviorOutput) ToWorkloadScalingPolicyRolloutBehaviorPtrOutputWithContext(ctx context.Context) WorkloadScalingPolicyRolloutBehaviorPtrOutput {
	return o.ApplyTWithContext(ctx, func(_ context.Context, v WorkloadScalingPolicyRolloutBehavior) *WorkloadScalingPolicyRolloutBehavior {
		return &v
	}).(WorkloadScalingPolicyRolloutBehaviorPtrOutput)
}

// Defines if pods should be restarted one by one to avoid service disruption.
func (o WorkloadScalingPolicyRolloutBehaviorOutput) PreferOneByOne() pulumi.BoolPtrOutput {
	return o.ApplyT(func(v WorkloadScalingPolicyRolloutBehavior) *bool { return v.PreferOneByOne }).(pulumi.BoolPtrOutput)
}

// Defines the rollout type to be used when applying recommendations.
//   - NO_DISRUPTION - pods are restarted without causing service disruption.
func (o WorkloadScalingPolicyRolloutBehaviorOutput) Type() pulumi.StringPtrOutput {
	return o.ApplyT(func(v WorkloadScalingPolicyRolloutBehavior) *string { return v.Type }).(pulumi.StringPtrOutput)
}

type WorkloadScalingPolicyRolloutBehaviorPtrOutput struct{ *pulumi.OutputState }

func (WorkloadScalingPolicyRolloutBehaviorPtrOutput) ElementType() reflect.Type {
	return reflect.TypeOf((**WorkloadScalingPolicyRolloutBehavior)(nil)).Elem()
}

func (o WorkloadScalingPolicyRolloutBehaviorPtrOutput) ToWorkloadScalingPolicyRolloutBehaviorPtrOutput() WorkloadScalingPolicyRolloutBehaviorPtrOutput {
	return o
}

func (o WorkloadScalingPolicyRolloutBehaviorPtrOutput) ToWorkloadScalingPolicyRolloutBehaviorPtrOutputWithContext(ctx context.Context) WorkloadScalingPolicyRolloutBehaviorPtrOutput {
	return o
}

func (o WorkloadScalingPolicyRolloutBehaviorPtrOutput) Elem() WorkloadScalingPolicyRolloutBehaviorOutput {
	return o.ApplyT(func(v *WorkloadScalingPolicyRolloutBehavior) WorkloadScalingPolicyRolloutBehavior {
		if v != nil {
			return *v
		}
		var ret WorkloadScalingPolicyRolloutBehavior
		return ret
	}).(WorkloadScalingPolicyRolloutBehaviorOutput)
}

// Defines if pods should be restarted one by one to avoid service disruption.
func (o WorkloadScalingPolicyRolloutBehaviorPtrOutput) PreferOneByOne() pulumi.BoolPtrOutput {
	return o.ApplyT(func(v *WorkloadScalingPolicyRolloutBehavior) *bool {
		if v == nil {
			return nil
		}
		return v.PreferOneByOne
	}).(pulumi.BoolPtrOutput)
}

// Defines the rollout type to be used when applying recommendations.
//   - NO_DISRUPTION - pods are restarted without causing service disruption.
func (o WorkloadScalingPolicyRolloutBehaviorPtrOutput) Type() pulumi.StringPtrOutput {
	return o.ApplyT(func(v *WorkloadScalingPolicyRolloutBehavior) *string {
		if v == nil {
			return nil
		}
		return v.Type
	}).(pulumi.StringPtrOutput)
}

type WorkloadScalingPolicyStartup struct {
	// Defines the duration (in seconds) during which elevated resource usage is expected at startup.
	// When set, recommendations will be adjusted to disregard resource spikes within this period.
	// If not specified, the workload will receive standard recommendations without startup considerations.
	PeriodSeconds *int `pulumi:"periodSeconds"`
}

// WorkloadScalingPolicyStartupInput is an input type that accepts WorkloadScalingPolicyStartupArgs and WorkloadScalingPolicyStartupOutput values.
// You can construct a concrete instance of `WorkloadScalingPolicyStartupInput` via:
//
//	WorkloadScalingPolicyStartupArgs{...}
type WorkloadScalingPolicyStartupInput interface {
	pulumi.Input

	ToWorkloadScalingPolicyStartupOutput() WorkloadScalingPolicyStartupOutput
	ToWorkloadScalingPolicyStartupOutputWithContext(context.Context) WorkloadScalingPolicyStartupOutput
}

type WorkloadScalingPolicyStartupArgs struct {
	// Defines the duration (in seconds) during which elevated resource usage is expected at startup.
	// When set, recommendations will be adjusted to disregard resource spikes within this period.
	// If not specified, the workload will receive standard recommendations without startup considerations.
	PeriodSeconds pulumi.IntPtrInput `pulumi:"periodSeconds"`
}

func (WorkloadScalingPolicyStartupArgs) ElementType() reflect.Type {
	return reflect.TypeOf((*WorkloadScalingPolicyStartup)(nil)).Elem()
}

func (i WorkloadScalingPolicyStartupArgs) ToWorkloadScalingPolicyStartupOutput() WorkloadScalingPolicyStartupOutput {
	return i.ToWorkloadScalingPolicyStartupOutputWithContext(context.Background())
}

func (i WorkloadScalingPolicyStartupArgs) ToWorkloadScalingPolicyStartupOutputWithContext(ctx context.Context) WorkloadScalingPolicyStartupOutput {
	return pulumi.ToOutputWithContext(ctx, i).(WorkloadScalingPolicyStartupOutput)
}

func (i WorkloadScalingPolicyStartupArgs) ToWorkloadScalingPolicyStartupPtrOutput() WorkloadScalingPolicyStartupPtrOutput {
	return i.ToWorkloadScalingPolicyStartupPtrOutputWithContext(context.Background())
}

func (i WorkloadScalingPolicyStartupArgs) ToWorkloadScalingPolicyStartupPtrOutputWithContext(ctx context.Context) WorkloadScalingPolicyStartupPtrOutput {
	return pulumi.ToOutputWithContext(ctx, i).(WorkloadScalingPolicyStartupOutput).ToWorkloadScalingPolicyStartupPtrOutputWithContext(ctx)
}

// WorkloadScalingPolicyStartupPtrInput is an input type that accepts WorkloadScalingPolicyStartupArgs, WorkloadScalingPolicyStartupPtr and WorkloadScalingPolicyStartupPtrOutput values.
// You can construct a concrete instance of `WorkloadScalingPolicyStartupPtrInput` via:
//
//	        WorkloadScalingPolicyStartupArgs{...}
//
//	or:
//
//	        nil
type WorkloadScalingPolicyStartupPtrInput interface {
	pulumi.Input

	ToWorkloadScalingPolicyStartupPtrOutput() WorkloadScalingPolicyStartupPtrOutput
	ToWorkloadScalingPolicyStartupPtrOutputWithContext(context.Context) WorkloadScalingPolicyStartupPtrOutput
}

type workloadScalingPolicyStartupPtrType WorkloadScalingPolicyStartupArgs

func WorkloadScalingPolicyStartupPtr(v *WorkloadScalingPolicyStartupArgs) WorkloadScalingPolicyStartupPtrInput {
	return (*workloadScalingPolicyStartupPtrType)(v)
}

func (*workloadScalingPolicyStartupPtrType) ElementType() reflect.Type {
	return reflect.TypeOf((**WorkloadScalingPolicyStartup)(nil)).Elem()
}

func (i *workloadScalingPolicyStartupPtrType) ToWorkloadScalingPolicyStartupPtrOutput() WorkloadScalingPolicyStartupPtrOutput {
	return i.ToWorkloadScalingPolicyStartupPtrOutputWithContext(context.Background())
}

func (i *workloadScalingPolicyStartupPtrType) ToWorkloadScalingPolicyStartupPtrOutputWithContext(ctx context.Context) WorkloadScalingPolicyStartupPtrOutput {
	return pulumi.ToOutputWithContext(ctx, i).(WorkloadScalingPolicyStartupPtrOutput)
}

type WorkloadScalingPolicyStartupOutput struct{ *pulumi.OutputState }

func (WorkloadScalingPolicyStartupOutput) ElementType() reflect.Type {
	return reflect.TypeOf((*WorkloadScalingPolicyStartup)(nil)).Elem()
}

func (o WorkloadScalingPolicyStartupOutput) ToWorkloadScalingPolicyStartupOutput() WorkloadScalingPolicyStartupOutput {
	return o
}

func (o WorkloadScalingPolicyStartupOutput) ToWorkloadScalingPolicyStartupOutputWithContext(ctx context.Context) WorkloadScalingPolicyStartupOutput {
	return o
}

func (o WorkloadScalingPolicyStartupOutput) ToWorkloadScalingPolicyStartupPtrOutput() WorkloadScalingPolicyStartupPtrOutput {
	return o.ToWorkloadScalingPolicyStartupPtrOutputWithContext(context.Background())
}

func (o WorkloadScalingPolicyStartupOutput) ToWorkloadScalingPolicyStartupPtrOutputWithContext(ctx context.Context) WorkloadScalingPolicyStartupPtrOutput {
	return o.ApplyTWithContext(ctx, func(_ context.Context, v WorkloadScalingPolicyStartup) *WorkloadScalingPolicyStartup {
		return &v
	}).(WorkloadScalingPolicyStartupPtrOutput)
}

// Defines the duration (in seconds) during which elevated resource usage is expected at startup.
// When set, recommendations will be adjusted to disregard resource spikes within this period.
// If not specified, the workload will receive standard recommendations without startup considerations.
func (o WorkloadScalingPolicyStartupOutput) PeriodSeconds() pulumi.IntPtrOutput {
	return o.ApplyT(func(v WorkloadScalingPolicyStartup) *int { return v.PeriodSeconds }).(pulumi.IntPtrOutput)
}

type WorkloadScalingPolicyStartupPtrOutput struct{ *pulumi.OutputState }

func (WorkloadScalingPolicyStartupPtrOutput) ElementType() reflect.Type {
	return reflect.TypeOf((**WorkloadScalingPolicyStartup)(nil)).Elem()
}

func (o WorkloadScalingPolicyStartupPtrOutput) ToWorkloadScalingPolicyStartupPtrOutput() WorkloadScalingPolicyStartupPtrOutput {
	return o
}

func (o WorkloadScalingPolicyStartupPtrOutput) ToWorkloadScalingPolicyStartupPtrOutputWithContext(ctx context.Context) WorkloadScalingPolicyStartupPtrOutput {
	return o
}

func (o WorkloadScalingPolicyStartupPtrOutput) Elem() WorkloadScalingPolicyStartupOutput {
	return o.ApplyT(func(v *WorkloadScalingPolicyStartup) WorkloadScalingPolicyStartup {
		if v != nil {
			return *v
		}
		var ret WorkloadScalingPolicyStartup
		return ret
	}).(WorkloadScalingPolicyStartupOutput)
}

// Defines the duration (in seconds) during which elevated resource usage is expected at startup.
// When set, recommendations will be adjusted to disregard resource spikes within this period.
// If not specified, the workload will receive standard recommendations without startup considerations.
func (o WorkloadScalingPolicyStartupPtrOutput) PeriodSeconds() pulumi.IntPtrOutput {
	return o.ApplyT(func(v *WorkloadScalingPolicyStartup) *int {
		if v == nil {
			return nil
		}
		return v.PeriodSeconds
	}).(pulumi.IntPtrOutput)
}

func init() {
	pulumi.RegisterInputType(reflect.TypeOf((*WorkloadScalingPolicyAntiAffinityInput)(nil)).Elem(), WorkloadScalingPolicyAntiAffinityArgs{})
	pulumi.RegisterInputType(reflect.TypeOf((*WorkloadScalingPolicyAntiAffinityPtrInput)(nil)).Elem(), WorkloadScalingPolicyAntiAffinityArgs{})
	pulumi.RegisterInputType(reflect.TypeOf((*WorkloadScalingPolicyAssignmentRuleInput)(nil)).Elem(), WorkloadScalingPolicyAssignmentRuleArgs{})
	pulumi.RegisterInputType(reflect.TypeOf((*WorkloadScalingPolicyAssignmentRuleArrayInput)(nil)).Elem(), WorkloadScalingPolicyAssignmentRuleArray{})
	pulumi.RegisterInputType(reflect.TypeOf((*WorkloadScalingPolicyAssignmentRuleRuleInput)(nil)).Elem(), WorkloadScalingPolicyAssignmentRuleRuleArgs{})
	pulumi.RegisterInputType(reflect.TypeOf((*WorkloadScalingPolicyAssignmentRuleRuleArrayInput)(nil)).Elem(), WorkloadScalingPolicyAssignmentRuleRuleArray{})
	pulumi.RegisterInputType(reflect.TypeOf((*WorkloadScalingPolicyAssignmentRuleRuleNamespaceInput)(nil)).Elem(), WorkloadScalingPolicyAssignmentRuleRuleNamespaceArgs{})
	pulumi.RegisterInputType(reflect.TypeOf((*WorkloadScalingPolicyAssignmentRuleRuleNamespacePtrInput)(nil)).Elem(), WorkloadScalingPolicyAssignmentRuleRuleNamespaceArgs{})
	pulumi.RegisterInputType(reflect.TypeOf((*WorkloadScalingPolicyAssignmentRuleRuleWorkloadInput)(nil)).Elem(), WorkloadScalingPolicyAssignmentRuleRuleWorkloadArgs{})
	pulumi.RegisterInputType(reflect.TypeOf((*WorkloadScalingPolicyAssignmentRuleRuleWorkloadPtrInput)(nil)).Elem(), WorkloadScalingPolicyAssignmentRuleRuleWorkloadArgs{})
	pulumi.RegisterInputType(reflect.TypeOf((*WorkloadScalingPolicyAssignmentRuleRuleWorkloadLabelsExpressionInput)(nil)).Elem(), WorkloadScalingPolicyAssignmentRuleRuleWorkloadLabelsExpressionArgs{})
	pulumi.RegisterInputType(reflect.TypeOf((*WorkloadScalingPolicyAssignmentRuleRuleWorkloadLabelsExpressionArrayInput)(nil)).Elem(), WorkloadScalingPolicyAssignmentRuleRuleWorkloadLabelsExpressionArray{})
	pulumi.RegisterInputType(reflect.TypeOf((*WorkloadScalingPolicyConfidenceInput)(nil)).Elem(), WorkloadScalingPolicyConfidenceArgs{})
	pulumi.RegisterInputType(reflect.TypeOf((*WorkloadScalingPolicyConfidencePtrInput)(nil)).Elem(), WorkloadScalingPolicyConfidenceArgs{})
	pulumi.RegisterInputType(reflect.TypeOf((*WorkloadScalingPolicyCpuInput)(nil)).Elem(), WorkloadScalingPolicyCpuArgs{})
	pulumi.RegisterInputType(reflect.TypeOf((*WorkloadScalingPolicyCpuPtrInput)(nil)).Elem(), WorkloadScalingPolicyCpuArgs{})
	pulumi.RegisterInputType(reflect.TypeOf((*WorkloadScalingPolicyCpuApplyThresholdStrategyInput)(nil)).Elem(), WorkloadScalingPolicyCpuApplyThresholdStrategyArgs{})
	pulumi.RegisterInputType(reflect.TypeOf((*WorkloadScalingPolicyCpuApplyThresholdStrategyPtrInput)(nil)).Elem(), WorkloadScalingPolicyCpuApplyThresholdStrategyArgs{})
	pulumi.RegisterInputType(reflect.TypeOf((*WorkloadScalingPolicyCpuLimitInput)(nil)).Elem(), WorkloadScalingPolicyCpuLimitArgs{})
	pulumi.RegisterInputType(reflect.TypeOf((*WorkloadScalingPolicyCpuLimitPtrInput)(nil)).Elem(), WorkloadScalingPolicyCpuLimitArgs{})
	pulumi.RegisterInputType(reflect.TypeOf((*WorkloadScalingPolicyDownscalingInput)(nil)).Elem(), WorkloadScalingPolicyDownscalingArgs{})
	pulumi.RegisterInputType(reflect.TypeOf((*WorkloadScalingPolicyDownscalingPtrInput)(nil)).Elem(), WorkloadScalingPolicyDownscalingArgs{})
	pulumi.RegisterInputType(reflect.TypeOf((*WorkloadScalingPolicyMemoryInput)(nil)).Elem(), WorkloadScalingPolicyMemoryArgs{})
	pulumi.RegisterInputType(reflect.TypeOf((*WorkloadScalingPolicyMemoryPtrInput)(nil)).Elem(), WorkloadScalingPolicyMemoryArgs{})
	pulumi.RegisterInputType(reflect.TypeOf((*WorkloadScalingPolicyMemoryApplyThresholdStrategyInput)(nil)).Elem(), WorkloadScalingPolicyMemoryApplyThresholdStrategyArgs{})
	pulumi.RegisterInputType(reflect.TypeOf((*WorkloadScalingPolicyMemoryApplyThresholdStrategyPtrInput)(nil)).Elem(), WorkloadScalingPolicyMemoryApplyThresholdStrategyArgs{})
	pulumi.RegisterInputType(reflect.TypeOf((*WorkloadScalingPolicyMemoryEventInput)(nil)).Elem(), WorkloadScalingPolicyMemoryEventArgs{})
	pulumi.RegisterInputType(reflect.TypeOf((*WorkloadScalingPolicyMemoryEventPtrInput)(nil)).Elem(), WorkloadScalingPolicyMemoryEventArgs{})
	pulumi.RegisterInputType(reflect.TypeOf((*WorkloadScalingPolicyMemoryLimitInput)(nil)).Elem(), WorkloadScalingPolicyMemoryLimitArgs{})
	pulumi.RegisterInputType(reflect.TypeOf((*WorkloadScalingPolicyMemoryLimitPtrInput)(nil)).Elem(), WorkloadScalingPolicyMemoryLimitArgs{})
	pulumi.RegisterInputType(reflect.TypeOf((*WorkloadScalingPolicyPredictiveScalingInput)(nil)).Elem(), WorkloadScalingPolicyPredictiveScalingArgs{})
	pulumi.RegisterInputType(reflect.TypeOf((*WorkloadScalingPolicyPredictiveScalingPtrInput)(nil)).Elem(), WorkloadScalingPolicyPredictiveScalingArgs{})
	pulumi.RegisterInputType(reflect.TypeOf((*WorkloadScalingPolicyPredictiveScalingCpuInput)(nil)).Elem(), WorkloadScalingPolicyPredictiveScalingCpuArgs{})
	pulumi.RegisterInputType(reflect.TypeOf((*WorkloadScalingPolicyPredictiveScalingCpuPtrInput)(nil)).Elem(), WorkloadScalingPolicyPredictiveScalingCpuArgs{})
	pulumi.RegisterInputType(reflect.TypeOf((*WorkloadScalingPolicyRolloutBehaviorInput)(nil)).Elem(), WorkloadScalingPolicyRolloutBehaviorArgs{})
	pulumi.RegisterInputType(reflect.TypeOf((*WorkloadScalingPolicyRolloutBehaviorPtrInput)(nil)).Elem(), WorkloadScalingPolicyRolloutBehaviorArgs{})
	pulumi.RegisterInputType(reflect.TypeOf((*WorkloadScalingPolicyStartupInput)(nil)).Elem(), WorkloadScalingPolicyStartupArgs{})
	pulumi.RegisterInputType(reflect.TypeOf((*WorkloadScalingPolicyStartupPtrInput)(nil)).Elem(), WorkloadScalingPolicyStartupArgs{})
	pulumi.RegisterOutputType(WorkloadScalingPolicyAntiAffinityOutput{})
	pulumi.RegisterOutputType(WorkloadScalingPolicyAntiAffinityPtrOutput{})
	pulumi.RegisterOutputType(WorkloadScalingPolicyAssignmentRuleOutput{})
	pulumi.RegisterOutputType(WorkloadScalingPolicyAssignmentRuleArrayOutput{})
	pulumi.RegisterOutputType(WorkloadScalingPolicyAssignmentRuleRuleOutput{})
	pulumi.RegisterOutputType(WorkloadScalingPolicyAssignmentRuleRuleArrayOutput{})
	pulumi.RegisterOutputType(WorkloadScalingPolicyAssignmentRuleRuleNamespaceOutput{})
	pulumi.RegisterOutputType(WorkloadScalingPolicyAssignmentRuleRuleNamespacePtrOutput{})
	pulumi.RegisterOutputType(WorkloadScalingPolicyAssignmentRuleRuleWorkloadOutput{})
	pulumi.RegisterOutputType(WorkloadScalingPolicyAssignmentRuleRuleWorkloadPtrOutput{})
	pulumi.RegisterOutputType(WorkloadScalingPolicyAssignmentRuleRuleWorkloadLabelsExpressionOutput{})
	pulumi.RegisterOutputType(WorkloadScalingPolicyAssignmentRuleRuleWorkloadLabelsExpressionArrayOutput{})
	pulumi.RegisterOutputType(WorkloadScalingPolicyConfidenceOutput{})
	pulumi.RegisterOutputType(WorkloadScalingPolicyConfidencePtrOutput{})
	pulumi.RegisterOutputType(WorkloadScalingPolicyCpuOutput{})
	pulumi.RegisterOutputType(WorkloadScalingPolicyCpuPtrOutput{})
	pulumi.RegisterOutputType(WorkloadScalingPolicyCpuApplyThresholdStrategyOutput{})
	pulumi.RegisterOutputType(WorkloadScalingPolicyCpuApplyThresholdStrategyPtrOutput{})
	pulumi.RegisterOutputType(WorkloadScalingPolicyCpuLimitOutput{})
	pulumi.RegisterOutputType(WorkloadScalingPolicyCpuLimitPtrOutput{})
	pulumi.RegisterOutputType(WorkloadScalingPolicyDownscalingOutput{})
	pulumi.RegisterOutputType(WorkloadScalingPolicyDownscalingPtrOutput{})
	pulumi.RegisterOutputType(WorkloadScalingPolicyMemoryOutput{})
	pulumi.RegisterOutputType(WorkloadScalingPolicyMemoryPtrOutput{})
	pulumi.RegisterOutputType(WorkloadScalingPolicyMemoryApplyThresholdStrategyOutput{})
	pulumi.RegisterOutputType(WorkloadScalingPolicyMemoryApplyThresholdStrategyPtrOutput{})
	pulumi.RegisterOutputType(WorkloadScalingPolicyMemoryEventOutput{})
	pulumi.RegisterOutputType(WorkloadScalingPolicyMemoryEventPtrOutput{})
	pulumi.RegisterOutputType(WorkloadScalingPolicyMemoryLimitOutput{})
	pulumi.RegisterOutputType(WorkloadScalingPolicyMemoryLimitPtrOutput{})
	pulumi.RegisterOutputType(WorkloadScalingPolicyPredictiveScalingOutput{})
	pulumi.RegisterOutputType(WorkloadScalingPolicyPredictiveScalingPtrOutput{})
	pulumi.RegisterOutputType(WorkloadScalingPolicyPredictiveScalingCpuOutput{})
	pulumi.RegisterOutputType(WorkloadScalingPolicyPredictiveScalingCpuPtrOutput{})
	pulumi.RegisterOutputType(WorkloadScalingPolicyRolloutBehaviorOutput{})
	pulumi.RegisterOutputType(WorkloadScalingPolicyRolloutBehaviorPtrOutput{})
	pulumi.RegisterOutputType(WorkloadScalingPolicyStartupOutput{})
	pulumi.RegisterOutputType(WorkloadScalingPolicyStartupPtrOutput{})
}
